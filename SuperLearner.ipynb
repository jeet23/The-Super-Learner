{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import random\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "import inspect\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Add more packages as required\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Grid Search for 6 base estimators and then use the best params for the SuperLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 25}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6270833333333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 8, 'min_samples_split': 25, 'n_estimators': 400}\n",
      "0.75\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.2, 'max_iter': 1000, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
      "0.78125\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 6}\n",
      "0.7125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeet/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/jeet/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/jeet/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/jeet/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/jeet/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:565: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/Users/jeet/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:565: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 1e-05, 'hidden_layer_sizes': (400, 200)}\n",
      "0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "# Performing Grid search for the 6 base estimators for Fashion MNIST train dataset 1% sample,\n",
    "# so that those parameters can be used as a sensible default set of hyper-parameters\n",
    "data_sampling_rate = 0.01\n",
    "cv_folds=2\n",
    "dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "\n",
    "X = dataset[dataset.columns[1:]].values\n",
    "X = X/255\n",
    "Y = np.array(dataset[\"label\"])\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, stratify=Y, test_size=0.2)\n",
    "\n",
    "param_grid ={'criterion': ['gini', \"entropy\"], \\\n",
    "             'max_depth': list(range(3, 50, 3)), \\\n",
    "             'min_samples_split': [25,50]}\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_tree = GridSearchCV(DecisionTreeClassifier(), \\\n",
    "                                param_grid, cv=cv_folds, \\\n",
    "                            return_train_score=True)\n",
    "my_tuned_tree.fit(X_train, Y_train)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_tree.best_params_)\n",
    "display(my_tuned_tree.best_score_)\n",
    "\n",
    "\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(100, 501, 50)), 'max_features': list(range(2, 10, 2)), 'min_samples_split': [25, 50] }\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(RandomForestClassifier(), param_grid, cv=cv_folds)\n",
    "my_tuned_model.fit(X_train, Y_train)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "print(my_tuned_model.best_score_)\n",
    "\n",
    "param_grid = [\n",
    " {'multi_class': ['ovr'], \n",
    " 'C': [x / 10.0 for x in range(2, 21, 2)],\n",
    " 'solver':['liblinear'],\n",
    "  'max_iter':[1000]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(LogisticRegression(), param_grid, cv=cv_folds)\n",
    "my_tuned_model.fit(X_train, Y_train)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "print(my_tuned_model.best_score_)\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "               {'n_neighbors': list(range(1, 50, 5))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(KNeighborsClassifier(), param_grid, cv=cv_folds)\n",
    "my_tuned_model.fit(X_train, Y_train)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "print(my_tuned_model.best_score_)\n",
    "\n",
    "param_grid = [\n",
    "               {'hidden_layer_sizes': [(400), (400, 200), (400, 200, 100)], \n",
    "               'alpha': list(10.0 ** -np.arange(1, 7))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(MLPClassifier(), param_grid, cv=cv_folds)\n",
    "my_tuned_model.fit(X_train, Y_train)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "print(my_tuned_model.best_score_)\n",
    "\n",
    "param_grid = [\n",
    "               {'hidden_layer_sizes': [(400), (400, 200), (400, 200, 100)], \n",
    "               'alpha': list(10.0 ** -np.arange(1, 7))}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Super Learner Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Super Learner* is a heterogeneous stacked ensemble classifier. This is a classification model that uses a set of base classifiers of different types, the outputs of which are then combined in another classifier at the stacked layer. The Super Learner was described in [(van der Laan et al, 2007)](https://pdfs.semanticscholar.org/19e9/c732082706f39d2ba12845851309714db135.pdf) but the stacked ensemble idea has been around for a long time. \n",
    "\n",
    "Figure 1 shows a flow diagram of the Super Learner process (this is from (van der Laan et al, 2007) and the process is also described in the COMP47590 lecture \"[COMP47590 2017-2018 L04 Supervised Learning Ensembles 3](https://www.dropbox.com/s/1ksx94nxtuyn4l8/COMP47590%202017-2018%20L04%20Supervised%20Learning%20Ensembles%203.pdf?raw=1)\"). The base classifiers are trained and their outputs are combined along with the training dataset labels into a training set for the stack layer classifier. To avoid overfitting the generation of the stacked layer training set uses a k-fold cross validation process (described as V-fold in Figure 1). To further add variety to the base estimators a bootstrapping selection (as is used in the bagging ensemble approach).\n",
    " \n",
    "![Super Learner Process Flow](SuperLearnerProcessFlow.png \"Logo Title Text 1\")\n",
    "Figure 1: A flow diagram for the Super Learner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the SuperLearnerClassifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class SuperLearnerClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    criteria : indicates whether the stacked layer classifier should be trained \n",
    "               on label outputs from the base classifiers \n",
    "               or probability outputs from the base classifiers.\n",
    "    \n",
    "    stacked_model : type of model to use at the stack layer\n",
    "    \n",
    "    base_models : list of base estimators to use\n",
    "                'CART' -> Decision Tree\n",
    "                'RF' -> Random Forest\n",
    "                'NB' -> Naive Bayes \n",
    "                'KNN'-> K Nearest neighbour\n",
    "                'LR' -> Logisitc regression\n",
    "                'MLP' -> Multi-layer perceptron\n",
    "    \n",
    "    add_original_input : If original data is to be added to the input at the stack layer \n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    \n",
    "    chosen_base_models : list of base estimator objects as chosen\n",
    "    \n",
    "    final_model : the final stack layer model\n",
    "    \n",
    "    criteria : the type of output used to train the stacked layer\n",
    "    \n",
    "    correlation_hash : contains predicted values of each base estimator to calculate diversity among them\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = SuperLearnerClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    global LIST_OF_MODELS\n",
    "    # This global variable contains default set of base estimators if nothing is passed as parameter\n",
    "    LIST_OF_MODELS = ('CART', 'RF', 'NB', 'KNN', 'LR', 'MLP')\n",
    "    \n",
    "    # SuperLearner constructor takes these arguments as parameters with default values if nothing is specified\n",
    "    def __init__(self, criteria = 'label', stacked_model= 'CART', base_models = LIST_OF_MODELS, add_original_input = False):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        criteria : string like, among 'label' or 'probability'\n",
    "    \n",
    "        stacked_model : string like, indicates type of model - according to global values from LIST_OF_MODELS\n",
    "    \n",
    "        base_models : array-like, list of strings indicating type of model - according to global values from LIST_OF_MODELS\n",
    "    \n",
    "        add_original_input : Boolean\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \n",
    "        \"\"\"          \n",
    "        # Dictionary of sensible set of hyper-parameters created from previously done grid search on base estimators\n",
    "        best_hyperparams_found = {'CART': DecisionTreeClassifier(criterion= 'entropy', max_depth= 6, min_samples_split= 25),\\\n",
    "                        'RF': RandomForestClassifier(max_features= 4, min_samples_split= 25, n_estimators= 400),\\\n",
    "                        'LR': LogisticRegression(C= 0.2, max_iter= 1000, multi_class= 'ovr', solver= 'liblinear'),\\\n",
    "                        'NB': GaussianNB(),\\\n",
    "                        'KNN': KNeighborsClassifier(n_neighbors= 6),\\\n",
    "                        'MLP': MLPClassifier(alpha= 1e-05, hidden_layer_sizes= (400, 200), solver='lbfgs', activation='logistic')}\n",
    "            \n",
    "        # Use this set of sensible hyper-parameters\n",
    "        __stacked_model_dict__ = {'CART': best_hyperparams_found['CART'],\\\n",
    "                                  'LR': best_hyperparams_found['LR'],\\\n",
    "                                  'RF' : best_hyperparams_found['RF'], \\\n",
    "                                  'NB': best_hyperparams_found['NB'], \\\n",
    "                                  'KNN': best_hyperparams_found['KNN'], \\\n",
    "                                  'MLP': best_hyperparams_found['MLP']}\n",
    "        \n",
    "        \n",
    "#         __stacked_model_dict__ = {'CART': DecisionTreeClassifier(), 'LR': LogisticRegression(), 'RF' : RandomForestClassifier(), \\\n",
    "#                                   'NB': GaussianNB(), 'KNN': KNeighborsClassifier(), 'MLP': MLPClassifier(solver='lbfgs')}\n",
    "        \n",
    "        __base_model_dict__ = copy.deepcopy(__stacked_model_dict__ )\n",
    "        \n",
    "        self.base_models = base_models  #This is used in cross_val_score() which clones the object\n",
    "        self.stacked_model = stacked_model #This is used in cross_val_score() which clones the object\n",
    "\n",
    "        # Exception handling to ensure correct base estimators and stacked layer model is entered\n",
    "        try:\n",
    "            if len(stacked_model) < 0:\n",
    "                raise ValueError\n",
    "            final_model = __stacked_model_dict__[stacked_model]\n",
    "        except ValueError:\n",
    "            print(\"Please enter minimum 1 stacked model estimator\")\n",
    "            sys.exit(0)\n",
    "        except KeyError:\n",
    "            print(\"Please enter a valid stack model among {}\".format(list(__stacked_model_dict__.keys())))\n",
    "            sys.exit(0)\n",
    "        \n",
    "        # Final stack layer model\n",
    "        self.final_model = final_model\n",
    "       \n",
    "        try:\n",
    "            if len(base_models) < 3  or len(base_models) > 10:\n",
    "                raise ValueError\n",
    "            chosen_base_models = [__base_model_dict__[i] for i in self.base_models]\n",
    "            self.chosen_base_models = chosen_base_models # Each base estimator\n",
    "        except ValueError:\n",
    "            print(\"Please enter minimum 3 base estimators and max 10 base estimators\")\n",
    "            sys.exit(0) \n",
    "        except KeyError:\n",
    "            print(\"Please enter a valid base estimators among {}\".format(list(__base_model_dict__.keys())))\n",
    "            sys.exit(0) \n",
    "\n",
    "        # Criteria - label or probability\n",
    "        self.criteria = criteria\n",
    "        self.add_original_input = add_original_input\n",
    "\n",
    "        # To check diversity among base estimators\n",
    "        self.correlation_hash = {}\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"     \n",
    "        \n",
    "        # As described V-fold in the description of SuperLearner\n",
    "        k_fold = 10\n",
    "\n",
    "        #Split the original dataset into K folds\n",
    "        split_X = np.array_split(X, k_fold)\n",
    "        split_y = np.array_split(y, k_fold)\n",
    "        \n",
    "        stacked_list = list()\n",
    "        \n",
    "        for i in range(k_fold):\n",
    "            # Segregating training and test set using splitted array for both X and y\n",
    "            X_test = split_X[i].tolist()\n",
    "            \n",
    "            X_train = [ split_X[j].tolist() for j in range(k_fold) if i!= j]\n",
    "            # Flattening the X_train to 1-D list\n",
    "            X_train = list(itertools.chain.from_iterable(X_train))\n",
    "\n",
    "            y_test = split_y[i].tolist()\n",
    "            y_train = [ split_y[j].tolist() for j in range(k_fold) if i!= j]\n",
    "            y_train = list(itertools.chain.from_iterable(y_train))\n",
    "\n",
    "            y_pred_list = list()\n",
    "            \n",
    "            #Iterate for each base estimator\n",
    "            for model in self.chosen_base_models:\n",
    "                # Fit each base estimator\n",
    "                model.fit(X_train , y_train)\n",
    "                # If criteria is label use predict else predict_proba\n",
    "                y_pred = model.predict(X_test) if self.criteria == \"label\" else model.predict_proba(X_test)\n",
    "                # Append it to as list that can be used as input to the stacked layer\n",
    "                y_pred_list.append(y_pred)\n",
    "                \n",
    "                \n",
    "                # -----TASK 9 -----\n",
    "                self.y = y\n",
    "                if self.criteria == \"label\":\n",
    "                    # To evaluate correlation between base estimators only in case of label outputs\n",
    "                    if str(model.__class__.__name__) not in self.correlation_hash.keys():\n",
    "                        self.correlation_hash[str(model.__class__.__name__)] = y_pred.tolist()\n",
    "                    else:\n",
    "                        self.correlation_hash[str(model.__class__.__name__)].extend(y_pred.tolist())\n",
    "\n",
    "            \n",
    "            # Using column stack on the appended list so that the input training set for stacked layer is of proper shape\n",
    "            stacked_list.append(np.column_stack(y_pred_list).tolist())\n",
    "        \n",
    "        #Converting stacked_list to 1-D flattened list\n",
    "        stacked_list = list(itertools.chain.from_iterable(stacked_list))\n",
    "\n",
    "        if self.add_original_input:\n",
    "            # Add the original input to the final list of training data for stacked layer\n",
    "            stacked_list = np.column_stack((X,stacked_list)) \n",
    "        \n",
    "        self.final_model.fit(stacked_list, y)\n",
    "        \n",
    "        for model in self.chosen_base_models:\n",
    "            # Fitting each model with entire dataset\n",
    "            model.fit(X,y)\n",
    "            \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        stacked_list = list()\n",
    "        y_pred_list = list()\n",
    "        for model in self.chosen_base_models:\n",
    "            # Predict for each base estimator if criteria is label and append it to a list\n",
    "            y_pred = model.predict(X) if self.criteria == \"label\" else model.predict_proba(X)\n",
    "            y_pred_list.append(y_pred)\n",
    "\n",
    "        # Then append the entire list as a column stack to another list to be used at the stacked layer\n",
    "        stacked_list.append(np.column_stack(y_pred_list).tolist())\n",
    "        stacked_list = list(itertools.chain.from_iterable(stacked_list))\n",
    "\n",
    "        if self.add_original_input:\n",
    "            # Add the original input to the final list of training data for stacked layer\n",
    "            stacked_list = np.column_stack((X,stacked_list))\n",
    "        \n",
    "        # Finally predict at the stacked layer\n",
    "        y_pred = self.final_model.predict(stacked_list)\n",
    "            \n",
    "        return y_pred\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        stacked_list = list()\n",
    "        y_pred_list = list()\n",
    "        for model in self.chosen_base_models:\n",
    "            # Predict_proba for each base estimator if criteria is probability and append it to a list\n",
    "            y_pred = model.predict_proba(X) if self.criteria != \"label\" else model.predict(X)\n",
    "            y_pred_list.append(y_pred)\n",
    "        \n",
    "        # Then append the entire list as a column stack to another list to be used at the stacked layer\n",
    "        stacked_list.append(np.column_stack(y_pred_list).tolist())\n",
    "        stacked_list = list(itertools.chain.from_iterable(stacked_list))\n",
    "        \n",
    "        if self.add_original_input:\n",
    "            # Add the original input to the final list of training data for stacked layer\n",
    "            stacked_list = np.column_stack((X,stacked_list))\n",
    "            \n",
    "        # Finally predict_proba at the stacked layer\n",
    "        y_pred = self.final_model.predict_proba(stacked_list)\n",
    "            \n",
    "        return y_pred\n",
    "        \n",
    "    \n",
    "    # ------------------------------ TASK 9 ---------------------------\n",
    "    \"\"\"\n",
    "    This function calculates Accuracy among the base estimators using accuracy metric\n",
    "    and the diversity among them using Disagreement measure.\n",
    "    \n",
    "    It also displays the Pearson-R correlation matrix among base estimators\n",
    "    and plots the pandas dataframe using a scatter matrix plot\n",
    "    \n",
    "    \n",
    "    Calculating disagreement measure among base estimators of SuperLearner using the formula for disagreement measure\n",
    "    as stated in the Paper [2].\n",
    "    \n",
    "    See also: [2] https://link.springer.com/content/pdf/10.1023%2FA%3A1022859003006.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    def check_accuracy(self):\n",
    "        if self.criteria != \"label\":\n",
    "            raise ValueError(\"Please enter only label type output in the SuperLearner\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n******************** Accuracy (Predictive power) of each base estimator ***********\")\n",
    "        acc_hash = {}\n",
    "        # To evaluate accuracy between base estimators\n",
    "        for model_i in self.chosen_base_models:\n",
    "            y_pred = self.correlation_hash[model_i.__class__.__name__]\n",
    "            accuracy = metrics.accuracy_score(self.y, y_pred)\n",
    "            acc_hash[model_i.__class__.__name__] = accuracy\n",
    "        display(pd.Series(acc_hash))\n",
    "\n",
    "        \n",
    "    def check_diversity(self):\n",
    "        \"\"\"\n",
    "            Calculating Disagreement measure and Pearson-R correlation measure.\n",
    "            N11 - number of Test Examples correctly classified by both classifiers\n",
    "            N00 - number of Test Examples incorrectly classified by both classifiers\n",
    "            N10 - number of Test Examples correctly classified by 1st classifier but incorrectly by 2nd classifier\n",
    "            N01 - number of Test Examples incorrectly classified by 1st classifier but correctly by 2nd classifier\n",
    "            \n",
    "            Disagreement measure = (N01 + N10) / (N11 + N00 + N10 + N01)\n",
    "            \n",
    "            Pearson R measure is calculated by using corr() function in pandas dataframe.\n",
    "            \n",
    "        \"\"\"\n",
    "        # Dataframe used for plotting y_pred values and Pearson correlation\n",
    "        plot_df = pd.DataFrame()\n",
    "        diversity_hash = {}\n",
    "        __dict_classfier_code__ = {'DecisionTreeClassifier': 'CART', 'RandomForestClassifier': 'RF',\\\n",
    "                                           'GaussianNB': 'NB', 'KNeighborsClassifier': 'KNN',\\\n",
    "                                           'LogisticRegression':'LR', 'MLPClassifier': 'MLP'}\n",
    "\n",
    "        try:\n",
    "            # Take every combination of base estimators and calculate disagreement measure among them\n",
    "            for model_i in self.chosen_base_models:\n",
    "                div_list = list()\n",
    "                for model_j in self.chosen_base_models:\n",
    "                    y_pred1 = self.correlation_hash[model_i.__class__.__name__]\n",
    "                    y_pred2 = self.correlation_hash[model_j.__class__.__name__]\n",
    "                    # Store y_preds in a pandas dataframe for visualisation\n",
    "                    plot_df[__dict_classfier_code__[model_i.__class__.__name__]] = y_pred1\n",
    "                    plot_df[__dict_classfier_code__[model_j.__class__.__name__]] = y_pred2\n",
    "\n",
    "                    N11, N00, N10, N01 = 0,0,0,0\n",
    "\n",
    "                    # Calculate the disagreement rate among the base estimators\n",
    "                    for i in range(len(Y_train)):\n",
    "                        if Y_train[i] == y_pred1[i] and Y_train[i] == y_pred2[i]:\n",
    "                            N11 += 1\n",
    "                        elif Y_train[i] != y_pred1[i] and Y_train[i] != y_pred2[i]:\n",
    "                            N00 += 1\n",
    "                        elif Y_train[i] == y_pred1[i] and Y_train[i] != y_pred2[i]:\n",
    "                            N10 += 1\n",
    "                        elif Y_train[i] != y_pred1[i] and Y_train[i] == y_pred2[i]:\n",
    "                            N01 += 1\n",
    "\n",
    "                    disagreement = (N01 + N10) / (N11 + N00 + N10 + N01)\n",
    "#                     print(\"Disagreement between %s and %s is %.2f\" % (__dict_classfier_code__[model_i.__class__.__name__],__dict_classfier_code__[model_j.__class__.__name__], disagreement))\n",
    "                    div_list.append(disagreement)\n",
    "                \n",
    "                diversity_hash[__dict_classfier_code__[model_i.__class__.__name__]] = div_list\n",
    "\n",
    "            # Display disagreement measure among base estimators\n",
    "            print(\"\\n******************** Disagreement (Heterogenity) measure  ***********\")\n",
    "            display(pd.DataFrame(collections.OrderedDict(diversity_hash), index=diversity_hash.keys()))\n",
    "            # Display the Pearson R correlation among base estimators\n",
    "            print(\"\\n******************** Pearson-R correlation scores ***********\")\n",
    "            display(plot_df.corr())\n",
    "            \n",
    "            # Plotting the Pandas dataframe using a scatter matrix to visualise each base estimator's target label with others\n",
    "            print(\"\\n******************** Pandas scatter plot of y_pred values for each base estimator ***********\")\n",
    "            pd.plotting.scatter_matrix(df, figsize=(8, 8))\n",
    "            plt.show()\n",
    "            \n",
    "    \n",
    "        except KeyError:\n",
    "            print(\"Please fit the model OR use label outputs in the model before checking for diversity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the SuperLearnerClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the SuperLearnClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9733333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       1.00      0.92      0.96        50\n",
      "          2       0.93      1.00      0.96        50\n",
      "\n",
      "avg / total       0.98      0.97      0.97       150\n",
      "\n",
      "[1.         0.93333333 1.         0.93333333 0.86666667 0.93333333\n",
      " 0.86666667 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Testing the basic version of SuperLearner on IRIS dataset with both label and probability outputs\n",
    "clf = SuperLearnerClassifier()\n",
    "iris = load_iris()\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "y_pred_proba = clf.predict_proba(iris.data)\n",
    "\n",
    "if clf.criteria == \"label\":\n",
    "    y_pred = clf.predict(iris.data)\n",
    "    accuracy = metrics.accuracy_score(iris.target, y_pred) \n",
    "    print(\"Accuracy: \" +  str(accuracy))\n",
    "    print(metrics.classification_report(iris.target, y_pred))\n",
    "    # Evaluating 10-fold CV \n",
    "    print(cross_val_score(clf, iris.data, iris.target, cv=10))\n",
    "else:\n",
    "    y_pred = clf.predict_proba(iris.data)\n",
    "    # Evaluating 10-fold CV \n",
    "    print(cross_val_predict(clf, iris.data, iris.target, cv=10, method='predict_proba'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the number of folds for all grid searches (should be 5 - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_folds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15327</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>194</td>\n",
       "      <td>198</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38074</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18473</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21627</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "46612      0       0       0       0       0       0       0       0       0   \n",
       "15327      4       0       0       0       0       0       0       0       0   \n",
       "38074      6       0       0       3       1       1       0       0       0   \n",
       "18473      3       0       0       0       0       0       0       0       0   \n",
       "21627      0       0       0       0       0       1       0       0       0   \n",
       "\n",
       "       pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "46612       0    ...            3         0        78        36         0   \n",
       "15327       0    ...            3         0         4       192       194   \n",
       "38074      50    ...          132       110        80        68         2   \n",
       "18473       1    ...           12         7         0         0         0   \n",
       "21627       0    ...           64        73        10         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "46612         0         0         0         0         0  \n",
       "15327       198       140         0         0         0  \n",
       "38074         0         3         1         1         0  \n",
       "18473         0         0         0         0         0  \n",
       "21627         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "num_classes = 10\n",
    "classes = {0: \"T-shirt/top\", 1:\"Trouser\", 2: \"Pullover\", 3:\"Dress\", 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "display(dataset.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform data pre-processing and manipulation as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    322\n",
       "0    319\n",
       "6    308\n",
       "3    307\n",
       "2    304\n",
       "5    303\n",
       "9    297\n",
       "1    283\n",
       "7    279\n",
       "4    278\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.00000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.00000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.496333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>0.130333</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.461667</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>2.346333</td>\n",
       "      <td>5.686000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.033333</td>\n",
       "      <td>23.684667</td>\n",
       "      <td>17.620333</td>\n",
       "      <td>18.011333</td>\n",
       "      <td>22.36600</td>\n",
       "      <td>17.860000</td>\n",
       "      <td>8.844333</td>\n",
       "      <td>3.094333</td>\n",
       "      <td>0.98500</td>\n",
       "      <td>0.060667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.890578</td>\n",
       "      <td>0.036515</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>0.218943</td>\n",
       "      <td>3.326214</td>\n",
       "      <td>4.472495</td>\n",
       "      <td>6.104666</td>\n",
       "      <td>9.011821</td>\n",
       "      <td>14.216859</td>\n",
       "      <td>24.200977</td>\n",
       "      <td>...</td>\n",
       "      <td>58.140207</td>\n",
       "      <td>49.232901</td>\n",
       "      <td>42.738933</td>\n",
       "      <td>43.523687</td>\n",
       "      <td>50.56536</td>\n",
       "      <td>44.269218</td>\n",
       "      <td>30.205456</td>\n",
       "      <td>19.394694</td>\n",
       "      <td>10.11584</td>\n",
       "      <td>1.518471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>255.00000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>214.00000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       pixel1       pixel2       pixel3       pixel4  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean      4.496333     0.000667     0.003667     0.020333     0.130333   \n",
       "std       2.890578     0.036515     0.083600     0.218943     3.326214   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       5.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       9.000000     2.000000     3.000000     6.000000   150.000000   \n",
       "\n",
       "            pixel5       pixel6       pixel7       pixel8       pixel9  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean      0.239000     0.461667     0.896000     2.346333     5.686000   \n",
       "std       4.472495     6.104666     9.011821    14.216859    24.200977   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max     166.000000   190.000000   188.000000   215.000000   242.000000   \n",
       "\n",
       "          ...          pixel775     pixel776     pixel777     pixel778  \\\n",
       "count     ...       3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean      ...         35.033333    23.684667    17.620333    18.011333   \n",
       "std       ...         58.140207    49.232901    42.738933    43.523687   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...         60.000000    12.000000     0.000000     0.000000   \n",
       "max       ...        246.000000   236.000000   246.000000   249.000000   \n",
       "\n",
       "         pixel779     pixel780     pixel781     pixel782    pixel783  \\\n",
       "count  3000.00000  3000.000000  3000.000000  3000.000000  3000.00000   \n",
       "mean     22.36600    17.860000     8.844333     3.094333     0.98500   \n",
       "std      50.56536    44.269218    30.205456    19.394694    10.11584   \n",
       "min       0.00000     0.000000     0.000000     0.000000     0.00000   \n",
       "25%       0.00000     0.000000     0.000000     0.000000     0.00000   \n",
       "50%       0.00000     0.000000     0.000000     0.000000     0.00000   \n",
       "75%       1.00000     0.000000     0.000000     0.000000     0.00000   \n",
       "max     255.00000   235.000000   219.000000   238.000000   214.00000   \n",
       "\n",
       "          pixel784  \n",
       "count  3000.000000  \n",
       "mean      0.060667  \n",
       "std       1.518471  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max      56.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add code here\n",
    "# Some data visualisation\n",
    "display(dataset[\"label\"].value_counts())\n",
    "\n",
    "if(dataset.select_dtypes(include=[np.number]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.number]).describe())\n",
    "if(dataset.select_dtypes(include=[np.object]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.object]).describe())\n",
    "\n",
    "X = dataset[dataset.columns[1:]].values\n",
    "X = X/255\n",
    "Y = np.array(dataset[\"label\"])\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, stratify=Y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate a Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Super Learner Classifier using the prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the stack layer model : 'CART', 'LR', 'RF', 'NB', 'KNN', 'MLP' \n",
      "cart\n",
      "----Fitting the classifier using DecisionTreeClassifier------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(add_original_input=False,\n",
       "            base_models=('CART', 'RF', 'NB', 'KNN', 'LR', 'MLP'),\n",
       "            criteria='label', stacked_model='CART')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code here\n",
    "# Enter the stacked layer model as a string\n",
    "\n",
    "\"\"\"\n",
    "    While creating the SuperLearner object, if we pass criteria=\"probability\" then it will train stacked layer with \n",
    "    probability outputs from base estimators using SuperLearner's predict_proba method\n",
    "\"\"\"\n",
    "x = input(\"Enter the stack layer model : 'CART', 'LR', 'RF', 'NB', 'KNN', 'MLP' \\n\").upper().strip()\n",
    "clf = SuperLearnerClassifier(stacked_model = x)\n",
    "print(\"----Fitting the classifier using {}------\".format(clf.final_model.__class__.__name__))\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7733333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.72      0.75        64\n",
      "          1       0.90      0.95      0.92        57\n",
      "          2       0.56      0.67      0.61        61\n",
      "          3       0.85      0.87      0.86        61\n",
      "          4       0.65      0.70      0.67        56\n",
      "          5       0.87      0.90      0.89        60\n",
      "          6       0.43      0.32      0.37        62\n",
      "          7       0.88      0.79      0.83        56\n",
      "          8       0.91      0.92      0.91        64\n",
      "          9       0.87      0.92      0.89        59\n",
      "\n",
      "avg / total       0.77      0.77      0.77       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>73</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          46   1   1   3   0   0  12   0   1   0   64\n",
       "1           0  54   0   0   0   0   2   0   1   0   57\n",
       "2           1   1  41   2  12   0   4   0   0   0   61\n",
       "3           0   2   2  53   2   0   1   0   1   0   61\n",
       "4           0   0  11   1  39   0   5   0   0   0   56\n",
       "5           1   0   1   0   0  54   0   1   0   3   60\n",
       "6          11   2  16   2   7   0  20   1   3   0   62\n",
       "7           0   0   0   0   0   7   0  44   0   5   56\n",
       "8           0   0   1   1   0   0   3   0  59   0   64\n",
       "9           0   0   0   0   0   1   0   4   0  54   59\n",
       "All        59  60  73  62  60  62  47  50  65  62  600"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code here\n",
    "# Using X_valid to evaluate the trained SuperLearner\n",
    "y_pred = clf.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(Y_valid, y_pred)\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "# Print the classification report including Precision, Recall, F1 score and Support\n",
    "print(metrics.classification_report(Y_valid, y_pred))\n",
    "# Display the confusion matrix\n",
    "pd.crosstab(np.array(Y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Experiment (Task 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a 10-fold cross validation experiment to evaluate the performance of the SuperLearnerClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores are [0.76734694 0.77142857 0.80327869 0.78099174 0.79079498 0.77824268\n",
      " 0.80252101 0.77310924 0.77446809 0.74042553]\n",
      "\n",
      "Mean is 0.778261 and Standard deviation is 0.017370\n"
     ]
    }
   ],
   "source": [
    "# 10-fold CV performed on the trained SuperLearner\n",
    "scores = cross_val_score(clf, X_train, Y_train, cv=10)\n",
    "print(\"Cross validation scores are {}\".format(scores))\n",
    "print(\"\\nMean is %f and Standard deviation is %f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Performance of Different Stack Layer Approaches (Task 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance of the ensemble when a label based stack layer training set and a probability based stack layer training set is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_accuracy_comparison(model_valid_accuracy_comparisons):\n",
    "    plt.xlim(0, 1.0)\n",
    "    _ = plt.barh(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.values()), align='center')\n",
    "    _= plt.yticks(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Label with Decision tree----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "      <td>35</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          50   0   1   3   2   0   6   0   2   0   64\n",
       "1           0  54   1   1   0   0   0   0   1   0   57\n",
       "2           1   1  48   1   7   0   3   0   0   0   61\n",
       "3           1   2   4  51   2   0   1   0   0   0   61\n",
       "4           0   1   8   5  39   0   3   0   0   0   56\n",
       "5           0   1   1   0   0  52   0   3   0   3   60\n",
       "6           9   1  15   2  11   0  21   0   3   0   62\n",
       "7           0   0   0   0   0   5   0  48   0   3   56\n",
       "8           2   0   1   2   0   0   1   0  58   0   64\n",
       "9           0   0   0   0   0   0   0   6   0  53   59\n",
       "All        63  60  79  65  61  57  35  57  64  59  600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Label with Logistic regression----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>44</td>\n",
       "      <td>82</td>\n",
       "      <td>55</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>63</td>\n",
       "      <td>46</td>\n",
       "      <td>43</td>\n",
       "      <td>59</td>\n",
       "      <td>89</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          21  26   1   2   0   2   9   0   3   0   64\n",
       "1           3  51   1   1   0   0   0   0   1   0   57\n",
       "2           5   2  22  21   4   3   3   0   1   0   61\n",
       "3           6   1   8  43   1   0   2   0   0   0   61\n",
       "4           0   0  14  24   7   2   8   0   1   0   56\n",
       "5           0   0   0   0  10  37   1   8   3   1   60\n",
       "6           9   2   9   4   2   3  22   0  11   0   62\n",
       "7           0   0   0   0   0  11   0  34   7   4   56\n",
       "8           0   0   0   0   0   2   1   0  28  33   64\n",
       "9           0   0   0   0   0   3   0   1   4  51   59\n",
       "All        44  82  55  95  24  63  46  43  59  89  600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Probability with Decision tree----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          43   0   0   4   0   2  12   1   2   0   64\n",
       "1           0  55   1   0   0   0   1   0   0   0   57\n",
       "2           2   2  28   1  16   0  11   0   1   0   61\n",
       "3           0   3   2  49   1   0   5   0   1   0   61\n",
       "4           1   1  14   4  31   0   5   0   0   0   56\n",
       "5           0   0   0   0   0  54   0   4   0   2   60\n",
       "6           9   0  11   4  13   1  24   0   0   0   62\n",
       "7           0   0   0   0   0   6   0  46   0   4   56\n",
       "8           2   0   3   0   0   0   1   0  58   0   64\n",
       "9           0   0   0   0   0   1   0   5   0  53   59\n",
       "All        57  61  59  62  61  64  59  56  62  59  600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Probability with Logistic Regression------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>69</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          51   0   0   3   0   0   9   0   1   0   64\n",
       "1           0  55   2   0   0   0   0   0   0   0   57\n",
       "2           2   0  46   1   9   0   3   0   0   0   61\n",
       "3           1   0   1  55   3   0   1   0   0   0   61\n",
       "4           0   0   6   4  45   0   1   0   0   0   56\n",
       "5           0   0   0   0   0  54   0   2   0   4   60\n",
       "6           7   0  14   3   7   0  30   0   1   0   62\n",
       "7           0   0   0   0   0   2   0  48   0   6   56\n",
       "8           0   0   0   1   0   0   2   0  61   0   64\n",
       "9           0   0   0   0   0   2   0   2   0  55   59\n",
       "All        61  55  69  67  64  58  46  52  63  65  600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Decision Tree Label : Accuracy 0.790000\n",
      "Classifier Logistic Regression Label : Accuracy 0.526667\n",
      "Classifier Decision Tree Probability : Accuracy 0.735000\n",
      "Classifier Logistic Regression Probability : Accuracy 0.833333\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAD8CAYAAADnntf1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ4EkSQLg/wE2DPIU+12UgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b12b4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add code here\n",
    "# Comparing 4 combinations of {Label, Probability} outputs with {Logistic Regression, Decision Tree} as the stacked layer model\n",
    "model_valid_accuracy_comparisons = {}\n",
    "clf = SuperLearnerClassifier(criteria=\"label\")\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(Y_valid, y_pred)\n",
    "print(\"------ Label with Decision tree----\")\n",
    "display(pd.crosstab(np.array(Y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "model_valid_accuracy_comparisons[\"Decision Tree Label\"] = accuracy\n",
    "\n",
    "clf_2 = SuperLearnerClassifier(criteria=\"label\",stacked_model = 'LR')\n",
    "clf_2.fit(X_train, Y_train)\n",
    "y_pred = clf_2.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(Y_valid, y_pred)\n",
    "print(\"------ Label with Logistic regression----\")\n",
    "display(pd.crosstab(np.array(Y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "model_valid_accuracy_comparisons[\"Logistic Regression Label\"] = accuracy\n",
    "\n",
    "clf_proba = SuperLearnerClassifier(criteria=\"probability\")\n",
    "clf_proba.fit(X_train, Y_train)\n",
    "y_pred = clf_proba.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(Y_valid, y_pred)\n",
    "print(\"------ Probability with Decision tree----\")\n",
    "display(pd.crosstab(np.array(Y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "model_valid_accuracy_comparisons[\"Decision Tree Probability\"] = accuracy\n",
    "\n",
    "clf_proba_2 = SuperLearnerClassifier(criteria=\"probability\", stacked_model='LR')\n",
    "clf_proba_2.fit(X_train, Y_train)\n",
    "y_pred = clf_proba_2.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(Y_valid, y_pred)\n",
    "print(\"------ Probability with Logistic Regression------\")\n",
    "display(pd.crosstab(np.array(Y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "model_valid_accuracy_comparisons[\"Logistic Regression Probability\"] = accuracy\n",
    "\n",
    "#Plotting the comparison and display each one's accuracy\n",
    "show_accuracy_comparison(model_valid_accuracy_comparisons)\n",
    "for key, value in model_valid_accuracy_comparisons.items():\n",
    "    print(\"Classifier %s : Accuracy %f\"  % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Specify the base estimators to use (Task 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the base estimator models (seperated by space) : 'CART', 'LR', 'RF', 'NB', 'KNN', 'MLP' \n",
      "CART LR RF NB KNN MLP\n",
      "Accuracy is  0.8133333333333334\n"
     ]
    }
   ],
   "source": [
    "\"\"\" ******* Finally the accuracy comes out to be around 81%\n",
    "    when we use 6 base estimators with label outputs and stacked layer decision tree\n",
    "    The 6 base estimators will be using the sensible set of hyper-parameters as was calculated initially\n",
    "    using Grid Search on individual base estimators.\n",
    "    The number of base estimators can vary between 3-10 as an input here.\n",
    "\"\"\"\n",
    "# Entering the list of base estimators to be used as a list of strings seperated by spaces\n",
    "my_list = input(\"Enter the base estimator models (seperated by space) : 'CART', 'LR', 'RF', 'NB', 'KNN', 'MLP' \\n\").upper().strip()\n",
    "list_of_models = my_list.split(' ')\n",
    "\n",
    "clf = SuperLearnerClassifier(criteria=\"label\",stacked_model = 'CART', base_models = tuple(list_of_models))\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(Y_valid, y_pred)\n",
    "print(\"Accuracy is \", accuracy)\n",
    "\n",
    "# cross_val_score(clf, X_train, Y_train, cv=cv_folds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Through SuperLearnerClassifier Architectures & Parameters (Task 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a grid search experiment to determine the optimal architecture and hyper-parameter values for the SuperLearnClasssifier for the MNIST Fashion classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=SuperLearnerClassifier(add_original_input=False,\n",
       "            base_models=('CART', 'RF', 'NB', 'KNN', 'LR', 'MLP'),\n",
       "            criteria='label', stacked_model='CART'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'criteria': ['label', 'probability'], 'base_models': [('CART', 'KNN', 'NB'), ('LR', 'RF', 'KNN'), ('LR', 'CART', 'NB')], 'stacked_model': ['CART', 'LR']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_models': ('LR', 'RF', 'KNN'),\n",
       " 'criteria': 'label',\n",
       " 'stacked_model': 'CART'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7020833333333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add code here\n",
    "\"\"\"  *****We find that Grid Search best accuracy comes out to be ~70%, this reduction is because we are just using \n",
    "     3 base estimators and giving 3 different combinations of those 3 estimators. Earlier we used 6 base estimators \n",
    "     and we received 81% accuracy. If we try to increase the base_models in param_grid to 5-6 estimators, grid search\n",
    "     will give better accuracy and the best parameters found of the set will change accordingly.\n",
    "     \n",
    "     Best base estimators are found to be : Logistic regression, Random forest, K-NN which is quite good because \n",
    "     they are quite less correlated to each other so it maintains the diversity and heterogenity among base models\n",
    "     in the SuperLearner.\n",
    "     \n",
    "     Decision Tree at the stacked layer with Label type output for base estimators are the best options as\n",
    "     found by the GridSearch\n",
    "\"\"\"\n",
    "# ****** GRID Search on SuperLearner ******\n",
    "param_grid ={'criteria': ['label','probability'], \\\n",
    "             'base_models': [('CART', 'KNN', 'NB'),\\\n",
    "                             ('LR', 'RF', 'KNN'),\\\n",
    "                             ('LR', 'CART', 'NB')], \\\n",
    "             'stacked_model': ['CART', 'LR']}\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(SuperLearnerClassifier(), param_grid, cv=2)\n",
    "my_tuned_model.fit(X_train, Y_train)\n",
    "\n",
    "display(my_tuned_model)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_model.best_params_)\n",
    "display(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the model selected by the grid search on a hold-out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after Grid Search on MNIST Training set is  0.6916666666666667\n",
      "Accuracy after Grid Search on MNIST Test set is  0.7041\n"
     ]
    }
   ],
   "source": [
    "# Add code here\n",
    "#***************** Evaluating on the validation set ******************\n",
    "y_pred = my_tuned_model.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(Y_valid, y_pred)\n",
    "print(\"Accuracy after Grid Search on MNIST Training set is \", accuracy)\n",
    "# print(cross_val_score(my_tuned_model, X.values, Y, cv=cv_folds))\n",
    "\n",
    "\n",
    "#***************** Evaluating on the Fashion MNIST Test set ******************\n",
    "\n",
    "# LOAD the MNIST Test dataset\n",
    "_test_dataset = pd.read_csv('fashion-mnist_test.csv')\n",
    "\n",
    "X_test = _test_dataset[_test_dataset.columns[1:]].values\n",
    "X_test = X_test/255\n",
    "Y_test = np.array(_test_dataset[\"label\"])\n",
    "y_test_pred = my_tuned_model.predict(X_test)\n",
    "accuracy_test = metrics.accuracy_score(Y_test, y_test_pred)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    We conclude that after running model with best params found in Grid Search, we get an \n",
    "    accuracy of ~72%. On testing it on the MNIST test dataset, we find that accuracy is ~73%.\n",
    "\"\"\"\n",
    "print(\"Accuracy after Grid Search on MNIST Test set is \", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Impact of Adding Original Descriptive Features at the Stack Layer (Task 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the impact of adding original descriptive features at the stack layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before adding Original Input to the Stack layer is  0.7383333333333333\n",
      "Accuracy after adding Original Input to the Stack layer is  0.7216666666666667\n"
     ]
    }
   ],
   "source": [
    "# Add code here\n",
    "\"\"\"\n",
    "    We see that after adding Original input to the Stack layer (using best parameters found from grid search),\n",
    "    there is a slight reduction of accuracy(from ~74 to ~72%). This may be possible due to `curse of dimensionality`, \n",
    "    wherein the accuracy tends to fall after reaching the peak as the number of features keep increasing.\n",
    "    Since the dataset itself contained 784 columns, adding it to the output of base estimators increased the\n",
    "    number of features exorbitantly which resulted in drop in the accuracy of the model \n",
    "\"\"\"\n",
    "# Using the best params found from Grid Search in Task 7 to evaluate the validation set\n",
    "best_params_found = my_tuned_model.best_params_\n",
    "criteria,stacked_model, base_models = best_params_found['criteria'], best_params_found['stacked_model'], best_params_found['base_models']\n",
    "original_input_stack_model_accuracy_comparisons = {}\n",
    "roc_curve = []\n",
    "clf = SuperLearnerClassifier(criteria=criteria, stacked_model=stacked_model, base_models= base_models)\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(Y_valid, y_pred)\n",
    "original_input_stack_model_accuracy_comparisons[clf.criteria.upper() + ' ' + (clf.final_model.__class__.__name__) + ' Without Original Input'] = accuracy\n",
    "print(\"Accuracy before adding Original Input to the Stack layer is \", accuracy)\n",
    "\n",
    "# Now repeating the same and also adding the original input to the stack layer\n",
    "clf_with_original_input = SuperLearnerClassifier(criteria=criteria,stacked_model = stacked_model, base_models = base_models, add_original_input = True)\n",
    "clf_with_original_input.fit(X_train, Y_train)\n",
    "y_pred = clf_with_original_input.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(Y_valid, y_pred)\n",
    "print(\"Accuracy after adding Original Input to the Stack layer is \", accuracy)\n",
    "original_input_stack_model_accuracy_comparisons[clf.criteria.upper() + ' ' + (clf.final_model.__class__.__name__) + ' With Original Input'] = accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApAAAAD8CAYAAADAHJRYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11481bf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparison of the accuracies by plotting \n",
    "show_accuracy_comparison(original_input_stack_model_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Ensemble Model (Task 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform an analysis to investigate the strength of the base estimators and the strengths of the correlations between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************** Accuracy (Predictive power) of each base estimator ***********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier    0.699583\n",
       "GaussianNB                0.506250\n",
       "KNeighborsClassifier      0.778750\n",
       "LogisticRegression        0.806667\n",
       "MLPClassifier             0.792500\n",
       "RandomForestClassifier    0.785417\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************** Disagreement (Heterogenity) measure  ***********\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>RF</th>\n",
       "      <th>NB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CART</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.234583</td>\n",
       "      <td>0.256250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.151250</td>\n",
       "      <td>0.179583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.394583</td>\n",
       "      <td>0.407083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167083</td>\n",
       "      <td>0.179583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.234583</td>\n",
       "      <td>0.151250</td>\n",
       "      <td>0.394583</td>\n",
       "      <td>0.167083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.256250</td>\n",
       "      <td>0.179583</td>\n",
       "      <td>0.407083</td>\n",
       "      <td>0.179583</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CART        RF        NB       KNN        LR       MLP\n",
       "CART  0.000000  0.216667  0.400000  0.240000  0.234583  0.256250\n",
       "RF    0.216667  0.000000  0.392500  0.165000  0.151250  0.179583\n",
       "NB    0.400000  0.392500  0.000000  0.382500  0.394583  0.407083\n",
       "KNN   0.240000  0.165000  0.382500  0.000000  0.167083  0.179583\n",
       "LR    0.234583  0.151250  0.394583  0.167083  0.000000  0.087500\n",
       "MLP   0.256250  0.179583  0.407083  0.179583  0.087500  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************** Pearson-R correlation scores ***********\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>RF</th>\n",
       "      <th>NB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CART</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803517</td>\n",
       "      <td>0.715889</td>\n",
       "      <td>0.793584</td>\n",
       "      <td>0.794191</td>\n",
       "      <td>0.770373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.803517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.768954</td>\n",
       "      <td>0.864027</td>\n",
       "      <td>0.870671</td>\n",
       "      <td>0.851583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.715889</td>\n",
       "      <td>0.768954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764007</td>\n",
       "      <td>0.773523</td>\n",
       "      <td>0.760941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.793584</td>\n",
       "      <td>0.864027</td>\n",
       "      <td>0.764007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847583</td>\n",
       "      <td>0.836879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.794191</td>\n",
       "      <td>0.870671</td>\n",
       "      <td>0.773523</td>\n",
       "      <td>0.847583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.770373</td>\n",
       "      <td>0.851583</td>\n",
       "      <td>0.760941</td>\n",
       "      <td>0.836879</td>\n",
       "      <td>0.916835</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CART        RF        NB       KNN        LR       MLP\n",
       "CART  1.000000  0.803517  0.715889  0.793584  0.794191  0.770373\n",
       "RF    0.803517  1.000000  0.768954  0.864027  0.870671  0.851583\n",
       "NB    0.715889  0.768954  1.000000  0.764007  0.773523  0.760941\n",
       "KNN   0.793584  0.864027  0.764007  1.000000  0.847583  0.836879\n",
       "LR    0.794191  0.870671  0.773523  0.847583  1.000000  0.916835\n",
       "MLP   0.770373  0.851583  0.760941  0.836879  0.916835  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************** Pandas scatter plot of y_pred values for each base estimator ***********\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAHeCAYAAABUhkiBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXdYXNeZ/z9nGkPvXQjUe0eSVdx7W9fEJdXZxFknzi/Z\ndYpTnOJsumM7G9tZO9nsJnEvsdxkW1aXbHUJCQmBhBC9MzDA9HJ/fwwgoRkY7jADg3Q+z6NHA4f3\nnnfOPfece+493/cViqIgkUgkEokkOtGMtwMSiUQikUiGRk7UEolEIpFEMXKilkgkEokkipETtUQi\nkUgkUYycqCUSiUQiiWLkRC2RSCQSSRQjJ2qJRCKRSKIYOVFLJBKJRBLFyIlaIpFIJJIoRjfeDgBk\nZGQoRUVF4+3GhKC6uprzta2sTg+9DjdGnYakWL0qW4/HQ1lzLwACSHB1Rm07KYpCo9mOy+0lPcFA\nolHld/UqdFqdAKTGGdBqxKDyTquTZrMdIQRTMuKJ0Q2+H69q68Xi9CCAmdkJNNbXRW1bjZZuuwu7\ny0tCjI44g1aVbafFSX2XDQCDVkOMveO8bSen24vZ5kKnEaTEGRAiuM3ZlDaYBz4nRvG1N1oUBbps\nTtweheRYPQadurXu6TYLvU43AGlxBpqrytoVRckMZhcVE3VRURH79+8fbzcmBMXFxedtW/3vx6fp\nsroAeOCyaRj1Ix9Yf7aulM7dtQM/Z2z8SdS209EGMz9/twyAaZnx/PL2hars91eb2HGyHYA10zNY\nMSVtUPldz35CWWM3AJ9ZWcjDN8wZVD7jh+tJ8vhCB1+3NJ/Nv/1y1LbVaLC7PPxp6ykAkmL1/Ova\nKarsl/zsQ3Jt7oGfo7lPjZb1pU1UNPcAcPvSfArT41XZFz383sDn87md6kxWXj9QD8CM7ARuWpin\nyn7qw++R2PfZoIXmX95UMxI7+ehbEjXMz09GIwQzsxP9VoHB+PcrCgc+66O8V0/PjGdyWhw6jeDi\nmUFvpv2YmplAQoyOhBgd0zL9B9SbF+ah1WqIj9HxL4v9B5K5uUkAaAXcf0mR6vonCka9llk5iWiE\nYH5ekmr7By6dNvA5PyUmnK5FHbNzEjHoNGQlxZCdZFRtH+WXXNjobx+9VjA7R32fWjTpjM2NC3JH\nbCeiISlHcXGxEqk7sLPv9M6l+tc3RqTOUBmJr+fzijqcyHYaObKtRoZsp5Eh22nkCCEOKIpSHOzv\nLpQbIYlEIpFIJiRyopZIJBKJJIqRE7VEIpFIJFGMnKgvMMw2F3UmK9GwN0EtO0+0cs+zu9hX1THe\nruBwe6jpsGB3eQKWW51uajosuD3ekI5/sKaTD442h+zfs1sreaekIWT7iYLT7R32PATjH5+c5jN/\n3o3NZguzZ+Gny+qkzmQdl7pN3TY+8+fdvLy3elzqH0t6Hb5r1+sNbYz8yVtHefD5A2H1KSrkWf1M\npI1fE5Feh5vnd9fgdHtZXpTG2hkZ4+2SKj73130owKef283pce4P6w410NhlJysphs+sLBxU5vEq\nvLS3jm6bi+lZCdy8SJ2EY1dlO9994wheReFoo5lvXzNLlf39f9/H1oo2hBD0OFzcu7JIlf1EYl1J\nAw2dNjISY/jcRYXBDc7ig9JGHnnbJ5Nb+sutHP/59RHwMDx0WZ08v7sGl0cJKMmLNKt+uwWHW+Hj\nUx1My0hk+dT0Ma1/rHC6vby4pwaLw8PcvCSunZejyv7B5w/wbt8NdtljW9j87cvD4pdcUV9AWB1u\nnG7fCq8/YMZEQjnn//Gks0/v3a/7PhuXx0uv3d1Xrr6dq00WvH1PPOo71a+g6jt9q0NFUTjW2KPa\nfiLR375mq1P1U6LDdV0Dn/uvi2ilx+7G1ad9H49r1+k+07ZHG7qG+cuJjcPtwer0PZ0J5dotb+4e\n+Nze6wibX3KivoDISjJyycxM5uQmcskM9frd8WbppGT0GsGqMV5NBOL6+TnMyknkhgBaSKNey7Xz\ns5mVk8jVc9XdkQN8etkkLpuVycJJKTx09UzV9r+7cxEFaXHMy0vipzfNVm0/kbh+fi6zchK5fkEu\nQmU4re/dMJecpBj0WsH9F6sLhjLWFKTFsWZ6BnNyk1g9bexXs59fVYheK5iUEst9F08LbjBBSTTq\nuWpONrNzErlidrZq+1fvv4h4g5YYneCZe5eGza+oevQtiTzLClPH24WQ+eeDa8fbhQEK0+OHjd40\nOycppIAIAFqtll/cpi5a2dnMy09m00OXhWw/kShIi6MgLS5k+90/uCqM3kSWsX7cfTY/u2U+P7tl\n/rjVP5bMz09mfn5ySLZpSbEce/S6MHskJ+qQke/TJRKJRDIWyEffEolEIpFEMXKilkgkEokkipET\ntSRsdFmd/GHTCZ7fVR2S/bPbTnLRLzfy768cCsn+ZEsPG8ta6AjjbstIcbTBzKbjLXTb/XeNB6O5\ny86yn29g6aMbqO7oDm5wAfOZ53Yx78fv89O3SkOyP1BjYktFKzZnaDrtscLt9vLXnad5ZmvlgOJA\nDTtPtrHmN5u4/ZmPQ6q/yWzjo7IWajosIdmPJbtPdfC7Dys4VNsZkv11T25n6c83sLEs9DgHapET\ntSRs/H1XDZ9UdvDOkSZ2nGxTbf/ER5W09jh4+3ATJ5vVyYqsTjfrS5spbTDzUVmL6rrHko5eBx+V\ntXCk3szWCvXtdNdzu+iwuDBZXXz+f2Tyg6GobO7i4yoTFqeXv5+VAnWk1HRY2H6inZLaLnZHQZCd\n4fjgWDMfHmtmW0Ubrx2oU23/0KuHaeqyU1LXxa/XH1dtv760maMNZt453Kjadizxer08vbWS/dUm\nntlSqdr+Z28dpby5B5PFxX+8ejgCHgZmwmwmi8TmreGOOZrjXqikJxgA0Agx8FkNBr0Gp8eLRkB6\ngrq0gjqNBqNeg9XpIcEY3d06Rq/FoNPgdHtJjFHva05SDDV9EaoyVbbThURGvBGBT3evDWFJEmfQ\noRECr6JEfZ/KTIxBCFAUSItXf+0lGnW09ToQQjAlQOrUoPYxOrptLuIM0d1OGo2GhBgdJreTRKNe\ntf20rPiBdo4fw+8a3a0qmVB8ZmUhhWlxpCUYmJurXt7w9tfW8NhHJ7htcR5pKid6g07D3Ssm09Zj\npzA9np+qrn3sSIjRce+KyXRYnEzNUD8ovvJvq/nWS4fweL388TPLIuDh+UFKopEn7lrIP3bV8vNb\n5qm2z0yM4Z6VBVgcHorSQ5eAjQUrp6bz/etnY3d5WRlC1LD131jN998sY/6kZO5aPlm1/b8szqPO\nZCUvJZZnVFuPLT+/dR4ltV0sL1Ivd/vsqil02dyU1HXx9N2hSyjVIidqSVhZO4pAKkWZCTw1iiAB\nybF6kmPV3yWPB6nxBlJDWPn08+Q9S8LozfnLrUsKuHVJQcj2WYlGSAyjQxFkUUHoMRIMBgO/v2tx\nyPZGvZYZ2ROjoTISjFwVQiCifh68YkYYvRkZ8h21RCKRSCRRjJyoJRKJRCKJYuSj72EIttlMIpFI\nJJJIIyfqCUZbj4PP/3UPF0/P4CuXqAuOX9/Zw1WP78DpVrhidhZ/+cJyVfYltZ18/81SBPDYnYuY\nqzIebmVrDxuPt5KTZOTmRXloNeqSKIwlpfVmdla2U5Qex3Xzc/wSPnxyqp2Sui4W5CdzcYD38it/\nsZEOi5PFBSm8/sBqVXU3m2382/MHsTjcfPfaWVytMtXekfou/mvTSRJi9Pz4prlBN+Y1dtn4wl/3\ncu+KyVw7X11dFc3d/MerJXg88J+3zqN4yuCNTGVNZp7YcIJYg44f3TiHrCTjoPJfrS/j77tqiDfo\nePf/rSEnWd2mrd1VHRys7WReXjKXzoxsohm7y8Oftp4iPzWWmxbkolHZf7/1yiFK6rq4cnYWj9w0\neHOb2+3lP9cf53S7hbuKC7hh4eBkL712Nz979xgdvQ7uv3gaF6lMzPHKnloefa8MnUbw5y8sY8WU\n6E1xu7/axJ+2niIlztd/k+MG998Nx5p5cW8tBalxPHLTXAy6wQ+Gf73+OB+UNTMvN5mnP6Nuz4vT\n6WTVb7ZhtrlYPT2Nv3/polF/n3AgH31PMHodbhwuL9tOqNffPre1GrtLwavAx5Xtqu3fPtxIt82F\n2eZiXQh6ycN1ZmxOD6fbLWFNARcJSuo6sbs8lDf30OvwDyBxqLYLh8vLoVr/lH8Hqk209TrwKgql\nDWbVdX9wtJm2HjtWp5t1JerbedPxFnrsbprMNvZVm4L+vd3lxe7ysPG4ev35O0ea6LK66HG4eLOk\nwa988/FWuu1uWrrt7AqgRX73SBMer0K33cWLe9Rrnc+ch07VaS7VYnN6sLs8nGrtVZ1q0ub0sO+0\nCZfby7YA2vm6TivHm7qHPA8ldZ3UdlixODxsLFd/nl7YW4vL48Xm8vDXnTWq7ceSTcdb6XW4qe+0\ncajO//raeLwFm9PDiZYeqtp6/cq3VLTicnspqetUHfzog2NtdFqdeBWFfaejJ53nsBO1EOKXY+WI\nZGTEGbQIAcUhSAu+tLYQg1YgBCwJYYfotfNzMOq1xOq1XKdylQcwNy8JrUaQl2IkfRQ7nseCuXnJ\naIRgamY8CQG0zvPykhDC9/+5LMhLIDlWjxCC6Vnq5VdXzskiKVaPXqvhunnqU+2tmZ6BQachNU7P\nkskpQf/eoNOgEYI109Wvsq6dm02cQUeMTsv18/1Tfl48I4MYvYbkWD3FRf597rJZWQghiDNouWOp\n+t3ZZ85Dsuo0l2oxGrRohKAgLY6UOHX9N9agHfAxkCwoPzWOqRnxfefBf7W8ID+ZrL6UnBeHcJ5u\nXeJ7gqXXarhrxSTV9mPJxTN8/TcjwcDCfP/+u3ZGBlqNYHJ6XEDZ3Mqp6QghmJ2TpDoewxUzM0mI\n0SGECHhtjxdiuLtQIcRBRVHCl1RzCIqLi5X9+/eH/E54uMAk4/GeORL+9B+zuLiYvXv3otGE/jDE\n4XAQExNaoAyPx4NWqw25bkVRIj6ggq+d9u8fXdSuYL4GK3c6nRgMod+QjKatvV7viPtIOPrUcL4G\n88XlcqHXhy6rG8s+tW/fvlHVFeycBmsrNef1XEbbziMlHNfeaNthtOPUaK/dkSKEOKAoSnGwvwv2\njlorhEgFAvZMRVGCP1eThJ3RDKhAyJM0MKrOD4zJgBougvkarHy0F/po2lptHxltnxrO12DHHu3k\nMZZ9arR1BTunwdpqNOdpLCbpcDHadhjtODUWk7Qagk3Us4EDBJ6oFWBq2D2SSCQSiUQyQLCJukxR\nFBkCSSKRSCSScSJiu76FEEVCiBYhxFYhxIZI1SMJLyaLkyazLWT7h14+xFObT4Rka3e62X2qA1Ov\nuh2144HT7aW2w4rDHVr6w4rmbt490oDHE5r97zcc5/cb1Gc5ikbqO62YbYHTffZanDyyrpSdIWRj\nA2jotPHWoQZ6baH1qS6rk4au0K+Hs7G7PNR2WHF5vGE53rk8tfkkv1pfFrL9+6VNlIWgUogEDV02\nulTurB8pe6va+crf9lHWENqu7rpOK/tHoKYIJ8FW1H8YqkAIMVlRlGB6io8URfmserfUEW2BSaLN\nn5HS2mPn5b11eLwKV83JZsEkdTrpS3+7ZSCrk8Xh4XvXz1Fl/9sPKzjW2E1KrJ4/3rvUTx8ZTaw7\n1EBDl43sJCP3rlSXxKDOZOHfnj+I0+1ha0U7j31qkSr7r79wgPVHfblwK5p6eU6lHj6a2F3Vwa5T\nHRh0Gj63qpCkczIaXfnkdtp6Hby8r46PvnUJRZkJIz620+nhX/+2jx67izcO1fP3L61U5ZvJ4uSF\n3TW4vQqXzhq9RvvV/XV09DopTI/j9qXh3Xn9w3+W8uK+WhQFSuu7efF+dfrfR985xofHmtFpNfzp\n3qWqYySEk4O1nWyraEOnEXzmosKQsoENx91/3oNX8cm4Kn+pLkNiXaeVH/yzFKfby7XzcvjS2ilh\n9W0ohh0JFUX5PyHEKiHEnUKILAAhxEIhxIvASDKMXy6E2CGE+PdzC4QQ9wsh9gsh9re1hXa3LAkv\n3TYXHq9PBWAK4W7WZD2jWSwJoH8MRmuPz77b7sbm9NcuRxP97aNWTwtQb7Lh7FuJN5vtqu0rW3tR\nFF+qvdPtFtX20USnxdd+TreXXrv/Oe/p07B7FagxqfuuFqdnQAPf3qNet2+2uXD3XQ/9foaKx6vQ\nZfU9NTCN8liBON5spl/AU6uynQDqO31PDdweL1Ud/trksaS/rd1ehe4hnrSEit1up++UEsqDjdZu\nB063z3A0Tx7VEkxH/Vvgr8AdwHtCiP8ENgB7gGApRJqAmcDlwFVCiEE5wRRFeU5RlGJFUYozMyMb\nUUgyMqZmJLC8KI15eUksD6B5DcavbltAnF5Derye//28+q0NX7l4CvPzk/ncRYV+0Yiijevm5TAz\nO5HrVUbyAlg1PYObF+YxJzeJb18zU7X9s59dQnqCnrR4Pc+ojLwUbayensGc3ETWTM8gLyXWr/yb\nV04jNc7AyilpXDpLnaY8NcHAF1cXMSsnif93pfp2LkqPY+XUNObmJYWUOvJstBrB9fN9febaEGIQ\nBOPZzy4nM8FAaqyOp+5Vf+09dM1M5uYlcfXcbG5amB92/9Swcmo6c3KTWDk1jcIwpxc1Go2sLErF\nqNNw1Zws1fbLClO5YUEuiwuS+fzqorD6NhzBdNRlwFJFUex9Mq06YL6iKNWqKhHiAcCsKMqLgcpH\nq6O+EDhbRz1ajeKFgGynkSPbamTIdhoZsp1Gzkh11MFeAtoVRbEDKIrSCZwc6SQthDg7Oeka4NRI\n7CQSiUQikZwh2GayqUKIt8/6ecrZPyuK8i/D2F4shPg54AB2KIqyZxR+SiQSiURyQRJsor7lnJ9/\nP9IDK4qyHliv2iOJRCKRSCQDBNv1vS3QP6AKWDE2LkrCyY/eLOXu53ZxuLbTr0xRFPZXm9h+og27\ny1/f295j5band3Lb0zsxW8O7G3Mk7D3dweMbKjgUwHe19DrcbClvpbQ+sG60sqWHxzdUsCmEjFIA\nP337KFc/vpVXQsgIBfDCnhqe2nwScwi7ys1WJ09vqeT5XdV4vZHR7Pbjdnv5687TPLvtFNYAO/Wd\nbi87Trax97QpYHardw83sOCnH3DFY1si6udQlDV2s7m8ZUgddzh582A933jxINsqWgOWVzT3sLm8\nZUj98J1/+oS1v9nEnir1me9GS02HhSc+quDDPllgJDH1OvmvTSd5aW/ga8dsc7G5vIWyxu6A5c9u\nO8mqX23kO68dDqn+Ey09bDreEtJOf6/Xy98+qeaZrZUBVQyhMmKhqhAiUwjxNSHEDmAroD6tj2Rc\nef9IE2+VNHCswcwP1x31K69qt7DjZDsHajoDpkd86LWjHGvs5lhjNw+9VjIWLg/iqS2V7Dlt4o+b\nT476WNtPtFFS18XG4y20dvtLpJ7Zeoo9p038Zcdp1QFYatotvLS3jpoOK7/6QH1Qkh0n23i7pJEd\nJ9v5x271KQmf31PL9hNtvHOkie0nIzuov3e0iQ+PNbO5vJXXD9T7le+vMbG/upOPK9s52eov+/nO\n60fosXuoarfy/ddDG1hDpdPi5MNjzRyuM7N1iMkzXDidHp7ceIKDtZ38an25X3m33cX7R5s4XGdm\n43F/X369/jgHaztp7LLzzZfH/tp7ZuspdleZ+N9PTtMUpgAwQ/H33dV8XNnOukMN7D7lnxp1S3kr\nh+vMbChrDnhT8/hHlbR0O/jnoQbqTeqkZr0ON+tLmzhSb+ajEG7SPyprZX1pE9sq2nhlX2g36YEI\nJs9KFEJ8QQjxIbAXmAZMURRlmqIo3w6bF5IxITs5Bm1fsvukWP8A/fEGHf05B+IDpHbMTT6TzCMv\n2V9KE2n6000mGkefXKD/++k0ghi9fwD//vYx6jWqA6/Ex4iBdg507GCkxxvQ9J2I1BCCPfQHiBCC\nsAeLOJez05WmBZDU9Z8zIXwpWs/FqDvzuymZ6lOCjgaD7sy5jTcEews4OrRaMPb1hQSjf10G7Rlf\nEmL826kwPW4gIUigtKuRJiXWV6dBpyE2wHkMJ6l9/UgjBClxAcapvu+v1wa+Ng1aXztpBaTEqOv/\neq0gpq9PhtLO6QmGgTE0LT705EfnEkyeZcM3Qf8I2KkoiiKEqFIUJazJOKQ8KzjhkmdtKmumpN7M\n1y+ZhjHAgNHSbcfq9DAlI/Cg+eTGcrRCwzdC0KWOlvZeOwdruiguTCMtYfgLMFg7eb0KVe0WUuP0\nAXPWWp1udp5sZ05eEgWp6rWcO0608l5pE9+4fAb5aertjzaY6eh1cOks9VpP8K3KU+MMzB9BhKnR\n9qkDNZ243F4umhZYa1zdbiFGryE3wM1dV4+dr75wkKWFqaoj2YWDTouTDouDKRkJAzdXQzHadqpq\n62X7iTZuWJBDVlKAtrA6aetxMCUjHp3WfwL6y7ZTHGvu5je3zRvz7E52p5udle3MyE6kMH34G6rR\ntpPX62XHyXYyE2OYm+fffz1ehaq2XjISYgLeyJ5s7uHxjRXcuXQSV85Vr1k3W1209tiHPA/BOFzX\nicXhYfUI8oaPVJ4VbKL+FnA3EA+8BLyCLyyonKjHGKmjVodsp5Ej22pkyHYaGbKdRk5YdNSKojyp\nKMpFnNn9vQ7IE0J8Vwgx9ksqiUQikUguMIK9o54uhFijKEqVoii/VBRlAbAcuA44P1L3SCQSiUQS\nxQR7AP8kMGgPvKIopcC3gPcj5ZREIpFIJBIfwba1ZfdNzINQFOWIEKIwQj5JhqHX4eZPW0+xqCCZ\n1dMGb1ZQFIUNZS2cbrewZlqG6jSVr++r5dtv+E735bMy+N/7BqcF7LI6eaukESHglkX5JAfYkTkc\nla29bDreQk6ykZsW5gXdvBNJbvrDdo429SCAD/59DbOyU1TZP7KulJ2VHVw0JY1f3bEwuIEKuqxO\nHn2njB67iwevmM6iAvUJUtRgtrn4722nuGJ2FjOzEweVOdwe3jrUiNnm4voFOUw6Z2Ndj93FukMN\nuL0KtyzO99tl/vAbJby8rwEBPHbnAu4oHpwS9M2D9Ty9pZKMhBie/fwykmOjNxmL3eXlv7edIj8l\nlhsX5KI5p/8eqDGx93Qns3MTuVzlJsDWLgsX/XorXiAnKYbdP7gqjJ5De6+Dt0saMeg03LokX/WO\n5vLmbrZWtFGQGsf183P8vvvZuL0K33q5BKvTzbeumuG3IexUWy+PfViBViP4/g2zyU9Rt9ny8/+z\nh52V7cTqtOz63uUknbMZ9FBtJ7urTMzMTuDKOepUxF6vl1++X05lay93Lp3ETYvyVNlbHG7WlTTg\ncHm5eVEemYnh2fkdbEU93Og19vocCVanB7vLw8Ea/6AfVqeHssZubE4Ph+rUBwV57KMTA593BNDf\nnmjpxWRx0tHrpLKtR/XxD9d1YXV6qGqz0N6rPu1gODnW5PNfAf7zHX9dazC2n2zH6fawszL8OuW9\np000dNnotrv5qCyy+l4Au8uDzemhpNY/NWlDp42GLhu9DjdHG/wDTJxqs9De66TL6qK82b/87ZIm\nwNfOf9hc6Ve+rqQRm8tDXaeV7RXRne7W5nRjc3qobO0NmN70YE0XdpevHV0qcyj+YXMl/RbN3eG/\nNsqbejDbXLT1ODjdpj4N5qHaLmxODydaeoIGh7E43DSZbZhtroCa8K3lrZgsvh3u20+ov372VHXg\nVcDi8vDXT6r9yg/W+s7DkXozDrd/4KbhaOi0U1pvxub0BPQ9GKfbLbR2OzDbXBxvChyQJRSCTdT7\nhRBfOfeXQogvAwfC5oVkxMTqNQgBc/OS/MriDFqmZsb7ynP9y4PxpTVnVjvz8xL9yqdkxBNn0BIf\no6UoiEQjEHNyk9BqBLnJxojre4MxOf3MfeY3r5yu2n7J5BSEECycpG4lPhIWF6SQGqfHoNOwdgQS\nj9Fi0GnQCMGcAH0mNzmW9AQDeq1gVo5/nyhKjyMhRodRr2V6ZoJf+aUzzqSwvW+V/0O4K2dnotUI\n0uNjRiRnGU+Mei0aIchPjSUlgGZ8bl4SQsCsnET0KmU9X157pg8mG8OvU56WFU+MXkOiUcfkEOSC\nc3OT0AhBQVpcwBgMZxNn0JIc6+u/awKc01XT04ntG0cumpKm2pc5fe1s0AruXO6/4p2b6yufkZ0w\noIkeKbnJRqZm+MbQVdPU+zY5PY5Eo44YvYbpWf7XQ6gEk2dlA28CTs5MzMWAAbhNUZSwxJOT8qzg\nnC3P2rdv30Dwg0AoijJseTAsFgvx8YEn4v7+EurxR+vbSBmJRMRqtRIXF3q+W4/Hg1YbueAPXq8X\njUa9jlMto+1TwfqEzWYjNnboB3CRbsdwMd7X3mgZrW8jte+/9obrv/2hbUPt3w6Hg5iYoR8rj/a7\njvbaG2n9I5VnDfuiQlGUFmC1EOJyYH7fr99TFGXzSJyVRIZgHWC0E+FwA8Vojz0Wk/RIGc0kDUR8\nchmLSbqf0fSpYLbDTdIQ+XYMJ+N57Y2Wsb52h+u/o+3bw03SMPrvOlr/wj3OjWhHgaIoW4DxiZov\nkUgkEskFzNjdskskEolEIlGNnKgvMHZVtvHHTSdwuQLv3Oy0OGk2+2eTOmPfzp7T/hltJhqKovTt\nrA7cDna7m799UsWpABmfRoKp18meqg6c7tDSTHZZhz8PwWg224dMlxhunv/kNM9uGzqjWUu3HdMw\nKQMP1HTS0GWNhGtRRVljFz95q3TIjE4Wh5s6kxWvN/C+IbPNReMoMle1BjkP0cSft59iU1ng7FWK\nolDfaaXXETiNpN3pZk9VR8j93+oc/jyMB2OfhkUybuw93c59f9uP16uw8Xgrbz24dlB5a4+dl/fW\n4fEqXD032y+hwyt7a/njFp/E5qGrZ3Lb0klj5nu42VXVwZ4qEwadhs+vKvTLyHXXX3ZT1dbLU5tP\n8f63LiYjwTjiYzvdXr7/zyN02VzMz0/mkZvmqvKtvdfBS3tqcXsVrpidxaICdTvLS+vNbDzeglYj\nuGfF5LBpOQPxs3dK+fuuOhRFobShh6fuXTqo/HhTNx8cbUYjBHctLyAneXA7/nXnaT481oxBp+HX\ndyxQraksyMHxAAAgAElEQVSdSNz+zC6cHi9vHmrkyE+vHVTmcHt4YU8NFoeHhZOS/fS/ZquL5/fU\n4HR7WTsjg+VF6nYkVzT3sL60CY0QfKp4Enkp0auu/cJf97LrVDtCCB67cyE3L84fVL7tRBuHaruI\nNWj54uqigaxk/fzqgwrKm7pJizfwx7uXoFOR/c7p9vLC7lp6HW7m5ydz9dzoyOYsV9QXEMebegbu\nEtt6/LWaZqsLT195R4A771PtFhRFQVEUKttCW2lGC/0rC6fbi8Xhr7Xs6MtB7XB7VeejtjndmPtW\n6i0Bcl0Hw2xz4e47D6GsgDosvnPr8SqYbZFdQZU3WQZ2fVe2+mvr+/33KkpA7XGj2bdCdLq9NJvH\nV1sfSUy9Tlx959Tu8u9vdteZfhjo2uu2uwaeznSo7I++Y/radqjzEE00dPqeriiKwtFGs195f5+y\nOT1Ynf5t2Z9fvsvqwq7yiZbD7RlYqZss0dMf5Yr6AuILq6fwwdFm6jttPHz9bL/yaZkJFBelYnV6\nWF7kHw3rgUum0dRlQwi4/5KwJlAbc9ZOz0AjBBkJMX6rPIBvXzuT57ZXsXRyKjNz1GnSk+MMfHZl\nIQdrO7lZZWQjgKkZ8SwvSqPX4WZFCDrTFVPScLi9Pl19Rvi0nIF44q753Pnfe/B4FB7/9CK/8qWT\nU7E43MTotX5RzwC+cFERf99dTV5KLMsKIxuBbTxJSzBwzdwsdleZ+JdFuX7lybF6rpidRX2nLeA5\nn5Qay0VT0+myOlk9PXA60eHwnQcPeq1gtsr+PNb88vb5fOf1I6TFGfj21TP8yi+dmcnuKhO5KYHj\nMfzr2imsL21i+ZS0gLm/hyPRqOfKOVnUmqysUPnUIpIMq6MeK6SOOjgyzaU6ZDuNHNlWI0O208iQ\n7TRywpLmUiKRSCQSyfgiJ2qJRCKRSKIYOVFLJBKJRBLFyIl6guHyeNlc3jKknvLWp3Yy+0fv84t3\njgYsP9pgZktFa0ANoqIoHKgxseNkm+qsMxONv318ipk/XM+KX2wcb1cC8tLeWp7eUol5DHbo2l0e\ntpS3DpkVaenPNzDrh+t5+1C9X5nXq7CnqoNPKttxq8wYdb7x3ddKmP2j97nn2V0By2s7rGwubxlS\nCXCipcd3HqzDZ6cKBZfHy8eV7ew9bWIs9iXtrzax82R7wDgCFS1dzH3kfeb9+APazeHXz7f1ONhc\n3kJ1u/osYdGKnKgnGF1WF4frzLxzuNGvbPPxJkrqzdjdXv7ycY1feVuPg4/KWiip7WJbgJSCVe0W\ntp9oZ391J3tPmyLif7Tw6HvlOD0KrT0OvvlydCWC23GyjXWHGth+oo1/7PY/j+HGbHNRUtfF5nL/\nABN3PfsxJosLh0fhodeO+JUfb+7mk1Md7DltoqTOP03mhcRrBxqwu73sOm2iwTT4RtrrVXj7cAOH\n68ysL23ys+22u1hf2kRJXRcbjwcO9DEaDtb4rumPK9upaFGfolYNDreXHSfb2VdtYn+1/zjy6T/t\nweryYnF6uOGpT8Je/wdHmwbGSLXpRqMVOVFPMPoTtscFSPyel3QmsEWgvO4xeg16bb+9fyKEOIOW\n/ljycYbzW7mnOyto/tSMyCVCCIXUOMPAeUgJklIwHPQnEAh0zgvTz8i7DAECR5xtc773GTWknRNP\nRAiI7Wuf+ADtZNBqBto3PsC1OVrizxov4vSRPU8awZlxJMA4lXSWZCojLvz9u7+djXot2ihKAjQa\n5JU1wUiN03PDglwKzh0JgNn5aXz/+pm8cbCR392xwK88yajn7hWT6bQ4mRYgd3Bucix3LS/A5vQw\nNUD5+cTH372Mu/68h0UFKXzzKn9N+XgyPz+ZH9wwB5PFySUzIp+jOS3ewI0LcwPesPz2zkXYnG4q\nmnpY98AKv/IpGfF8qngSHq9CYQg5ys8n/vGl5Tz63nE+t3KyX8Yw0ReZraHTRmG6f/Q1o17LPcsn\n09briMiN4/z8ZBJidOh1GvIjHJVMr9Xw6eICHG4vUwJ8lx0PX8ltT+3EoBe88tU1Ya//poW51HRY\nyU0xDixsJjpyop5gaIRgVo5/4Ih+vnrpDL56qX+QgH4yEmLISBg6pGRucvSGFgwnGclxbPr25ePt\nxpAsnKQubOho0GlEwGAk/fzx3mXD2k9KPX/Dfqph7cwsNszMGrI8IUY37LWbGm8gNUAAj3BRNIZP\njoKFKH3znPDF4cSo1w7bzhMR+ehbIpFIJJIoRk7UEolEIpFEMRGdqIUQTwghdggh/hDJeiQSiUQi\nOV+J2DtqIcRSIEFRlIuFEH8SQixXFGVfpOq7UChr7Kbo4fdIMmo58tPrVNm6PV7ePdJEW4+Dq+Zm\n+2306LI6efSdMiwON9+4coZfmsvx5tltp9hd1cElMzO5b82UYf+21+Hmuie2YzRoefrepeSnhvfd\n+193nmbHyTZWT0vnK5dM8yvfWNbCqbZeVk1LV/2+uaTWxKef3Y3Hq3Df6iJ+dPM8VfYt3XbeO9JE\nnEHLrUvy/dIAnktpg5mih9+jIMXIjoevVFVXMNp6HLx7pJEYnZZbl+SFfWf43tMmDtV2Mi8vmbUq\nN955vQrvlTbRZLZxxewspmcN/16zormHooffQytgz8OXk5Gs7t38thNtlDd1U1yUyrLCsU34cKKl\nhyc+OoFBp+GHN8whK2nkaVsBypu72X6ijUmpcVw/P2dAKRAIs9XJlIffQwHuXp7Pr+9YrKquxi4b\n60ubSIrVc8viPGJ0g/tvZWsPm8tbyU2O5cYFuWHdMOb1evnNB+WcaOnlU8sKuGGhfwKV4bA63aw7\n1IjD7eGmhXlhSzEbyRX1RcBHfZ83AqsiWNcFg6cvWEG3XX1AktYeB6fbLfQ63BwOoHndVdVBQ5eN\nLpsrIlrO0bK1og2r08Pm8tagf9tpddLjcNHWY+e9I/6a89GypaIVq9PDlgB6dJvTQ2mDGavTw8Ga\nTtXHfmzDCZweBY8Cbxz0DzISjGONZsw2F01mOzUdIw8oUdelPiVnMMqauumyumjptlPVFv4AFAdq\nOrE6PeyvUR/Io93ioLK1F4vDw6Ha4BpwZ58m16PAk5tOqqrL41U42OfrgRD6xGjZfLwVk8VJs9nO\nx5Udqu0P1XZhcXioaO6hK0hAlpYeB/1n4u0Sf814MEobzPTY3TR02qjv9A/s1O9LZWtvwJSgo6Gh\n005Jne/a3VCmfgysarPQ0m2ny+rieFN32PyK5ESdAvR7au77eQAhxP1CiP1CiP1tbf6DnSQw/feO\nMTr1d5EZCTFkJcWg1QTeOb50cirJsXoMOg2rpqpPpRdplkz2daGRpENMMurRaTUkxOi4YvbQO3FD\npd+HJZP9fTHqNUzNjEcImJOrPqXgF1cXoRU+Peqls9T7PiMrEYNOQ1KsXtWThNQIaLanZyVg0GlI\nNOooSAv/7vA5uYl9/ycNu8oLRFqcgdxkIxohRnSedGet3O6/ZGhlRSC0GsHsnDO+jjWrpqURo/dd\nD8UhpBP1ta8v3WZSkH5ydurJUMaRmdmJ6LWC1Dg9eQFUKHNyk9AIQV6KkdQw67Bzk40UZfiu3ZVT\n1T/1KEiLI9Gow6DTMD0rfBLXiKW5FEJ8HWhTFOVVIcTtwCRFUf4r0N9mZGQoRUVFEfEjGnC4vXi8\nCrH6MwFFRorT7eFESy9CwLy8ZKqrqzmf2ypcRHs7ma0urC4PmQkGdNrw3i97FYXGLjt6rSA7wCNO\nq9NDrclKrF5DYXp81LfVaHB7FBweT8jBL8oau/EqClMz42ltrD9v20nB9yRIqxHEBAhsE4w6k5Uu\nm4sEgw5haTtv2wnCO54fOHBAURQlaINHUke9C/gq8CpwFfB/Q/1hUVHReZu/tK3HwQt7alAUWFSQ\nzBWzs1XZz/jBe+T0RcFzxmgpeu9H521bhZNozolb1mDm/ucPoCgKc/OS+PPnl4f1+F/52z5cVb7H\nm1+/eib3rZ06qHzuI++T4fJ1qi9eM4P/++69UdtWo8Ht8fLcjiocLi85yUbuWTFZlf01v99KVt/j\nehtQtPEn52U7ge9VTkltF0LAvSsnk5Wo7h120cPv0b/2zTiP2ync4zkHrj84EruIPfpWFOUgYBdC\n7AA8iqLsjVRdEolEIgkTkc/ZIVFJROVZiqJ8U1GUixVF+UYk64lmMhNjuGVxPpfMzGTt9EzV9lse\nuhijTkO8QcORn6nb5S2JTubmJ/O9a2dx48I8fnHr/LAf/4m7lnDdgly+sLrIbzUN8OKXLyI/2cjV\nc7J48IqZYa8/WtBpNdy5dBJrZ2Rwo8rduwAbHrqM1Fgdeg28/sDKCHgYPaydnsGlszK5ZXG+6h3h\nALctzkUrYEXR2EXUGw/GazyP2DtqNRQXFyvn66OScDPaR7pFD783ZFn1r28M+bjRRjQ/+o42ZFuN\nDNlOI0O208gRQhxQFKU42N/JyGQSiUQikUQxcqKWSCQSiSSKkRO1RCKRSCRRTFSkufQqCo++cwyL\n08ODV0ynYIzT5m0sa+bdI80UF6bw2VVFY1r3vqoO7vnzbhTgRzfM5r6L/cNRSqKPt0oa2FLexsUz\n0rljWYFf+d7TJipbe1kxJU114AO7083vPzqB2ebigUunMUVlbvDntlXy2w8q0Gk1vPvgKqbnRO8G\nn9ZuO1sqWkmLj+HK2Vmqw0GWNXZTUtfF3LwkFheo+54Wi4XFv9iKywvLC1N47YHw50aOFrrtLj46\n1oJBp+Gaedl+YTmDcd3jWylvtaAVcOpX589elkB8XNlOrcnK6mnpqnOsbzzWxJf/4VNcPXBxEd+7\nUV3436GIihV1j93NscZuqtstvHWoYczrf3V/PU1mG+8caaLX7h7Tuh96/TBuxReW8LGP1IUllIwf\nrx/w9Zk3Dvr3V7vLw8eV7bR02/m4sl31sXdWtnOk3kxNh5U3Q7ge/rilErcCdreX77xxVLX9WLK3\n2kRjl52jDWYauvzDRQZj24k2WrrtbKtoUx1C9DtvHqdPTs6+muAhRCcyR+rM1JqsVLb2crKlV7V9\neatPT+5R4Aevl4TbvajBbHOx97Qp5FCrD712ZODzczurw+ZXVEzURr0Wg06DRohxSQQxI9sX2m9S\naixxhrFtkmvnnAkROec8S3Z+PjOtb5U7NcP/jtug1QxEBCtIU58MZFZ2Esa+qEehXA8z+5JLCOD6\n+Tmq7ceS/qdnCTE60hMMQf7an8l9YUkL0mJVhxC9q/jMk5BYfVQMhRFjUmosWo3AoNMEjFYXjLOb\n5/bF0d2nRkO8QUtGXz+cHELI20umnwk7OiklfImAokaetWn7J9jd3pA60Wjxer00dNrJTjZiCCF8\n3mjZfLyJTouLO4qDR06KpDxrOCaadCvSEhG320uT2U5ushFdgD7j8Sr02t0khxiL2Gx1jup6WHeo\njrzkWFZMDZ5RarzlNN12F0adNqRrT1EUum1uEo26kLIolZxu5cPyNr53ffBHlOPdTqPF4nCj1Yig\n2dSG4sfrjvCp5ZNYkD98DOyJ3k5ujxeLwxPytfv6vho6LE6+elnwePAjlWdFxTtqgOQ4A+OVVFGj\n0VCQPrbvxc/mijnqgzFIxhedbvg+o9WIkC90GP31cOsS//fm0UqSMfR2EmJ07bx4ShaLp4Q/aUs0\nEh8zuuH+0VsXhsmT6Ean1ZAcF/qC7c7lhWH0xsf5/bxHIpFIJJIJjpyoJRKJRCKJYuREPQLcbi91\nnVa8Xm9I9tVtvWwqaw65fqvTjd3lCdlecv7xQWkjH5Q2jrcbY4LZ5sLtCe3aa+t28Nr+GhwOR0j2\nDreHXsfYKkFCpbXbRp3JErL93tPtNJisIdkqioLZ5sLrHf89T8FwOj2UNZnxeEIbU0c7nodC1Lyj\njmZ+/PZRTrVZWDgpmR/eOFeV7Z6qdj73P3txexVWTknnpfsvUmVfZ/JJdLQawaeKJ6mylZyfPPj8\nAd496hsorp/byJ8+H3QvyoTl48p29p42kZEYwz3LC1Tl7nY4HKz5zSacHoVfri/n0I+vVVV3t93F\nS3tqsbk8XBflu+d3Vbbz/TdL8XgV/uPqmdy2VN1Y8fUXD7CxrBWtRvCPL61gWdHwG8bO5cNjLRxv\n6qYghJ3SY80X/m8vtSYrc3KT+MsX1KWYHe14HipyRR0Et9tLVbvvLvVkq3r94frSJtx9d5nlzd2q\n7es6rXi8Ck63l6Yuu2p7yfnH7tOmgc97qtVrPScSNR2+FV57jwOLU90KqLLNjtPju/a6bepXxW09\nDqxOD4oCtR2hrTTHin3Vnbg8XryKwt6z+sdIOVJnRlEU3B4vWypaVdvX9q3k6zuju52cTg91nT69\nflWb+qcPox3PQ0WuqIOg02m4ZXE+u6s6uHKO+t2h37lqFh8cbaHH4eb+S6aotl+Qn0xTlx2dVjBL\n6qyBCycD2FD85ObZfOsVX2CFH94wZ5y9iSyrp6Xz8al2CtPiSY5Vt7t73qRkCtNjaey0s3KquhUi\nQGFaHLNzEumxu1lWmKrafiy5e8Uk9tWYcLi9fHFNkWr7By6byu8+PEFKrJ6vhRAdce30TA7VdTI7\nJ4nnVVuPHQaDlpsX5fFJZTvXzs9WbT/a8TxUokZHPZF1d2OJ1FGPbKKe6FrOsUS21ciQ7TQyZDuN\nHJnmUiKRSCSS8wA5UUskEolEEsXIiVoikUgkkijmgpio7S4PB2o6I7Yjscls40CNCZvKXakSyVBs\nLm/l9f11ON2h6YfVYHV6eHFPLV1WZ8TrmsgoChyo6Qwpy9d44/UqHG0wU9HcM96uRD2H6zp5YU8N\npt7ouR4uiF3fm463cqKlB61GcN+aIhJHEVv4XGxOD28cqMflUagz2bh1SX7Yji25MNlfbeLZbacA\n6LQ5+UqEc5S3dNt5q6SBytYefnxzePLnno90211sP9GGTiO4b+0UEkYZO3ssOVTXxfYTbQDotGIg\n+5tkMKZeJ7/7sAKXR+F4Yzf/eduC8XYJuEBW1Aq+ne2KApHY496/cV6JyNElFxres5UYY9ilJkBQ\nqXFFOef/icUZr6NB6RPNnBnPo4eJc0s4Cq6ak012kpGcJOOoMvUEItag5fZlk2jssjEvLymsxx6K\nYBKraJJShUqoMrLzgRVT0vnKxVNo63Vy2+K8iNeXlRjDjQtzuWlB5OuayCQZ9aydkUFOknFCraYB\nlhSkotNoMOg0TM+S8RiGIi3BwH9cM4tjjWZuWBA90egmVm8LEaNey3KVIfHUkJ8SS34Yk4RLJFfN\nHbtBIj5Gx+dXFY1ZfRMVjSCi40gk0WgEiwpSxtuNCcGywtSoC3BzQTz6lkgkEolkonJBrKglo+dC\nD9spkUgk40XEVtRCiCIhRIsQYqsQYkOk6pFIJBKJ5Hwm0ivqjxRF+WyE64g4l/1uC3UmK3NyEnn3\nm5eosnW7vTy56SQt3XbuW1vE3NzkCHkpmSh4PB6+/XopNR0Wvn75NK6co+599Ccn2/jy3w+goPDf\nn13KpbPUJxeYKDz2YTkv7KmlKD2ON7++VrX9/3vpEIdqO7l1ST4PXTNLla3Hq/BRWQs9dhdXzonu\nNj7Z3MOnn9uFx6vwxKcXcaXKPQ7vH2niNx+Wk54Qwwv3rcBoPH8ftl7/h+2cau1l8aQUXn1gtSpb\np9PDv792mJZuO9+6egZrp2dGyMvBRPod9eVCiB1CiH+PcD0Ro6vHTnWHFY8Cx5rUBws4WNfJvmoT\ntSYrbxxoiICHkonGrioTe0930NJt5392Vqu2f+StY1hdHmwuLz95+1j4HYwint9di8Xh5lhjNztO\nqEu/2NRlY0t5C11WJ6/sq1Ndd3WHheNN3dR32jhQ06nafiz58dvHMNtc9Drc/GJ9uWr7Z7ZV0tHr\n4ERzNy/sq42Ah9FBd6+D8uYenB6F/bXqz+mG8mZK6jppMtv4awjXbqgMO1ELIUZzW9UEzAQuB64S\nQiw859j3CyH2CyH2t7W1jaKayJKSaETX10oxOvX3NUXp8cTHaAGYI9NUSoCZ2QkD8p45uer7xJpp\n6QgBQsBFU9LD7V5UUZDqU1PE6LXMyVUXpCMzQU9KnMF3nLQ41XVnJMRg1GsRAialRreq47JZ6WiE\nQAjBiinqdywvzPftCNfrNCGlBJ0oJCXEYNAKAOIM6qe3+XnJxOq1fZ/HRo4LwR997wWWAggh/qgo\nyjdGemBFURyAo8/2XWA+cOSs8ueA58CX5lKd22PLzu9eyesHa/ns8smqbbOSjPzh7iV02VwUpKof\nLCTnH1lJsbz8lVU0mW3MzVf/KuTR2xZw5dwsXB5lTGVc48E7/+9iNhxtYmFBMhmJ6q4fnU7H+9+8\nhIO1JlaHMPkkx+q5b00RTo837PEXws1XL51BcWE6vQ5XSK9CfnH7Am5ZmkdBShy557nUdOd3r+Sd\nIw3cuVh9FMmijARe+eoqWnrsY/oaM9hELc76vEbNgYUQiYqi9D8rXgP8UY19NJGTYuTBK2aGbJ9o\n1Ic1bKlk4pOaYCA1wRCy/fn8XvpcrpmfG7JtglHHJTOzQrY36rUY+1ZQ0c6yUWq8VxSd309n+slM\niuFLa6eGbJ+eEEN6QkwYPQpOsIl6NCvdi4UQP8e3qt6hKMqeURxLooKxjuolpVsSiUQSOYJN1LOF\nEEfwrayn9X2m72dFUZSFQxkqirIeWB8eNyUSiUQiuTAJtjtqDnAzcNNZn/t/vjmyrqmjzmShc5i0\nZL0ON27P0CkDd5xoxWp1hVS3zemhskWmjzvfaOqyDZlmUlEUuu2uIRMcNHfZeWl3dQS9Gx6r0z0m\nKTLBl0bW7ho6xavN6cHhHrr8xd2nOVrbHgnXogq320tDlxWvN/B5cXu89NiHHoOq27rZWNYccv2m\nXuewx48m2nvt9NrdIdu/tLuarh57SLZOt5emKEtlOuyKWlGUmkC/F0JogHuAgOVjzV92VPF/n1QT\no9Pw7GeXMT178E7afdUmdp5sJzVOz70rCzGcs3v76se3UtNhJdGoZ/fDl6HXj/x9cq/NyT1/2YPJ\n4uSymZn84vYhHzJIJhDPbK1kW0UbOclGfnfnIr8+s760mRMtPUzNjOeWczaldPXYWfObTXgU+OUH\n5ZT+9LqxdJ3K1l7eO9JEjF7DPcsnkxwXuf0RrT12Xttfj9ercOuSfL/d1afbLbxzuBGdVnD38smk\nxQ9+L7/iPzfS2usA4LE753NncWHEfB1vHnnrKFXtFpZOTuV7188eVObyeHl5by3tvU4umprOqmmD\n3xdvLGvm/n8cQAGWFCTzz6+p05R/UtnOU1sq0WoEj9w0l5nZ0atAef9oE3/7pJpYvZZf3rZA9ea2\neT95H4vDy4/eOsaxn1yJ0Wgcsa3d6eY7bxyhtdvBVXOy+MolkU0xO1KGnaiFEEnA14F84G3gI+BB\n4CHgMPBCpB0cCQdqOlEUBbvLw74ak99EXd1uAaDT6sJsc5GZOHgjQGOX786rx+6i0eykMGPkA1tt\nlw2TxbeSP9YoV9VqiOYMWcebugFoNtvptDrJThp8sVd3+PpUTYfVz/ZQfReevoW2xTH0SjJS1Jos\neBUFm9NDc7c9ohN1Y5d9YOVe12n1m6jrTFY8XgWPV6HJbPObqNv7JmmA1w7Un7cTtdPt5XRfn6lo\n6fYr77W7ae97IljTYfGbqN8uaRxIQ3qy1aK6/iP15oHzcKyhO6on6tJ6M4oCVqeHipYe1RO11eHr\njx4FyltsLC4c+UTdZnHS2u3rk9E0ngd79P0PYBZQCnwZ2ALcCdyqKMotEfZtxHxxTRFZiUZm5yRx\n8wL/HaIXTU0nKymGxQUpZATYaXvjglziDFqWTk6lMCNeVd1zc5NZMz2D9PgYPrtKvXxLEp3csXQS\n2UlGrpid5TdJA1wyI5PMxBgumekfmejyOTlkxOvRCFg6eewzFi0pSCU/JZbpWQlMzVTXn9UyOyeR\nKRnxFKTFsSCA1GzRpBTyU2OZmhnP9Cx/HfS1832713UaePruJRH1dTwx6DTcvCiP7CQjty+Z5Fee\nGm9gaWEqWUkxfpM0wCM3zSPJqMOgFXxxtfpx5sZFuRSmxzEzO5ErZo9NNK1QuXVJPvkpsSyYlMxF\nU9TvZF84KRmNgOwkA4tVZsEqSI3j0lmZZCcZuXOZevlWpBDDJREXQpQqirKg77MWXxCTyYqihPbw\nfwiKi4uV/fv3h/OQ5y3FxcW0X/Wz8XZjxAy36zsSK+r++oqLi5F9amTIthoZsp1GhmynkSOEOKAo\nSnGwvwu2oh7YeaAoigeoD/ckLZFIJBKJZGiCybMWCSH6X6gIILbv53551tjFUJNIJBKJ5AIk2K7v\niRGSRyKRSCSS85RIZ88aMZuOt7DuUAPuANpPRVE41mimvNl/tyT49IeH67o43R54N+SHpY0s+MkH\nfOpPHwcs73W4OVDTSVuPI2C5yeLkQE0nZtvE0CBKfJTWm6ls7Q1YtqWskVk/XM8Vv9sc0rHLGsz8\nev1xSkLIwBNtuDxeDtZ2DqmF3nGyjdf312F3qte1tnZZWPLoBi7+9aaA5Wabk8c2VPDWoejPLOfx\nKry0t5ZDIZ7zjl4HB2o66R5Cy/wv/7WDWT9cz0u7T4/GzYhgd3k4WOvLGjUShhvPvV4vbx9u4P2j\nTQFtg43nm8uaWfLoBj73l90By4ON55HmZEsPRxvMeL3hS2ERFUlHex1untteBUC33cXnVxUNKi9t\nMLPpuC/FnUAw65wsVLurTOyrNgFw94oCcpMHb+d/4IVDeIF9NV08tbGCB68anJf23cONNJntGPVa\n7r9kKlrNmRDniqLw+oE6LA4PxxrNfr5JohOLw83G4y2Abwf35PTBsqH7/n4IgKoOG1/7xz6e+dxy\nVcf/j9cO02N3sbm8lQ3/cWl4nB4nOq0utlW00dRl58aFg1UTRxvMPL2lEkWB1l4HX7tsuqpjX/74\nDixOD51WF1f/fisfPXTZoPJH1h3lQE0nQghyUoysjOJsYK09dtYdakCnETxx12KyAqgBhsLrVXj9\nQPjxFjUAACAASURBVD1Wp4fjTd189qLBMrQ/bqzgSKNvIfL9dWXcc9GUsPo+Wj481kxVmwWdRvCv\nF08ZNvNUsPH8zUMNvLq/HgANgmvnD04sE2w8/8o/DuBRYEdlB3/eVslXLh3cJ4cbzyPN6XYL7x7x\n3YA43B6WFYYnE1nUrKj78QS4Czn7V94Au9TP/l2gTexn/ypQdLL+43sVJWCkqYHyMN4hScaOQH3m\nbIaLWDcU/f3kvOgSfd/BE6CdPF7vwDUVSv8/u+3dAezPbnqvJ7obs/+rKISWBKH/6w+ntIlWBn13\nFe4HGs/PPs2Bx/sg4/lZvwtlPI8kZ/sezrEhKlbUCTE6vrCqiB6Hi9sCaAwX5icjAK1GMDtATudV\n09KJj9GSZNSTF0Ac/7s7FvDI28eYlhnPt66d41d+48Jcypu6KcqIR6cdfO8ihOCOpZOoauuN6iAB\nksHEx+i4dFYmcQYtRQG08U98agHfeaOUjHgDz31xperj/+r2hbx9uIHrA+j2JxopcXrWTM8IrIMu\nSOX+S6bS3G3ntiXqdaXrv3EJtzy9A6NBy5bvXO5X/ugt8/jvraeYmhXPqukZIfk/VmQlGblhQS6z\ncxIDauuHQ6MR3LEsn9NtFr8nggDfuGoW60oaqDHZ+M41oWfqixTXzMvmaEM3uclG4mOGnzaCjee3\nL85HA+i0Gq6b758FLth4/uRdi/jBuqPMyk7kgQBZDYcbzyPNtMwErp2Xg8PtYeGk8MVQGFZHPVZI\nHfXIkTrqkdUntZwjR7bVyJDtNDJkO42ccOmoJRKJRCKRjCNyopZIJBKJJIqRE7VEIpFIJFFMVGwm\nU4D3S5uwuTxcNTebJOPgbD/9UhuNEFw9NxujfnAclndKGvjZu2UkGfW8+bU1qrMFPfnRCf55qJ6l\nk1N5MoTEAGt/vYnWHgc3Lczl8bvU2TvdXjYeb8Hh9nDVnGwSjZHLdCQZOb99/zgv769jemYCr/7b\natX2n/nzbo43d3Pronx+/C/zVNlWd3Rz/ZMf4/Z4+c61s7j/UnWSKLPVxabyFuIMWq6akx10Q02v\nw82r++pYMyODfJWZij4sbeTfXjiEAvzkptnct3ZwWsCGLivPbDlFrEHLt66cSYJx8JCzq7Kdxzee\nIDfZyBOfXoRWqy7G0vtHm9hY1sLqaencsaxAle1YM+/H72NxeslK0LP3R9f4lf95+ylOtPRy1/IC\niosGy3rcbi9PbjpJa4+dL188VfXG1sqWHn7y9jFi9Fp+d+dC0hNighuNE/+1sYL/2lyJQath80OX\nk5MyeOPeodpOXtxTy5TM+IBywRd21/DGwXpWFKXx8A3+m4eDcc3jW2nosnPnsnx+dsuCkL9HOImK\nFbXD5aG8uYeaDiuHarv8yksbzFS1Wahs7R1IP3g2T2w8SbfNRX2nlT9sPKG6/hf31tJpcbLpeAut\nZnWhzF/bX0N9lx2nRxnQz6nhZGsPFc09VLdbKanz/+6S8eGFPbX02t2U1HWx93S7KtuKJjP7qk30\n2t28drBedd0PvVKKzeXF5YU/bD6p2v5gbSc1HVaON/VQNUTQiLOxONw0dNn4uFLd9wT47htHBqRK\nv36/wq983aFGKlt7Ka03s7mixa/82R1VNHbZOFDTyfvHmlXX/8q+Ouo7bbx+oAGvV73MbqyobO7F\n4vT519rrH/CkpsPCxuOt1JqsvLS31q98b7VPW1zTYeW1/XWq6/+fnaep7rBQ0dzNi3v8jx9N/Pe2\nKtxesLq8PPTqIb/yl/fVUWuysq2ijRMt/qko/7GrhpZuO+8caaSzL3XoSHnvSAOVbRZsLg+vHYie\nIDxRMVHrtBoMOg1CEPCOPi85Fq1GoNMIP/E7wLz8RIQQaDWCi2epl3j015kSZyAtXt1DhlXT0tD1\nCepT4/xTaAYjO8mIQadBI0RAKYJkfMjtu4s36rXMyvaXLQ1HQXIccQbfyjAnSf3K5dp52fSHaJiW\n4Z8aMhj5qbEI4UutmDmClVN/QIhJqer739Kz0ghOC5BSc15eEhohMOg0zM7xTw0wv08SFqvXMj9P\nXTsDFKX76pycHodGExXDWUCm55w5j4HCb2Qmxgzk6g60Wp6SET/Qp+bmqm+npYWpCOEbQ5cUjn3q\nVTX0BycSnEmDejaz+tonJVZPbrK/TK5fjpmZaCQpVt0TmmWFyej7nkBlRdFTh6iRZ+34ZA8ur9fv\nsXc/vQ43GsGQEXG2VLSQl2RkVgid2O12s7PSxOKCJFLi1ekjAarbutlc0c6X1k5VbQtgc3pwe70j\neuwt5Vkjqy8cEpF3ShpYPiWVnOS44H98Du09Vnad6uS6eVno9epfZ+w82UJdh417LipSbQu+iFAG\nrcbvNVEgli0rZuP2T0iNV3+jCfDC7tNYHC7uvzSw/repy0aMTktagFzw4AvHmpFoICtJ/Y2C2+2l\nptNKQWocBl1kJ+rR9qnK5l6e3lLBz2+eRUKC/w2Y1en+/+ydd3gc1fWw39mVVr1YkmXLsmXJvVeB\nbWywTQm9BAj8aCGEACFfGql0AmmQQCgpEAKhhBYIHXcbbNy7LatYtnqvK23vM98fKwnbu9LurLTS\nytz3efx47btn5szdO+fMvXPPOTQb7OSN9P9wZrA6MdrcjEtXPx7Bu/wdE61hXFp4a5QPxL33+o4K\nJoxMYNlkX0cNUNlqZmRSrM+rFACPx8PhOiNTMhNIjFM/puv0ZraX67n+DPV1v9USbHhWRLyjBojT\naYmjd6OSGCDIfuVU/z9oMERFRbFiWmbI8rkjk/nuyNALicXptNDHtQuGhsvnhV44PiMpnsvnhWZQ\nAa+BmhyyeK8PvP6QJEJ20gA3BUh3mRVgpWiGn0QrwRIVpWFiL44t0pg0OpGnb1jYa3u8LqpXJw2Q\nEq8jJYRVu57zD6OETd8+q+9JT1/9pNVqT1rpUcvYtESuT4usMRW5a0UCgUAgEAiEoxYIBAKBIJIZ\nNo7685JG9la0hyxvcbhDKr4gOH15f18NZa2GkGQVRcFkdw3LAgtqOVqv59ND6ncaB4vV6cZ1Gtyb\nVquVf20po81gHWpVIp61R+rZcbx1qNUYNkTMO+q+uP2VPWwq9f6o1y3M5k/fmqdKfl+Vnq3H20hL\n0HHDmTlh33QiiHyW/HEjjQZvvdp/37qAc6erK66x+kgTx5pNTMxM5Iq5Y8KhYkTwzp4q7v2gCIDn\nPi9nw89WDOjxC+sNbCxpJjEmipsWje/arzE8mfO7L3DL8Ic1pVT2sYny686NL+5kR4W3jOXlc0bz\n1xt7f28v8DIsPNa+Ewq1bzmuPtazuwC53uLEYPNftF3w9aLF+FVR+Xf2qI91rmr3jqmqIOKUhzPv\nntA31e0DP1OsaregKGCyu2kzOwILRDDurkUBBShtFjkReuNw3VerWNvLQl8l/ToxLBz1Ly6YggbQ\nSvDo5TNUyy+ekM7IpBjmjksho5cQEcHXi29M98Yq67QSj39zlmr5ZZMyyEjUcfbkyC7N2F/+dP1s\nojUSEnD1goFfOcgfn0ZmcgzTs5JVZ0WLNLK7Yu8TY7RMHRXZscpDyU/Pm4SEN076NyHY868jERNH\nLcqiBcdwi6MebESZS/WIvgoO0U/BIfopeESZS4FAIBAITgOEoxYIBAKBIIIJq6OWJOlpSZK2SpL0\nbDjPIxAIBALB6UrYHLUkSQuAREVRzgZ0kiSd0df3r3huK+f86XP0RptPm6IolDQa/VZKCQaH28PB\nmg4aOn2PPRAU1hv4794aOq3qKrUIwoeiwMeH6tlc2hKW4xusLg7UdPT6m7eaHByo6cDicId0/Fte\n2sX5T22hqVNdNTcAWVYorDdQ0WoO6vuVrRbmPLKWdUcaVJ8L4FizieIGY0gx5S6PzOHaTmr1kR97\nbLa7WfSHjfzwjf1Dcv6adisFdZ0h5YPweDz8Y/Nx/rOzasD18sc3ntrM4j9sHJKYcrPDzYGajpCj\nCCLRnodzRr0Y2ND1eSOwpLcvVrRaKGgwUqO3ccEzW33aC+uNrC1sYlVBY0jOelNJC5tLW/nf/jpM\n9oENz9KbnTy+poQPDtTz1Hr1JTYF4UFvcfLW7hqe31zOrvKBDwH58GAdW7rG1Km4PDLv7a9lS2kr\nq46oL33607cPsrWsnbJWM5f99UvV8nuq9GwobubjQw1BOUCz043R4eHuN31LCgbieLOJVQWNrCtq\noqBOffKYbcfb+PxoC+8fqKM9wsOzqtotNBsdfFbYxPv7BrdUZIvJzgcH69hU0sL2EMbzkxuO8+au\nGl7YUs7be6rDoOFXlLeYOdZqocno4Ny/qB+//eWzww1sKW3lvX11eGR1D4+Ras/D6ahTge7i0Yau\nf/cgSdKdkiTtkyRpn930VZy0x89T+Yn/p7bjT5RRFAhBvE9kZLrV80RwPdyvGwpf/dCuMPwunq7D\ny37Gq6LQMybkEAaczfXVLDyU8XqiTv70641Qbg1PiOfqkT/hAv3d+5HEidpZnZ7BPXc/x5Tb/dU9\n4HKH106dPP7Ceiq/dI8jWVFUr/JEqj0PZ2YyA9BdUioZOCkDgKIoLwIvgjc8KzkjHrPDw4d3L/U5\n0Jyu6jpaSWLaaPUVYM6fPorMpBhGp8SSEqe+5GBfZCTG8pPzJ1PUYOTS2eqyWwnCR3qCjivnZZMa\nF83Zk0cO+PGvmjeG4y1mv5WbdFEarl6QTXW7lRlj1FdV++e3z+DKv22jzeTgzTv7fGPklzNz04iJ\n0pIQo2V8euCShnHRWuKiNDx42TTV55o6Kgm3R8EtKz33qRrOnpJBSnw0aQk6MpPUl5gdTHJGxJEQ\nF8XMMSncclbfFcMGmlHJsVw+N4sOq4u5Y9XHaP/sG1PRRWuI12n5dph1nzwqiZjUWKxODx//YFlY\nz+WPy2aPoaTJSG56AlFadXPRSLXnYYuj7npHfZeiKHdJkvQP4FVFUfb4+25GRoaSm5sbFj2GO40G\nG21m77uSrJRYzG2NiL7yRVEUihqMKIBOqyHG3i76KUiqqqpEX/nBZHdR1ZWNLTk2CsXUKvqpF0oa\njbhlBY0ECc4O0U+9cKo9ry4tVBRFCfg0EbYZtaIoByRJskuStBU41JuTBsjNzRUB8r2w8LfribZ4\n36uPT4vH8u4vRV/54b29Nfzy/SMAaCRI2/CI6KcgEQkq/HP9CztwVHlfy8VHa4hf85Dop17Iu3dV\nz6uBjI3i3uuNU+159a/PPRCMXFjDsxRF+YmiKGcrivKjcJ7ndOa6/HFIeJ3P988Z3OW24cTlszOJ\njdIgARMyIqvou2B48vNvTEEreVNdnjctc6jViWhGJumQgKTY4VtUZTAI1Z6LFKLDDDH7CY5g+in3\n3lW9tlV9jaofiTEVHKKfgkP0U/CIFKICgUAgEJwGCEctEAgEAkEEIxy1QCAQCAQRTMQ46hajPeQ0\ngoqiUNVmodUUWmYjs93N50dbaDGqT9cIUN9p5fOjLdidoaWLfG1HJX9Zf7TX9jd2VvHB/lrAm/Sg\nrMWM3RVawoUOi5OKVnNISRMA6jttYUvFGogvSpq4/oUdbDve7Lf9QLWeZzYco9MS2u/4dcUjK5S3\nmkNKJtRfZFlm6/FWyoNMd3oqdpeHshYz1hDvvTd2VvK91/Zi7CUr2pqCRl7YUhbSsSONzwrq2RJi\nSt2mTjs3vLiT13dU+G1v7LTxzIZjHGsy+m0fTJxumbIWc8jpe/trzx/8sIC7Xt/ba/uJ9jxYwpnw\nJGhcHpm39tSgKHDe9EzmqAzo31fdwbbjbWg1EjcuyiEjMUaV/B/XlFDWYiY5Nornb1pIVFTwzy8m\nu4sHPizE5vSwu6KN+y5RVwj9H1+U8eym4yiKwvEWC8/fvPCk9t99WsR/99UiSRIdVhcdViefHm4g\nMzmGmxaNV3Uuk93FW3tqcLplFowfwfIp6hKBlLWY+PSwNyXmFfPG+E32EU5uf30/sgL7/r2P8j+e\nvNmrxWDne6/vw+WW2Vji35EL/KO3OPnkUAOzslO4YMaoQT33v7ZW8vnRFqI0Eo9fPYdx6fGq5D8+\nVE9Dp520BB23npWrSnZLaTMPf1KMrMDyv2zm4MMXntS+pqCRX39Q4I3Rrx96B9Qf/rHZm0JUkiTu\nvXgql83JViW/8qkvsLlkdlXomTY6mTMnZJzUfsO/dtFudvDWnsFNreqPVUcaqGqzkhQbxXeX5qHR\nSEHL9tee//Ttg3x02Jsz//y/bGHjz5af1H6qPQ+WiHDUsvxVejyTXf1TTHf+bo+sYHG4VTvq7uTr\nFqcHpywTpWKhwer09Mxu9Rb1ecSr2iw9ae6aDL4z1QaDd3aoKArVekvPrCeUfrK5PDi70geGkvPc\neMI5zSGcv7/0pFD0M/HrtDlxd+X1NNgGNp/7YDCUO9C7Uz4OdB78YNBbvDNZt6ygtzpUO+ru+8Ds\ncKMoCpIUvFEub7X0jCW7yzddZF2ntefebI3wPOSBaDJ49VcUhYYO9StO3WlHFby5vE911N2zV6fb\nM+ROpXtMWJ0ePIqCN2gzOPprzyvbLT2fOyy+Y+ZUex4sEbH0HROt4ayJ6czPSWXh+BGq5ZdMyGDe\nuFTOmZIRVMrEU7l7xSQWjh/BnedMIF6nbpiNSo7l1rNyyc9N4/srJqo+928uncGcsalMykzkmevn\n+7ZfPpO5OSM4My+NX104nZS4aGaOSQ4pvV1mUiznTc9kdnYK56icTYM3lesZuWmcmZfGzBBSY/aX\n86dnEh+t4bLZo33apoxO5ubFOUwZncxDl6t7Cv66kxwXzazsFM4dgljh7y6bwKK8NK5ZOJa549Tf\n+xfPzmLmmGQum5Olykl3n3veuBRGxEXxyGW+Y+aOcyayYmomM7NT+P1Vs1XrFkncc94UFk9I59xp\nmXxnSa5q+Z9eMJkEnYZZWUncsNhX/lcXTWXyqKSQbOBAc+HM0V4bOSeLaJUpRPtrz1+7NZ+RiTpS\nYqN4+du+6X9PtefBIuKohxkiRjE4hlsc9VDqIsZUcIh+Cg7RT8Ej4qgFAoFAIDgNEI5aIBAIBIII\nRjhqgUAgEAgimKHeoDcsuPO1veys1HPhzEye/Jbvhq9AnPWHjXTaXDx06XS/GzH6wuH2sKOsHa1G\nYumkjMACQ8iW0mZ+8s4hEmOi2HTPMmJi1O2+/8lbB1hd1EReRgLr71keWEBw2rOmoJHnvyxjfk4q\nj16hfkPXyj9/Tk2HjRWTR/LybWeqkpVlmVd3VNNucXLrEnWhkINNq9HBZX/dikuW+c9ti5g5Vl1t\n8Pf21vDIJ0Ukx0Wx6/4LVJ+/rsPKkToDU0YnqZYdbG56cSf7aztZOTWD529WX++9P/Y8VMSMOgAO\nh4MNR1sw2d18cKBBtfzP3zlIg9GB1SXz2KoS1fKHajo5VNvJ/uoOShojO5bzZ+8dptPmpq7Tzo/e\nKVAt/0lBIy6PwrFmM3sr2sOgoWC48ce1JVS2WvjwQAOF9Z2qZPdVtlHZbsMjw6bSVtXn3lHezrqi\nJvZV6Xlzd7Vq+cHkrjf20mxyoLe4uOsN9Ru5HvmkCKtLpsno5Edv7lctv7awiaNNJlYXNKqWHUzs\ndjvbK/TYXTJrC9Unf+mvPQ8V4agDEBMTg7Yr7CNKReB8NzOzU3qi+BJ06kvApcbrAJAkSImLVi0/\nmKTHe2fQkgQzstSHb2lP6N4xqeriaQWnJyO6xn+0VkNmYqwq2dy0r8aQ+jsXRifHou2650clx4Vw\nhMFjSmYS3dFpY1LU65oQ411clYDZKmfj8JWdSo5wGxUbG0u3GQ/BnPfbnoeKWPoOgrfvOIOXt1Xz\n8wumqJb97tkTcMsye6s6+Ov16pfupo5OIjkuCq1GIjNJnaEabNb/bDm/eO8gkzMSuWvlZNXya3+2\njPvfL+KWxePITotswygYHN783mLe2F3FskkZZKaoG/8ZKfE8ee0sXt1ezePfVB9bP2lUEr+9ahbt\nZgdn5qXzF9VHGDwev3YuI5N1GCxuHvumejuz98ELuOv1vd58EssnqZa/Yu4Y6jttZKXE8lfV0oPL\n69/N559bKrnv4mmqZftrz0NFxFEPM0SMYnCIOOrgEWMqOEQ/BYfop+ARcdQCgUAgEJwGCEctEAgE\nAkEEI95RCwQRTl/L4jD4y/QCgWBwiQhHbbS5mHT/amRF4dbF43nkylkntR9tNPLndaVoNRIPXDrd\np/BGTbuVz440kBwbzbULxxIbffJuvM8ON/DO3hqyR8Tz2ytnoTuljOVrO6pYV9TE7Oxk1WXNnE4P\n3319HzV6C1fPz+anF0xVJV/WbOJH7xzE6ZZ58NLprJzWd5nB4gYjufeuIiU2isO/ubDP7/qcq6mT\nC5/djqzAgpxU3v/BUlXy/WVdYRP/2VXFmNQ4HrtiJrEqC6A8s/EYeyr1LJucwQ9WqN/wIvDPkXoD\nufeuIislhp33na9KdlNxMz9+5yAK8OCl07hxUa4q+c2lLby8rZKMxBh+e+UsEmPVjYntZW3sr+5g\n5phkzpuurkSn3enmkU+Lqe+wcuOZ47lkTt+FbspbzeTdt4qYKImtvzyPkcnq8gQs/sNGWs1O8tLj\n2fjzFep0dXn44EA9HVYnl8zOIi9DXfGhjw7W8dhnxURpNLxw8wIWjE9TKV/Pe/tqyctI4DeXz+yz\nFHAgex6Ijw/W8/SmYyTHRPPitxcyWuUu9v7Yc7PFydInv8Ds8JA/PpX/3nWWKvnGThuPfVaM3eXh\nngumqC7Z3BsRsfTdanbglhVkBT494huHt72sDbPDjcHmYke5b3xtSZMRh0um1eSgvtO3VOSXx1tx\neRSq2ixU+ClQv72sDY+scKjWoLrUX1mrmco2Mx5ZYXNpmypZgHXFTRhtLuwuD6uONAX8vqdr858x\nhDKTz2+uxKN4S9UV1BtUy/eXzaUtuDwK1e1WylqDL/HWze4KPR5ZYaefMSDoP40G9aUc39pTg8sj\n4/bIvLevTrX85tJWnG6Zhk4bRQ3qx2RBnQGPrHCk3oDajbEV7Raq2iy4PAqbjwWOqbU5PSgK2F0K\nH+xXV3dZb3bSYnJ0lTe0qpIFaDLYaTbacbrlkPIpfHSwAZdbxuZ08/7+etXyW4614pYVjreYqe3o\nW/9A9jwQawqbcLll2i0OvihVH+vcH3v++bFWTHZvydSCOvX9vKdKj97ixOr0sPW4en/QGxExox6Z\nFIOskZAVhavmjvFpXz5lJLsqvNm5lk30zc41IyuZyjYLybHRZKf6Pn2tnJbJW7tryEmLZ8LIRJ/2\ncyZnsK64mdnZKSTFqosDnDQykUmZSVS1WzhvuvoygRfPymL1kUYcLoWr5vle+6loJQmJ0GKq716R\nx8cFDXhkWDBuYJ701LByWiZ1u6oZmxrHpJHqy5EumZjO3io9yyI4Q9tQ7N4eqHOOS1Uf/nfzkhz2\nVOmRZYWbFqvP3nXe9Ewq2yxkJsUwc4z6+N2541I4WNPJjDHJqstcThqZxKTMRGr0Vs4LsJIFEK/T\nopEgJkrDDWfkqDpXWqKOUckxtJqcTAxh7GelxpKVEkuH1RVSidlr87MpbDAQpZG4Ln+savmV00by\n3r468jISGDei7xwHgex5IC6bO5pjzSaSY6M5L4TSq/2x5+dOGUlKXDQmu5v5Oept5OIJ6awvasLu\nklk5VX0p4d4Q4VnDDBH6EBxDFZ4V6jEDvYcOlWCuQ4yp4BD9FByin4JHhGcJBAKBQHAaIBy1QCAQ\nCAQRjHDUAoFAIBBEMGFz1JIk5UqS1CxJ0mZJktaH6zyDQX2Hjbf3VNNuVr8rFkBvcVLVZlG9K7Wb\n/dUdFNSpqxw0VHx8sJ6dZQO321ENZc0m3t5TjdnmHJLzCwYeu9PN5tIW6jvV75QGaDHa2VzagjmE\nKAmAY80mdgzReFZLYb2BfVX6kGRlWWbb8VbK/UTFBIPJ7mJzaQttZntI8oOJ3uxkc2mL6h3h3ZS3\nmtl2vBVZlkOSD8Weh3vX9wZFUW4O8znCzh2v78Vgc/H+/nr+d7e6uDqD1cWbu6pxywqL8tI4S+WO\n5TWFjby6vQpJgp+ep74oyGDy+OoSPi1oQJIkHr9mNssmDdyux0B0mJ18/4392FweNharD+kQRCZP\nbThGQZ2BeJ2W526Yr2oXr9st88CHRzDa3UzObOZ3KotVHGs28ZtPivDIit+wzkhiT2U7f9lwDEWB\nWxaP5zKVu61f2V7F+uJmojQSf7h6tk+uikD89rNiqtutjIiP7OpZAA9+fIR2s5OctHj+/K25qmRr\n2608/FEhblmhpNHIHedMVCUfqj0POKOWJGm5JElzuj5fJ0nS3yRJukeSpGCi/VdKkrRVkqR7/Bz3\nTkmS9kmStK+1VX2t2MHC4/FgcXifxg029U9gFqcbt9wd+6xevsXoncUrCjSbIvtptalLP0VRaOwc\nXF3NThd2t/cJV28RM+rThe7f0ubyYHV6VMna3TKWLpkOq/ox0WK04+m6d1tDXE0bLFqMDroX7FpM\n6nVtM3v7xy0rPZ/V0Gn12jZTiCsXg4Usyxi77HgoY6LN4uix520hjIlQ7XmfM2pJkv4OzAFiJEk6\nBiQCa4GlwL+Bm/oQbwSmAA7gY0mSNimKUtDdqCjKi8CL4A3PClrjQUar1fKj8yazsbiFK4OIcz6V\nMalxLJ86Er3ZyaIJ6rIBAVyzYCwmu4torYaLZ2XxW9VHGDx++Y1pPLG2hIzEGK6er76v+sO4tAS+\nc1Yu+6o6uG1ZLv/vlUE9vSBM3L18Iu8fqGd2dgqjktXFeSfGRvG9syewt1LPpQGyjvlj2eSRVLRZ\naDc7uGXJeN5UfYTB46KZo2k02LC5ZL4VQpz0d5bmotVIjEmNY+H4Earl714xkfVFzZw1KZ17/qla\nfNDQaDR8f/lEtpe1h5T3Yn7OCK6an019h42bFqmLpQdfex4sfcZRS5JUrCjKDEmSYoF6IFNRFI/k\nzSxQoChKUGtJkiTdDRgURXnLX7uIow4eEaMYHCKOOvA5uxFjKjhEPwWH6KfgGag4ajuAoih2fIBt\nFAAAIABJREFUoFpRFE/XvxWgz3VcSZKSTvjnUqA8kDICgUAgEAhOJtBmskxJkn4GSCd8puvfgXYK\nnS1J0m/xLn1vVRRld/9UFQgEAoHg60cgR/0vIMnPZ4CX+hJUFGU1sDp01QQCgUAgEPTpqBVFeXSw\nFNlR3obd5eGsiRk+ZSoD0Wa28+r2akYmxXDrWbmqz/3vbRW8vrOapZMy+L3KEA6A7/x7N0UNRn6w\nchK3Lc1TJSvLCrsq2nG4ZZZMTA947U63zNrCRmZkpZCT3ndyfH/c9soeqtutPHT5dFZOVVcWsKyp\nk2te2A2SxMc/XExuuvriAP2hqs3C0SYjM8ekMC5N/bUL/GNzeVhX1MSZuWmMSNCpk3V6ePSTIhwe\nmYcvncGIxJPlDVYnr+yoIkGn5baz8nzKI763t4ZHPikiLUHHtnvP6/e1qKWgrpNGg51FeWmkxvd9\n7W5ZYV1RE9mpcczKVl9A5LlNx9hY0sz/nTGeG/1sRPr4UD3FDUauO2McE/0UD7r8ua20mh08cc1s\nlqu8dx1uDzvK29FpNSyZkI5Go66ASbvZwd6qDsalxQVVPKU/9vxYk5H7PywkMymGf9y80Ke9stXM\nu/vqmDIqiW8uyPZpf2ZDKW/urmHRhHT+duMCVecGbynhGr2V/NwRZCSqK2Wq1p4HS5/vqCVJeriP\nPw8NiAaA3SWzu0LP4VoD+6o6VMu/vqOavVV6Vh9pDCk5wdMbj9PQaeN/++toMqhLrLCltJmtZe20\nW5w8ua5U9bmPtZjYXannUG0nB6oDX7vB5qKk0cSqEMrHvbGriu1lbdR1WHnww0LV8t95dT8Gu7fc\n6K0v71ct319WHWmkpNHE6hCuXdA7RpuL4gZjSCUFX9pawdayVvZUtvPXL477tL+7r5ad5e1sLGlh\n01Hf4z/0SRFWl0xdp51fvXsoJP1DRW9xsqmkheIGI5tLA4eImuzeftpQ3IzBqi7U0mx38/K2Sipb\nLTy9wddO1HZYeXtPDYdqO/nnFt/tPI9+eoSiRiMtJge/+t8RVecGOFDdyaGaTvZU6jnaZFItv+lo\nCyWN3msPFGbaX3v+4EeFlDYZ2Xq8lX996dsXL22r5EBNB+/sraHST3z781sqaLc4WVPYRJ1eXfy7\n2eFmfXETJY1GPi9Rfz+otefBEmgzmcXPH4DbgV8PlBJaDWi6StSFUr4xMymm6zhSz2c1xOu8Tz1R\nGonkaHXnH5MST/ezafdx1JAcG013db7kIK5dqwm9nyZmJPT0c6DZgz9OLCGak6aumPtA0N0/oVy7\noHf6c+/lpMX3lJcc66f8YWZXSJUkQWay772Z0HXPSMCssYO7QhMbrSEm2msCg7n27nsvNlrbIxf0\nuaLomV0l+knakhwT1dPubxY3bXRKTz+nhpBUpPv6JAmS49TnueqWj43WotP2fe39teejesaMxIQM\n38QrGV2rNjHRGlLifO1Y92+jlSA1Rp2di9ZKxHX9DsHY41NRa8+DJegyl127uH+C10m/CzylKMqA\npIDKz89X1nyxHYfb4/dmD4bdFe2kJ+iYNCop8JdPoclg5cUtlVw5fwxzx6mPIdxU3MTaombuu3g6\naYnqHWCLyY7Lo/itpX0qCxfm897azYxJjQtpWWVTcTP7q/Xcc/4kolU+lAD86t1D6KI1/O6bc1TL\n9he7y0NDpy2oaxfhWYHP2c38hQv5cN2X5KTFq14SBdh2vBWb08MFM0f7bd9f3UGcTsOMLN8lU7vd\nzv97u4BFE9K4c/kk1efuLwabiw6LM6hrz8/P5721W0hP1JGsss4xQHmLmTVHGrkufxyZKb4x4fWd\nVipaLSzKS0cX5esM/7u3hsJ6Aw9dMhWdTr2dqe+0Ea2VyExSX3fcIyvU6K1kJOoCZofLz8+nv/b8\nlW0V5KTFc94M3zHldsvsqmxnfC+1sev0Zp7eUMZ1Z4xl0QT1tetNdhdtXZnLtCHcD2rsebDhWQEd\ntSRJacDP8CY3eQ14VlGUgZvTI+Ko1SBiFINDOOrA5+xGjKngEP0UHKKfgidYRx0oM9mfgavxZhCb\nrShKZCe8FQgEAoHgNCPQi5afA2OAB4EGSZKMXX9MkiQZw6+eQCAQCARfbwKFZ4l61QKBQCAQDCHh\nLnMZFC6Pwg/e3I/N6eGn508OaUNXX7y4pZw399SQlRzLK7edSZzK3dmfH22mqN7IwvEjfMpUyrLC\npwUN1OqtLJ+Syeyx6uIrTXYXHxyox+H2cOW87ICFB0x2N3/ddJy541I5Z8rJyeEURWH1kSYq28ws\nnZTB/Bx1/Virt3D3GwewOj3cd/E0n81B7WYHHx6sR5Ikrp6frTrmtr88u+kYeyr0nD15JN9foa68\nnKB3Oq1O/vb5cc6dNooZYwZ253VBXSdPbzhGnE7LQ5fOIOuUDTb/3VPD81vKGRGv49+3nuEThx2I\nHWVt7K/uYGZ2MudOUxdb7JEVPjpYT5PRznnTM5k2uu9rt7k8/O3z42SPiOOKudk+G412V7Szp1LP\n1NFJfMPPxrqNxc2UNBrJz01jycT0k9rcbpnffFpEVbuFb+WP48p5J8cHO9wePjhQT4fVySWzssj1\nsxu6L1qMdj46VI9Oq+HqhWNVb4YrrDewubSFcWnxXD5nTJ8b72RF4bUdVdhdHq6YN4aslJN/8zaz\ng48O1qORJK5ZMJaUU3ax1+qtfFbQSHJcFNcsGKt60+zrO6tYV9jErOwU7rtkuipZt1vmsVXFVLSa\nuWbBOL9x2n2h1p4HS0Q4aovTTXtXabUtx9oG3FGvL2nG7ZGp7bByqKaDJSpqQsuyQkGdAUWBw3UG\nH0dtsrupaPVGrRXUd6p21NXt1p5SfqVNpoA/rM3lwS0rFNR1+jhqi9PDsWZvjOSReoNqR72uqLmn\n9NunBQ0+jrqsxdxTxq6izczCBPXVwPrDrnI9sqKwvbxtSB11uDZ+hYNgNrc53DIuj0JhvWHAHfWX\nx1qxOr0lKvdU6X0c0OrCJlwemRaTnW1lrVw+T51hPFTX2XU/GFg5NbMnhCkY2i0OavTevAlH6gwB\nHbXd6cHlUahqs9JpdZJ+ShhVQZ0Bt6xQ1GBk5bRMok8IY/LICkfqDd5z1Xf6OOrqDivHW7xbgLaU\ntvr0U2OnnSaDtyxicaNRtaMubTZhcXiw4KG6zaraTh2pN+DyKFS0WjDYXH0+pDvc8kk27VRHfbz5\nKztS3mZmwSl2qrjRiN3lwe7yUNdhY1Kmb/KXvth6rBW3rHCothOT3aWqhnmjwU5pV5z55mMtqh21\nWnseLBGxtJ2giyIjUUe8TsuKqYFSiKvnG9NHEaXVkJMWzzyVzkujkZgzNoUojcRcP4M7KTaKCSMT\niNZKzMlOVa3b+PR40hJ0JMRomTo6cGhZXLSWKI3EnLG+50rQaZkyKolorcTsEDInXThzFCPidcRE\nabl8jm+ZysmjkkiKjSI5LpoJGepunoFg8cQ0ojQSSyeqD7kQ9E5MlAZdlCakbFuBWDE1k4QYLemJ\nOhZPSPdpv2TWaKK1GkYlx7Jskvp7f97Y1K57M1WVkwZIT4ghJy0eXZQmKMcVp9MSrZXIy0jwm4eg\n207MHJN8kpMGbwz27OyUXu/d8SPie+7d5X5sYFZqLKNTYomJ1jAjS/3D1NRRSSTEaBkRH834DPUh\nU7OzU4jWSkwYmRAwNjomSkN6lz339/AzeVQiSbFRpMRFM9GPHZmRlUxstJbM5BjGjlCfr+HsKSOJ\n0kjMG5eqykkDZKXEMnW093dYMUV9GUy19jxYgo6jDiciPCt4ROhDcIQzPCvUGfVQhGf1Rbc+YkwF\nh+in4BD9FDwDEp4lEHxdGU7L2wKB4PQmIpa+BQKBQCAQ+Ec4aoFAIBAIIpjTZum7r9ywgbA63eyt\n1DMzO5mMRPW79PqbG3YwWV/YyP6aDn5xweSQcn0fru1AkvxviBH0zem6nP7ajkrsTg93rVCfq1uW\nZXZV6MlKiSXPT2nH04lAub4DyreaaTU6ODNvBBqN+jlWf3J9DzafHqonKyWW/DzfDYiB6K89b+y0\nUdZq7jXn+lBwWjjqH711gM2lLUiSxNPXodpZ/2FVCcdbzKTERfOPGxf41MztC4fbw1u7a7A6PUzP\nSuaiWeofFAaLnWWt/PidQ8iKwraydlb9+GxV8p8fbekpwffDcydx9uSB36EvGF48ue4o/9paiaIo\nlLda+NO35qqSf3lbJRtLWojWSvzxmjl+iyycDrjdbm58aRdWh5v3D9bzxS9WqJKvbDXz8EeFuGWF\nC2eO5rvL1NW9L24wsq6oCUmCaxeODblYxmDw+8+KWV3YiEaSePq6uaqddX/sucnu4v4Pj2B1etg2\nrk11HHa4iIzHhX7SbPTGFyqKQkWbJcC3fdF3xQ6bHW6csqxK1uVRsLk8gLeubyRT3mZB7trl39l1\nzWrojuMEb7yhQFDeaqE7cqQ7JlkNLSYH4L2P9GbHgOoWSdjd3upvAOYA9Zz90Wp24Ja9/dwWQj8Z\numyTooDR5lYtP5g0ddlzWVGo7bCplu+PPbc6PT32vDseOhI4LWbUv7tqFvd/WEhmUgx3nKM+Ecb3\nl09kVUEjZ+alEa9T1yWJMVF8Y8ZoajusLBw/sIlaBpqbF+fyxdFWKtssPHS5+ifFq+aPQW9xoNFI\nXDEnKwwaCoYbj189h1te3o1LlnlK5Wwa4LtL83hjdw3ZqXEDnugokkiMjeKOZRPYUNLM9WfkqJY/\nMy+dy+dk0Wh08O0l41XLLxifit3tQafVMG0A43vDwa8umsrja0oZlRzDNxeMVS3fH3s+KjmWmxeN\np6jBqDrZSTgRcdTDDBGjGBz9jaP+OiDiqNUh+ik4RD8FT7Bx1KfF0rdAIBAIBKcrwlELBAKBQBDB\nCEctEAgEAkEEMywcdWFNG1MfWM20B9dQ0+a7s9TqdLOppJm9VXq/8k+sLmbS/as48/cb/bY3Geys\nK2qirKt6zXDmG09vYcoDq7n3/UOqZU0mE5PuX0Xevat4e1dlGLQTDEdmPLSGCfet4pVt5apltx1r\nYfpDa5jzm7Xojb47eBs7bTy5rpS399QMhKpDyg/f2M+UB1Zz1d+2hSQ/79F15N27inve3j/AmvUf\nvcXJ+qImihuMQX1/Z3k7Xxxt6dnpfiKHKluYfP8qJt+/msoW9VE6z24oZcoDq1n2xOeqZcONLCvs\nKG/ji9IWHG7faw+VYeGob3x5Hw6Pgt0tc+0LO3zad1W0U1BnYNvxNqrbfX/4F76sxC17Q0F++2mh\nT/u6rgG4+kgjLo+67fyRxOcljRxrNuP0KPx3b71q+XOf2YlbBgV44KPigVdQMOy47LkvsbpkZAV+\nu+qoavkfvHUAm0vGaPfwfy/v8Wl/dUcle6v0fHSwnsO1HQOh8pDxWWETTo/CoToDZa0GVbJPrCqi\n0+ZGAT483BQeBfvBppJmihqMrC9uwhggvMzuktlV0c6h2k72V/v+pjf+ez8uGVyywtXPb1ety3Of\nl+H0KNR12Pjz2hLV8uHkWIuJ3RV6DtX4v/ZQGRbhWemJOowO79P46JQYn/buIuhajURCjO8laTXg\n7vK/07N8QxOS46LQW5wkxEShVVkqL5IYk/xV32hDuIzxGfG0WrwGRhc1fPvhRL7uO7v7y7RRiRQ2\neOvzxoSQpSk5TofR7r13J6b71lDO6KrpHK2VSIv3vbeHE1oJPF1BNNmJvddr9sfME0qMRuKdlxwX\nDR02YqO16LR9jwOtBiTJG7Od7KfM5Ij4aKwGbyx4ZrL63zxKK+Fxezt62ujIymaXFBvd57WHyrBw\n1F/88lxueWkXcdFaXrz1DJ/2/Nw0RibFkBAT1XPjn8iuX6/k2//ey3kzRnFtvm8M4qWzx1DbYWV0\nciyaCE8B2hfTstN4/OqZvLOnjievn61a/n93L+Pml3bS0GHj81+eGwYNBcONJ69fAByguNHE6p8u\nVy2/7dfncuu/dzEqKZY/fWueT/vty/KYnpVMdmoc49IjN1tWMHxw9xIe+aSY25eNJy5OXR3ly+aN\n5UCtng1FrbzynUVh0jB0zp8+ismZiWQkxRAbre3zu9FaDTcuysHhkhmX5vubbr/vfL71/HbiorW8\n/r3FqnXZ+auVfO/1/Zw3YxSXzxunWj6cZKfGceOZOTjc/q89VEQc9TBDxCgGR3c/iRl174g4anWI\nfgoO0U/BI+KoBQKBQCA4DRCOWiAQCASCCCasjlqSpKclSdoqSdKz4TyPQCAQCASnK2Fz1JIkLQAS\nFUU5G9BJkuS7C6wLp1vmsue2cv5Tm/niaHO4VDotaDE5uPmlXfxjc9mAH9vqdPOfXdW8+GU5jQb1\nVWsEw5P6Thu3vLyb1QWNA37sZqOdf31Zwes7qzA7IrtqUyBaTQ5W/PkLbn5pN07nwMXInm64PQo/\nfOsA3311DwV1nQN+/KNNRv7+RRkfHqzDIw/9HqvBIJwz6sXAhq7PG4ElvX3RYHPRYXVic3n45PDA\nG4vTCYvDjcujsKOsbcCPXaO30mZyYHF4ONpoGvDjCyITh0vG6Zb5orRlwI99tMmE2eGm3eykKoQS\ntJGE0e7C5ZGpbDNTUD/wDuh0weJ009plRzaXtg748Y/UGXC6ZararBFVijKchNNRpwLdaWwMXf/u\nQZKkOyVJ2idJ0j631UBKXDQxUVoumzM6jCoNfxJiotBqJBZPUFdMPRjGjYgnPVFHbLSWKRFeCk8w\ncMREa4jSSJw9JWPAjz11VBLxOi0j4qMZP8zDr5Jjo9FqJHLS4pmZnRpY4GtKvC6K9EQdcToty8Mw\npmZlpxCt9f4OaQnq4tWHK2ELz5Ik6f8BrYqivCtJ0tXAWEVRnvP33YyMDCU3NzcsegwEbo+C3e0h\nNlpLVAhx1g63jNsjE6+LQm0+Fafbw7Fmb2rT6aMTqa2tJVL7SsG7fK6VpICxlv7wyAo2l4eYKA3R\nAZIq+KO0yYjTo5CeoMPZ2Ryx/QRgsrtxuD2kxutCGlMdVu9MIjVO5zOmPLJCfaeNKI3EmFTfeF6z\nw0Wt3kZMlJYJIxOoqqqK6L6KFE7nflIU770bpdEQE63+3qtss2B2uImN0hBta4/ofooke37o0CFF\nUZSAHR7OhCc7gbuAd4HzgVd7+2Jubm7Ext0pisILWyqwuzykxkdz29I8VfItJjtv7vLmMZ6dncL5\nM0apkp90/ypGd2VVc8VoyV31YMT21bbjbT351q9dOFZ1wP/be2poMtiJ1krcec5EdCoyYb2+vZyH\nP/0qxeWYjY9EbD9Vt1v49fsFKArMHpvCg5fOUCX/0cH6ntzY/3dGjk+B+9tf3YO70vs73HXeZO44\nZ+JJ7dMfWsNIl3dQffv8Sbx+700R21eRxOkcH/z50WYO13qzEt64KIdRybGq5HPvXUX3GlxGBN97\nkWbPOXTxgWDkwrb0rSjKAcAuSdJWwKMoim+i32FC91NXVAizPI0k9Tx1aUPI63niA190hGdN056g\nnzYEXbtlNBpJ9ZNqKDP4oUKjkdB0XWC0Rv2YOjGFY7SfMXXiakScn3458adJjBm4NIeC4Yu2axxK\nEj1j83RlONpzkZksCDosTqraLUzMTAwpf2ut3kqH1cmMrGTVg8NoNLLkye1EazUceuTCiH6ql2WF\n4kYjiTFR5Gb45nUOhNXp5lizmbEj4vymgg3ENf/YxpF6Aw9eMo3nfnJ9xPYTwMGaDspbzFw0K4vE\nWPULW+uLmlAUuHCW754Ou93NH9aVMDo5jh+snOTTXtbUyff+c5B5Y1N55ob5ET2mIonTuZ/cHpmS\nRhOp8dEhpb584H+HeWd/HedMSufI8z+M6H6KJHsebGYy4aiHGaezsRhIRD8Fz1D1VV/pXbvTm0YS\nYkwFh+in4BEpRAUCgUAgOA0QjlogEAgEgghGOGqBQCAQCCKYiKhHrSjekBO7y8OFM0czYpCD2Esa\njeyt0jM5M4klEwc+kUhfbDvWwq2v7EVW4KfnTeInF0wd1PMPJ2Y9vBaz00NKrJbDv7loSHU5XNvJ\n4bpOZmWnsCBnhE/7jrI2ylrNLMpLZ6rK5DFWp5sn1pZisLr4wcqJTBmlTv6lL8v507pSojQaPv5/\nZzF5dLIqeYHgVC54ajPHWy1EaaDsD5G3fyBSWHekgbvePAjAbUtyeOTK2QNy3IiYUTvcHirbLDQa\n7BwOQ27YQOwob6fd7GRXRTsO9+Dm8L3/o0I8ijdZyD+3Vg7quYcb5q78ygb70OdZ3lbWRrvZybbj\nvqlcbU4Puyv1tJud7CxXn+p1R1kbRxuNNBpsfHa4QbX8P7aU4/QoWF0eHvmkWLW8QHAqx1u96V/d\nMjz68ZEh1iZyuf+jwp7Pb+yuHbDjRoSjjtZqiI3WotVI5KarD+vpLxO6QonGjog7KUZ1MLj0hPCa\nudkpg3ru4UZ31GEkhJN3j5k8P2FosdEasrsyguWNTFR97OljkonXadFIEvP8zNYDsSBnRFc8LHxz\nQZZqeYHgVOJOSD70rTPHDqEmkc0F0zN7Pk/OHDhfFhFL31qNxPfOzsMjK0OSuGLltEzOzEsjLlqL\nNMjB/r++ZAYXzRqNye5m2ZTMwAJfYwofWsG7B5u4bv7Q54O/aNZozpkyknid73iVJIlrF47F5vKQ\nEKP+FstOjefvNy3A6ZZJjVf/GuilW89gb2UrIxNjyB0plr0F/afkdxfz5q5KzpqQSd4AOqDTjcev\nnceV88ZgtLm5cPaYATtuRDhq8M6qhzK5VCgGdaCYm5M2ZOceTiQkJHDbsomBvzgISJLU55jRaPpu\nD0S8LooQfHQPZ+SNDF1YIPDDTYvVpdv8urJk0sBPuCJi6VsgEAgEAoF/hKMWCAQCgSCCiZil70jG\n5vRQVN/JnOxUdH7eSQZiT0Ubh2o7uXO5b97lYDDaXWgDLLVGCrvL28lIimFipvpNVA6Hg1d31HDh\nrFEhvVt1eWSMNhfpIeQJH2xMdhdtJkdIm80AXttejtOtcEeIY0pwMsMtnak/qtrMONwyU0MMx3t2\nQymzxyZz7vTTewNif+35tmMt7K/uGNRQ2si3/BHALf/eTWOnjUmZSbz23TNVyX50sJZ7/luAAryx\nu4Yvf3WuKvmqNgsfH2pAI8F1Z4xTJTvY/O7TIt7dX4dGI/GPG+dz1iR170kXPb6ZTpubJzccZ//9\n55GswuG6PTJv76mh3exkXk6qWtUHlU6rk1+8dxiT3c0ls7O49axcVfK3vLSLrWXtAGw82sx/71oa\nBi0Fw4ltx1t54MMjeBT40cpJXH9mjir5JX/cSKPBAcDjV8/k/87MDYOWkUF/7Pk7e6q494MiAN7a\nW8vu+88Ph4o+iKXvAHg8HpoMdsBbNUUt64qa6C570mJ0qJZvMNiQFQW3rPToEakU1BtQFAWPR2Zn\nhV61vNnhjY92yQqlrUZVsna3TLvZCUB9h031uQeThk4bJrsbgGPNJtXyBXWGns/FDerlBacfB6o7\nccsKiqJwqFZ9Loq2rnsH4NPDTQOpWkTRX3u+pvCrvtGf0GfhRsyoA6DVarlu4Ti+PN7KJbPVLwk9\nfe1stpVtxub0cNvSXNXyc8em0mpyEKXRMC1LXYaqwebnF0zlgY+OkBwXzV3nqN+dff70TD4/2sL4\ntHjVu5YTY6JYOimDqjYLiyek84zqsw8eM8akcM6UkVS3W7hB5cwH4IlrZvGDNw8B8PurZg2ITqfD\n0u/XmVsWj+dwXScOt8wd50xQLf+dxTm8vKManVbDX6+fGwYNI4P+2vMXbpjLgj9sxuGWuXGR+ns3\nVESZy2GGKCEXHKKfgic/P5+28x/ttT1cjjqSHg6C0UWMqeAQ/RQ8osylQCAQCASnAcJRCwQCgUAQ\nwYh31AKBIGz0taQsEAiCI2Jm1MUNRvZXd+CRh/6duVpq9VZ2VbRjdrhDki9qMHCgZnCufUtpC6/t\nqMJgHbwdiwNFq8nBzvJ22s3qd88PNO1mry6tpvDocrTJyP5qPS6PrFrW7ZHZX62npFHdznlBZFPW\nYmJvlR6nW/2YcLpl/ru3ho8P1YdBs9OLzwrqefjjQipazUOtSg8RMaN2uGXWFXm3vbs9MosmDG5N\n6P5gdbr58GA9HlmhodPG1QvUVZYpazGzvqgZAI+scEZu+PJ+l7eaeX5LOYriDRG675LpYTtXOPjw\nYB0Wh4fiRiO3LxvavMMfHWrAaHNxpL6TO0PY4d4XtXora4547we7S2bppAxV8nuq9OzuCo+L12kZ\nPwQV6QQDS7PRzqeHGwEw292snKYun/S7e2v4tMArn6DTcv6MoS9sE4nU6i08saYUWVE43mzi7TuX\nDLVKQIQ46hPrVWkjoYahCjSShEYCD6HpfqKMJsyVu6I0EhISCgpRg1zOcyDo7h9tBAyRbh3C8Ztp\n+jkmtNLgjSmxtD04SJL3j6KcPD6CRXvC/T4c7/3BIlqrQSOBrIBWEzn9FBGOWhel4Yp5Y7A5PczI\nGl5l+WKjtXwrfxwNnTamh6B7XkYCl88dg8PtYXqIqf+CZXx6Aj//xhSq2ixcNGv4pQm8duFYKtos\nTAwx7eZA8s35YylvM/fUpR5IslPjuGp+NhaHO6QxdUZuGgkxUcTrtIxLix9w/QSDT2ZSLFfPH0un\nzRmSjbw+fywJMVoSdFGsmCrK6fbG6JQ4HrtyFnuq9NyyePxQq9NDRDhqICKMb6iMSo5lVHJsyPKT\nQsiLHSr5uWnkh3F5PZykxutYkNOP2o8DSEp8NAtyRoTt+Hn9eADQaCRmZacMoDaCSCAnPZ4cQnvw\n0mg0XDE3e4A1Oj1ZPjWT5RH2MBM5c3uBQCAQCAQ+9DmjliTp4T6aFUVRfjvA+ggEAkHIRFK2M4Fg\noAg0o7b4+aMAtwO/7ktQkqRcSZKaJUnaLEnS+oFQViAQCASCrxt9zqgVRXmq+7MkSUnAT4DvAu8A\nT/UmdwIbFEW5uV8aRgBX/HUbx5pNLBg/grfuWDzU6kQsHx2o5dHPSojXaXn/7iWMTlHsHoo7AAAg\nAElEQVT3Pu1Ys4ndFe1MzEzkrInqQpKGE7Is89SG49TqrXx7yXjVewaKGwz86K2DyMBfb5jHrOzI\nLuspCD8FtXpufnkvHlnhT9fO5tI54n10bwxHex7wHbUkSWmSJP0OKMDr2BcoivJrRVFagjj+SkmS\ntkqSdE9/FR0qnE4nRY1GnB6ZPZXqSzd+nfjbF+VYHG5aTQ6e21SmWn5HWRttZie7K/TYXZ4waBgZ\nFDea2Felp9lo54MDdarlX9hSQYvJTpvJzvOby8OgoWC48cc1xzA73NhcHp5af3yo1YlYhqs9D/SO\n+s/A1cCLwGxFUdSkamkEpgAO4GNJkjYpilJwwrHvBO4EyMkZvHJhatHpdCTEaDHb3YyIjx5qdSKa\nM/PSqO2woZHg4lnqEyrkZiTQUdNJdmocMVGn7z7H8enxpCXo0FuczB6rfja8YkoGXx5rBRRWTFVX\nDjQUTpdY6dPlOvzxjZmj2FulRwGWTho+CaMGm+FqzwOFZ/0cr6N9EHhA+ip5goR3M1mvAX2Koji6\nZJEk6TNgFt5ZeXf7i3gfAMjPz4/ovKH77lvJ1jI9Z08anmFNg8Ufrp7DTYvGkxoXTXYI8bsrpmaS\nn5tGfLQWKcyJOoaSpNhonr5uLka7m8wQwvquXjiOM/K8oWHj0oZvWKNg4LhtaR7LJmZgc7mYM07Y\nqb4YjvY80DvqkKc1kiQlKYpi6vrnUuCvoR5rqNHpdJwnUu4Fxcx+xu8mxkRMaH9YidVFEasL/VqF\ngxacyuTRSUOtwrBgONrzcK4vni1J0n5JknYA9Yqi7A7juQQCgUAgOC0J9I7ahDcc68R1SKVLTqco\nSq/yiqKsBlYPhJICgUAgEHxd6XNGrShKkqIoyV1/JwFZwO+BJuDZwVAwWGo7rHT2UbrxUE0HHWb/\n7Xa7nec2llLV7r8soEdW0FucyL2UoWwyWFlV0KBe6RDpSxeXR0Zv6b0f2s0OjtR19tpe32GjtKn3\n8oivbS/nrV2VwSs7gAT6HdRS3W7BZHf12l7easbq9F+61On0cKC6A5vT/+70qnYjz20sxW63h6Rb\np9VJfac1JFmA+k4r+l7GuyA8KIp3fPZWrtbWNWY8Hv9jxmx3U9lHacVtx1r4++eh7+guazZRq7eE\nLN9hcQZddtXm9GDs495qNtppMfZ+bwSy531htVr5zcdHKG3u3c71hcHm5FBNR0iy4K2o2JddCYWg\nXpJJkpQK/BT4NvAWcIaiKO0Dqkk/+ORwPW/triEmSsvvvjmLcSNO3sj08MeFbCppJikmmjfvWER6\nYsxJ7Qt+/wVWl8yzm8ooeuQ8YmNP3uDzwYE66jpsTB6VyGVzxpzU1maycsHTW3G4PLywuZxPf3x2\neC6yi06ri9d2VDFhZAJXzjs5VtIjK7yzt5Y2k4N541J9SuHVd9j4zit7sDrdXDpnDPefUubyUE0H\nP/3vIdyywveW5fGdpSeXkrz+n9vZXekd/OuLWnj19kVhuMLe+ehgPTV6KxMzE7li7pjAAn3w1m5v\nbd7EmCieuHY2GYkn/+bPbjrGjrJ2RibF8Jfr5qE7ZRf67f/ZR0WrmZy0eJ9SeJ0mO+c+uRVZgX9u\nraDo0YtV6VbdbuGhjwtxumVuPSuXi1UWUFlf1MS/t1cSrdXw2BUzyRvGefSHE+uKmihpNDEmNZbr\nz/CNZLnl5d00GrzFe1669YyT2qxON7/832H0FifnTsvkruUnl079z45KHvqkGIC399Sy7d5zVen2\n3r5ant10HK0Ev796NssmqYsW2Ha8jb1VekbER3PT4vFE91GByy0r/Ht7JS6PzGVzxvjUMthV3s5z\nnx9HAn598TTmnBL5EMieB2LO777ALcOrO2sofngl8fHBy5ttTm54cRcGm4ulkzL407VzVZ271eTg\n3X21uD0Kl83NGrAaFn3OqCVJypAk6Y/AAcANzFcU5cFIctIARxtNKArYXR4qWnyfSI82efe0mRwu\nyvw8sdpc3qdEjwIV7Sc/5cmyQkOn9//qOmw+skcaTDi6Yn7rOn3bBxpn1xOtP10cbg9tJkdXu+9s\n7GiToWeGWNzgO2s+UNOJyyOjKAqH/My6ixtMPZ/9tYeb+q7+9Xdtailt9l6L2eGmVu/bl2Vd46jV\n5KDDz5N9rd56kk4nUthkoHtSZXMGNwM5kePNJhwuGUWBEj+/UyCKG40oCjjdMsf93A+C8NB9TzYa\n7LhPmXnanB6aumaQVW2+47fV5OhZCTvWbPJpX91Vnxyg2aR+leZAdQeKouCWFQ5Wq793u++5DqsL\ni8P/KlM3bo+M0+0dv/7uj+JGIx7Zq0tJo+/4DmTPA+E+oeuLm9XZippOGwabdzZ8rFn9uVtMdpxu\nGVlRaBhAfxBoM1k1cAPwGmAFbpck6WfdfwZMi37yrYVjyc1IYOH4ESzxk9HqjmV5ZKXEsXRSBovy\nfGMMz8wdgVaCsamxzDgly5NGI7Fy2kjGpMb6jVldOXUUs7NTSIqN5pbF4Y8HT4qN6lWXeF0USydl\nMCY1lrMn+7avmDKSM/PSyUqN446z83zar1uYzYwxyeSkxXPnsgk+7b+/ahYS3kHz+NWzBuJyVHHu\ntEzvtU/pf2Wb6/PHkpMez5KJ6cwd67tT/YYzchg7Io6LZo32Wxnt/84Yx6jkWL61cJxP27LJoxiT\nHINWgiV56kNAlk3KYEHOCCZkJHDNwrGq5a+ZP5aJIxOYNy6VcyafvhneIo3lU7x2YvmUkT41n+N0\nWq6an82o5Fhu9mMnxqcncP70THLS4rnhTN/2v98wj5goCQ1wo5/2QNy+LI/c9ASmjk7m5kXqyzcu\nnZRBdmoci/LSSI3vu4JdTLSWaaOTyM2IZ36Ob56Ay+ZkMWVUEtOzkrlopu/u60D2PBBTRnorz6XG\nRZGfp05+RlYK507LJCsljtuX5qo+9+TMJKZ2Xfu8cQOXMVBSlN7f90mS9Bu8m8f8oSiK8thAKJGf\nn6/s27dvIA512pOfn4/oq8CIfgqe/Px82s5/dKjVOIlQC2iEI6lJty5iTAWH6KfgkSRpv6Io+YG+\nF+gd9cuKotT2coLLQtJMIBAIBAJB0ARa+t4gSVLuqf8pSdJtRNiub4FAIBAITkcCOeqfAeslSZrc\n/R+SJN3X9f/Lw6mYQCAQCASCwHHUq4G7gTWSJM2SJOkZ4HLgHEVR1Jf96YOSRiMHajp6jUHsC5dH\nZn+1nuN+dksCrD3SwPzH1nHTv3b5bTfYXOyuaKe5j7i+vthXpeeV7ZV9xgVGCluPt/L6zioMvcQo\nLv7DRmY/spbiRt84QkVRKKjr5Eidgb72NkQKB2o6/O4qBW9M6oLH1nH137aFdOzyVjOvbK/0u0MX\n4HBtB69sr+xXLLQgspAVhT2V+p4d/wPNxc9sZsoDq3llW+RVRLM63WG9djX8b28N0x9aw2XPfem3\nvb/2vK7Dyu6K9oC723ujuMHIwRB9WW8ETCGqKMom4DZgMzABOFdRlNCjwf3gcMusLWxiS2kr+6rU\nlx7bWd7Ol8fa+Kyg0e+W+B++dZAOq5vt5e28stX3JlhV0MiO8nb+t7/OJ6wiEHqzk6c3HGNtYRPP\nbors8nLlrWb+/kUZqwoa+Yef8oiXPLOFJqMDk8PDN/+206e9sN7IppIWNpY0U9yLA4wULA43W0pb\nWVvYRFWbb5KH7762D73VzYE6A7//tFD18Z9Yc5S1hU08seaoT5vZ7ubJ9d4x8Zf1x0LSXxB5GO1u\ntpe18eHBeswhGvHe+Ofm45Q0WXB6FB79zHdMDTXri5p7rj1UBzZQ/PL9I9hcMoUNJp5ZV+LT3h97\nbnN6+PBAPTvK21lf3BRY4BTKW82sK2pic2krB/qRNOVU1KQQjQHOA1okb2mjPqtnqeHE/KQajfqq\nSZoTKi1p/FRdkiQJumaAp4ZNeGW+kg2lapN0gnwkowEkJBQUv/0QpQnUj/TZHqkEuhZ/fRH4mCf/\nfVKb5sTPw6efBH0jnfD3QP+qpybUiTS67xeJk++doUDiq1CkSLPnJ/si1eK9Eqh61qCUY9FFabh8\nbhZ2l8yMLPW+f/GENJJio0iOi2Z0im/M6yvfyedn7xUwb2wKt5zlGz982dwxlDaZyEmLR6uyd9MS\ndfzqomkUNRi5MMIrsuSNTOSeCyZT2Wbh0tm+mb0++fE5rHjicwx2N+t+stSnfeaYZDSShEYD00YP\nyDNa2EiIieL86aOI02nJSffNTPTunYu5840DTMlM5NeXzFB9/AcumcHWsjaWTPCNk47XRXHfJdM4\nVGPg/On9j/kWRAbJsdEsnzqS0cmxJAxwlbfblk1kVUETxY1GHrtC/XgMNxfOHE1xo5GslFji+1H1\nbSB4/qb5/OJ/BUwbncQPz5/q094fex6n03LtwnE0GGxMD8HG5WUkcNmcLBzu0HxZb/QZRz1YiDjq\n4BExisEh+il4RBx134g4anWIfgqegYqjFggEgkGnL4cbqhMXCIYrkf1iRCAQCASCrznCUQsEAoFA\nEMEMi6Vvs8PN2sImtBq4aGYWcTrtSe2vbK/kz+tKiYvWsurHSxidcnJpsVq9lS+PtzImJY4VU0f6\n7ARcV9jEqiONLBw/glvPylWt36/+d5ijjSa+fdZ4rvVTpGEgsTk9/GdXNXPHpviUhwuExWJh9u82\nIyuwOHcE73z/LHXyXb+DJMFFs0YP+aaScPKbTwr56GA949MT+PiHy1TLP/TREQ7XGrh2YTbf9rOB\nsS+aDFaueX4nNpeHRy+fyeWnlDMVDA1Ot8ybu6vJTo1jxVT1mwRnPrwWi9NDZpKOPQ9cEAYNe8dg\nc7G+qAldlIYLZ44mNlobWChEFAU+OdyA3enhGzNHBSzicSpPrCnhxS8riNZqWHvPUnLT1W3K6q89\n/8fmMo42mrgufyzL/BQ3GgqGxYy6sN5Ard5KVZuVo02+8bsvbC7H7vLQYXXyxFrfWOZdFe20GB0c\nqu2kzeyb6OP9A3U0G+2sPtKouuB3caOB7WVttFscvLGzRpVsKJgcbtpMjv/P3nmHt1Wdf/x7JFmy\n5L234yR29nScBYRMVhgNe7ZAB/woULpLG1qglFFKy2pLgTLL3pBByCIh09lxPOMZL9myZGtv3fP7\nQ7bjRLLleyXZV875PE8eZI7ee47OPfese973i+9OdvG2vevdsn75xf1N/H38KtqNaO624pTOOmgg\nkbHC50faYHV6UKU24kCjlpdtW48N26s10FkceP+g31D5Q/LCtjp0mRww2914Ybu4ffPPJSwONzRG\nB4426/slKYdLo8YCi9Mrh6sx8bMNBSdaDWjtsaGhy4JaAfKNfHC4PajXmNGmt+F4q4G3/Vt7m+Ch\ngN3N4fefVvC2D6Y/b+mxYmdNFzqNdnxyuI133uEiIgbq3CQlZBICuUyCnESlT/qs3AQQQiCVEFwx\nM8snvSDVK3uWpIpCgjLKJ31KptcLLT9FhRg5v5lmfqISyTHeGeP07PB7s/X5W45LieFte+P805KJ\n8dH8Z9S5SUpESQmipAQ5ifzE3CON/GTv71PJpZic4SuDORRpMXKkx3ndBCdn8m8TF03PgFTi9QGd\nX8BfJpMRHvqevZRYOeKi+e0mjU8//byOhmt9XrIS0t4+NCvR14U1lERJJVBESSAhBHlJvv11IArT\nvTuiBMA1c/nvJgXTn6fFyJEerwAwMv35cIkY9yy7yzsbHWzLprRBi4y4aBSkxfpNNzvciJZJBg1u\n0aa3IiM2GjIBgQdsTg/aeqwozAj/jS0pKcH23fsQp5AJcuY/1qjBgWY97lo6SVD+ge6DWAiFi8i+\nui5My05Egsp3cheIYNtEW7cVWosDs/OSBNnzQYzuWUMx1KnvcLtnfbt7H5RRUkFBcjR6C94rbcZP\nLshHTAz/iXaw2JweSCSAQhbeZ7ekpAR79peC4+DzmnK4bC5vR26SCtNyhGk6B9OfO90cdGYHsvws\nCkPNmHPPCjQwLJwwtEB4bIAABcGsEJVy6YgM0n3ER/MfOPqYMz4dc8YLD8Ih9gE6lCwuFP5+Ktg2\nkZOsQk7y2N61iETignj20hNj8PNLpoawNPwQOmgKIdjJwMUzfAMy8SGY/ty76xD+QZoPEbH1zWAw\nGAzGuQobqBkMBoPBEDERM1C/t78Rnxw6JdjeYHXB6eanpBKJ1HUZ8PyWGsH2eqsTaj8KZGORv35d\ngZ3VnaNdDMYYwWaz4W+bqtDWLez5sTrdOKXzVXobi7D+nB8R8Y76+pf24OApPQBgc4UGr9w+n5f9\n/gYd9tXrkKCMwq2L8sN+mGK0aOu24aK/7wYF8J/vGlD12GW87Bu7zHh4XQWcbg4/vmA8VolcZCQY\nZj68CSaHBy/tbMIz187EdfPzR7tIjGESjgNjoWD2X76F00Px7x0NaOQZ5tTqdONXHx1Ht8WJFVPS\ncffSiWEq5ejD+nP+RMSKulJt6v986BR//9/WHu8M12BzwWQfXS3VcHKkWdsv/2Z38Z9tnuw0w+Hi\nQClQ3j62/aTNDk//508Ot45iSRhjBafH+/RReHe2+NBlcvT7Zp/sNAX4dmTD+nP+RMRAvXb1ZBB4\nC/vMdbN42y+emILsxGjMG5eE1FhFyMsnFq6ck4dEpQwEwLx8/m4NSyalYlZuAgpSY3Dt3NzABhHM\nqqneE91SArz2/dmjXBrGWGBKZiwIgPQ4BQrT+Pnej0uJwYop6chJVOLG+eGNbjjasP6cPxHjR83w\nwiTkhgerp+ETaX7UIw2TueQHq6fhM1w/6ohYUTMYDAaDca7CBmoGg8FgMERMWAdqQsizhJBdhJDn\nw5kPg8FgMBhjlbAN1ISQYgCxlNIlAOSEkCHP4C96YitmPbIJjRpfP0JKKcpa9ShvM0DIO3W7y4OD\nTd1o6bbyth0Oh0/14K29TdCa7WG5/kBae6yY+sev8eAnxwTZN2ktONTU3R+z+2xqOkw42twDDxf6\nswsGqxPv7GvC/npdyK99NpQCHx5sxjflHWG5frfFiQON3dCZHX7TOwx2HGjs5q3e08fKZ77F3D9v\nRk2nnreth6M42twz5k8PjzR6qxMzH96EG1/eI8heY/K2CYNVWJsIBrvdjd99chyPflU+Ivld+PR2\nFD+2Gc1a/n2uy8Ph8Kke1GlGp/2+V9qMn75zGCf9KDWOFuFcUS8CsKX381YAiwf74slOEzqMDhjt\nHqx+8Tuf9LJWA7ZVabClshM1AjqfrVWd2F2rxWdH2mAU2HEORrfZiX9srsHGE2o8uyX8koQ9Vhds\nLg4fHOIvwdZjceKLY23YVavFTj8ymc06KzaeUGNHTRcONHaHorhn8M9v67CuTI3nt9WiRReeSVMf\nOosDnx1pw+t7GrG7lr8kaCC+ONqGPXXeNnU2TjeHT4+0Yk+dFhtPqHlf+8aX96Bea0WP1YWr/7mP\nt/2Bxm7sqOnChjI1msNcz+cSLT02mBwelDbq8daeel62HEfx6WFvm/nq+MjLJ/728xPYeEKNTw63\n4u+bhQdEGg51GjOau23otrj89ueB2N+gw3cnu7DuuBrtIxx8qV5jxl83VWFXbRfufe/oiOY9FOEc\nqBMB9E1JDL1/90MIuYsQcogQcshlGdrncKBIFAF/xag+G0IgwHoY1yd9+Yif/rrwl0b8fw4VZ8j7\nhfl0xMB2IpOEPrP+e+6nns6sR/4VKSXBlTfc95EhjNNtZuRvysBnL0o6cvkLyWngszsa7VeMj0w4\nI5MZAMT3fo4HcMYeHqX0FQCvAF73LGViNMwOD7554HyfC83MSYCkV29aiL7vyqnpyEyIRka8Iij1\nG38kx8rxm0smo6LdhEunhz+SV3KMHDFyKdbM8dXdDkRSjBzXFOegy+zA9Ox4n/S8ZBWunJ0Fq9OD\n6dn8/ECHw30rirC+TI2JaTHISwqvMlRyjBw3lOQiUSXHookpIb/+1XNzUN9lxvhUX1nVKKkE18/L\nRUuPFZMzfes5EO/dtRgX/30HdFYnPr/nAt728wuSoZJLoZLLkMcUuELGuGQVVEoZZuYk4Pbz+UUO\nk0gIrpuXi1M6CwrTR17n+Kk1M/EXhQyxChl+tlKYxO1wKUyPRUKqCia7BxvvP4+3/aIJyYiNliE+\nWoashJFVsZqYHou1l0/Fnjod7l9RNKJ5D0XY/Kh731HfTSm9mxDybwBvUkoP+PtuamoqLSgoCEs5\nRhtKgW6rEx6OIj46CtFR/FZLtRpTf5Sx+GgZqKkLY7WuLA43zA43FDIpEnlqQDvdHtR0mvv/jnP1\niLaeOErR1mODy0ORHCPn/VvdHEVPbxSrpBg5ZJIz1wBaswMaowOEAAUpMT7yhrUac/8ZhaL0WHS0\ntYi2rkaTTqMdGpP3DIKUEKic3ayehkFTU9OYradQ9+fapmpKKQ14kbCtqCmlRwghdkLILgDHBhuk\nAaCgoGDMOsi3dFv7Q1QWZcTiiln8dFYnPLgBfcFA5VIg/puHx2xdvbGnEfregzb3LJvIS/v60S9O\n4I39zf1/p24Vbz2Vtxnw2PpKAMDEtBg8cQ2/6EyHmrqxq1YLADi/MBULxiefkX7jy3tR2RsC9taF\n4/Dg6jM1kIvWboSrN9zl6uIcbH/6x6Ktq9Fk1sObIB0QalbMbUpMjOWAJ6Huz7VPXHFkOHZhfVNI\nKX2AUrqEUnp/OPMRM5kJ0ShIVSEuWobZufzDeq6YnNr/+c7zxoWyaKKjZFwyYhRSzM5L4DVIA8Av\nVpyuG5Vc3OEBJmXEYUpWPOKiZbhEwOuSoow4pMYpkBqnwOQM323U2xaNg1IuQ0qsAjct8A1HuWh8\nMggAuZTglxdPEfITzgkevvL0BGdiKnuFwBi9/pyFEI0wxvJsNZSweho+rK6GRzjraShFsCaeSlyj\nDWtPw4eFEGUwGAwGYwzABmoGg8FgMEQMG6gZDAaDwRAx4fSj5kWb3ga7y4OJab5+qcHi9nCo77Ig\nNVaOFD/6pQarE3sbdJiVm4CcxJE/NHLXWwehNTnw2X38fWZDTbveBpvLgwmpMaMSmGEoXt5Ri5e/\na8D9Kwpx5wX8/FjPxsNR1HeZkaSSIy2Ov6at1enGKZ0V+ckqxCh8HyODzQW1wYbxqTFQyPgdjAOA\n4y090FlcWDYpFRKeAVvsdjtuf/MIxiWr8PQNc3jnHWoausxQREmRk+jrE8txFHVdZiSqopAeFz3i\nZfv1h0ewp6Ebr90xD9OyksKa11DvoSOFQL8h0t6nh4NLn90JvdWJ/WsvCtk1RbGidno4fHyoBV8d\na8fR5p6QX397tQYbT6jxwcEWWBxun/Qnvq7Gm3ua8KcvKuB0c36uED6+/9/92FylwZFWAxY/uXVE\n8z4btcGGj3rvw5Fm/jGmw82Tm06i2+rGo+urg77WrlpviM0PDjQLir386ZE2bCrv6HfVGIjbw+GD\nA834+kSHoBCi5W0GPPl1NV7eWY/3SpsDG5zFymf3oLSpBx8dacNvPxIWEz5UHG/R48tj7fjoYIvf\nWPu767S996Gl3zd8pHhjdz0+OaqG2uDAFS/sHdG8GWOTFX/bjupOMzpMTkx5aGPIriuKgZpS7z8A\nsDn9i0UEg603uIPLw8Hl8R2I+wZvu8sDNzeyA3XXAFEHf5OIkcTq9IT1PoiJvt/n5igcHv6/1eb0\n3iurn3ryUApH74TPX3og9FZn/30w2Pm3CcuAPNtGOFby2Qz8/f6EYPrSPRyF08+zGU4GxkEPgwYN\n4xxEP2DS3xerIBSIYutbIZPgwklpsLs8KClIDmzAk+VT0pGg7EFWghKJKrlP+n3LC7GpogMLCpKh\nko9slXx+9wIseWY3nB4PPvrJghHN+2wmpsVi6eQ0WB0ezB8f3m1AIczKiUd5uxHFefz9F8/mwklp\nUClkSI2VC9pyvXJ2NqrVJkzyE9JWIZPiytnZaNJZMCuHfyjWC4rS0Ka3ocfiws1+/KAD8eYd83Hn\nmwcRGy3Du3cNqoUzIswblwRKKRRREhSm+77WunBSKpRyKVJi5MiIH9mt74e/NxObKjuhNTlw79IJ\nI5o3Y2yy85fnYd5Tu+DhKN69szhk1xXFQA14H+hwER8dhWWT0wdNn5IVjylZ/GMyhwKlUolDfwzd\nu4xgKc4X3wDdx1f3LwnZtWIUMiydlCbYPitBOWQc4vGpMRifGiP4+jfOzxdsO2dcEo4+fLFg+1Ai\nl0lwXmHqoOkqeXD3IVj2/X7VqOXNGHvExcXh5OOrQ35dUWx9MxgMBoPB8A8bqBkMBoPBEDFsoGYw\nGAwGQ8SwgXoYvL23ET94vRSfHG4RZH/xP3Zg3mNb8NXRNt62dpcHmys6sL26E+4RPhXLl/I2Pa58\ncRd+8Fop7AJOK//72zqc9+Q23P/+YUH5n2g1YN3xdnQY7ILsR5K39zXhz+sqUN9lDvjds6ls02P6\nw19j+p++RmWb+NzoxMSKZ75F4e834EdvDCreNyiUUuyu1eLrE2qY7Pxd+BjipLbThK+Ot6NJaxFk\nP+uRTSj6w0b8a3ttiEs2OKI5TCZWPB4PXt3VCI5S/GdHPa6bx+8U7lMbq1DX5W0Qf95Qiavm5vCy\nP9aiR0WvZGFa7MgHhODDXzZUoUlrQRMseGVPA2+B+pd21sPh8mBzhQZ1GiMK04d/wM/icGNbdSco\nBUwCJgkjSbXaiA1lXv/qN/c04bE1M3jZ3/3OEVgc3knbT94+jD2/XxnyMo4Fjjd3o0HrdcHaXtPF\n275JZ8XBpm4A3kNx5wpjITDLYFBK8XV5BzwcRYfBhrsu5Bc46a63DsJo97oUPretFveuKApHMX04\nd1qfQKRSKZJ6XbpS/UQ1C8Tc/ARIeiN8pQuIgJUa681bQgiSYqJ4248k41O8Ud0kEoLpAk7RJyq9\nvy9KSpAWO/iJan/IZRLE9kYIS4n1dcETE6lxcijl3mhl/qJ1BWLSADenCWnCT5aPdfISleiLrScV\nEGQvQRmFqF5DfxENGZEHIQTJMd7+ISWG/z1dPOG0+3Csgn/EQaGwFfUweOPO+VVNuVAAACAASURB\nVNjXoMWSIv5uJJfMyMa/bgHKWgz4zWVTAxucRWF6HG5bJIdUcrqBiZUnr52NhRNSkBWvxMKJKbzt\n19+/BG/va8TF0zKQoOI3KYmSSnDrwnHQWRzITlBiLe/cR47U2Gj89dpZaO2xYW4efz/r1+5cgGe/\nqYKTA34noE2dKyTHK/G/H87Hq7sb8MSa2fztY+T4/uIC2JweZCaIezeLMXyuL8mFxugQdE/vXOJd\ngR9o7MFLPwioThky2EA9DFJiFbhiFr8t64FcMiMbl8zIFmwvJBb1aLFmbq5g2wRVFO7nuV0+EKVc\nilz5yMdqF0JGfHRQAT5+cQkboIfDBZPSccGkwWMoBCJBGYUEpbh3shj8UMikyEsW3k/cuWQi7gxd\nSIdhwQZqBoPB4MFQ73CZKAUjHLB31AwGg8FgiBjRDNQcx8E9hHIVpRSUDh7knAsQVT9QerBYBSgw\nCSVYwQxnEPYcx4ELQrgk2PvgGUH1hEB5BUoP5re63W5BLm59OJ0eeHiIjZiDyItSGtRvDaY9Ahhx\nxTtGYIJtE8ESbN56k7hcPEWx9e3ycLj7f4dhd3N4YGWRjzCHxmjHp0faICHA9SV5PoeqGrUWrD/e\njrhoGW6Yn+cjrFHeZsC2Kg0y4hW4bl4uZNLQzU+sVhcu/McOmOxuLJqQgrd+GF5hjeZuK1b9YweK\n85Pw4i38gr73mJ24480D0Fmc+MGicbhrKT/XhGq1EU9tqgYBsHb1VBRm+ApSDEVFuwFbKzVI770P\nUTzvw+aKDlS0GzEnLxHLpwh/7zgcDjV1Y3edFvnJKqyZkwOJ5Mxjw99Wa3CsRY8ZOQm4aFrGGWmU\nUnx1vB0NXRacNzEFCyfwO1hX2W7AHW8chNPtwf0rivCjJfwEI9Yda8MzW04iWibBS7fNw4QAGu81\nHSac99Q2XD4zE09ey+/QVY/FiY8Pt8DNUVxbnMv7vfvbexvx6q5GJCij8PodJUiP53cK/oVttdhT\np8WcvET8fjV7by8GPJTitd2NcLg5fG9ONnKTRvbcyN56LUobulGYHosrZ/M7G6Q32VHy5Da4OSAv\nSYldv1sRplLyQxQraqvTA6PdDaebw956nU96fZcFdpcHVqcHTTpfJ/WTnSa4OYoeqwtqP8EuqtRG\ncJRCbbCjJ8Qr331N3TDaXKCU4nhL+INP9K2my1r553XoVDe0Zgcopdh5kr9faWljN2xO730o7fUv\n5UO12gSOUnQY7OgWoD1cpTYBACrVRt62/PMyglLglM4Ki9N3tdlXhio/ZbG7ODT0+s77Sw/E+rJ2\n2JxueDivzydftlR5g+OYHW7sGIb/sJvz7lbta+B/T091W2FxeOBwcYKCt2yr7gJHKXqsTpQKyP/w\nKa9+/fFWfVA7PYzQ4XJzMPX253Ua/m0iWPr6iTqNGQ43v92az461o2+Dpn2UJWIHIoqBOkYhQ3ai\nEkmqKKya5rtSmpIZh+QYOVLjFH6l8mbmJCAuWoacJCVyk3xn5HPzExGjkKIwPRYpIXZxurAoGVmJ\n0ZBJJVg+OfwqQLHRMkRHSXGhAMWhxROSMT41FsooGdbwDLwCAMsmp3llIeMVgvKfk5+IWIUME9Ji\nBPmklxQkQSWXoiSMSmt9zM335jUtO77fP3sg88YNXhalXIqZOQlQyaUoFlDWmxfkISVWgegoKW4R\nIHN5bXEu4hRRyIiPxuqZmQG/L5dJIJdJccWsLN55TUyLQVqcAskxckzJ5O87f83cHKjkMuQnq3Ch\ngOdnxZR0qORSLJuUDolEFN3ZOY9cJkVmQjQSVVGYlj3yqoTF+YlQyaWYk5cIhYyfr/Mt87OhjJKA\nAJjqR8J2tCBDvfcdKUpKSuihQ4dGuxgRQUlJCVhdBYbV0/BhdTU8+upJ6KlvoRG/RvokeTCRyZqe\nupy1Jx4QQg5TSgM6ZLMpKIPBYDAYIoYN1AwGg8FgiBhRnPpmMBiMsUA4BC1GequdIT7CtqImhBQQ\nQjoJITsIIZvDlc9IsKm8Hbe8sh97a/mflAaASrUB26o6h/QTHws4nU784sOjeG5LjSB7ndmB13c3\noqYj/Ke6R5u6ThO2VnYI9gH+5YdH8fMPjoa4VOKjtduMu98+hM8FSszWdBjx+u5GaIziOcHLGF0+\nONCEi5/diU0n2ke7KMMm3CvqLZTS28KcR9i5992j8FCve9PJx1fzsm3sMuMv66vg4ShqO834v2X8\nfJcjiav/sx9VahMIIVBESXDPMn4ScPe/fxSndBa8V3oKX/z0PMQqxS1CIhS13oZH1lXA5aE40WbA\nLy6azMv+9tdLsfOkFgCgNTvwzo8XhaOYouB7/9qHHqsT26o1mJGTiCIeJ3FtTg/uffcobC43Nld0\n4IO7F4expIxI4cHPKgAA97x7FI1PCddgGEnC/Y56OSFkFyHkF2cnEELuIoQcIoQc6uoStlIdCRwO\nB/rOxQuJimVyuPvtDLaxLT7fpwNNKcUpnZW3fV90LIebg8Mz+t4I4cLicMPl6WsT/COCaUyO/s9d\nAz6PRewurx8sBdDJM1qU0+OBszc6m9khbo1yxshgs53eWYmkHibgipoQIgWQRCnV9v4tB3AHgF9Q\nSocKBaQGMAmAA8CXhJBtlNKyvkRK6SsAXgG87lmCf0GYUSgUuKY4G9uru3DNHP6+x7NyE3HT/Hy0\n9Fhxy0L+PrGRxH9uK8Y97xxFcowcT/GMcAUAa6+Yinf3n8KSorQxrf9bmBGH7y8ah3qtGTfM498m\n3r5zIa7+924AwDs/GruraQD405XT8Py2WhTnJ+ECnjKzCUo5frayCN+d7MLN8/PDVMLRhb2H5odS\nqcTSSSkobejBJWdFFBQzQw7UhJCbALwMwEIIqQXwOIDXARwEcOtQtpRSB7yDNAgh6wHMAFA2lI1Y\neeb6uUHZX10sXCIzkpiWnYidv10u2H7h+BQsHM9fxzoSuYJnaMOBpMUrsPvBlSEsjXi5cX4+bgxi\nkL1uXh6uEzAZYoxd3vph5E1uA62oHwIwj1JaRwgpBrAPwHWU0nWBLkwIiaOUmnr/PB/Ai8EVlcFg\nMBiMc49A76idlNI6AKCUHgFQO5xBupclhJDDhJC9ANoopaXBFJTBYDAYjHORQCvqdELILwf8nTjw\nb0rpPwYzpJRuBLAxyPIxGAwGg3FOE2hF/SqAuAH/Bv49tHbeCGKyu7CpXI29ddohNasH4/H1FZj7\n5834yVsHBeX/6eEW/HldBSrbDbxtPZxXyWpzRUf/CdehcLg5rDvejgYBSkUA8Pa+Jjy2vhKNAuxr\nO4yY++dvUPzYZjR1jW1f57JWPf68rgJfHG3zm96otWDd8fZBFaPueL0Uc/+8GX/7uop33pRS7K7V\nYlN5Byxj/LTyv7bXougPGzHn0W8E2Z/See9DncYU+MuMc4IfvXEAhb/fgIv+sUOQfVmrHuvL2qEx\nikeTesiBmlL66GD/AIimpy5t6EaV2oTSxm5BbkFv72+GwebC9pouNPEcwNR6Gz461IqKdiNe293I\nO++TnSYcOdWDinZjv2TfUBhsLtRpzNhUwV/+sLzNgA1lapS3GfDmvlO87f/vnSPosbrRbXHh7nfG\ndrCN13c3oaLdiA8ONkNr9n1gN5V3eO+DHxnKynY9dtXpYLC58NqeJt55N2gtONjUjSq1EQca+Us/\nRhLPba2Fi6PQ29y4S8BE+ZsK7334+kSHoEk6Y+yxvaYLbgrUaiw43szv+THZXdhWpUFtpxnf1mjC\nVEL+BONH/cvAXxkZkmO9gTGipATxyije9qoorxSaTEKQquIXZCMuOqpfBjEzgZ/oPQAkqeSQEAIA\nSB6GBKdM4v2uELnOtDgFFFHeW56dEM3bfmJaDAgBCAEmZ4hHAi4cZMR73cPiFDLEyn3fEPXVv797\nlhmvgtR7mxDjRyIzEAnKqP77PJw2EcmoFKdlCBdPSOZtnxzjvU9JMXKQ3ueIcW7T9+wRAHmJ/Ppk\nhUza35/3tS0xIFjmkhDSQikNid9DKGQu1QYbVFEyJKj4D9QdBjNe2tGIa4tzMCuPf2ehNdvR0GVB\ncV4SZDL+c59uixNuD4f0+MCD57x5Jfhiy3fIiI+GXEBear0N7QY75uYlCNLvfW5zDWQyCe5bwS/q\n2EgTrNSe283hSEsPCtPi+ieCA3G6OXQa7UiPV/jVvC1r6cbnx9pw//LJfu0Dobc6YXdxyBQwoeLL\naMsS3vXWQSyekIw7l/CP2ufycOgwDH4fQslwZC7PdcQgc1nXZcCjX1bhzvPHYcVU/hrrVqcbOrMT\nOYlKSCThnfwNV+YymBCiotpnyhKwmu0jMyEWj35vpmD71NhopMYK71D5rJoIAfKSVYLzykpUIovn\nLHMgP7+YX7jLSEUmk2DBED7dcplkyPswKy9Z0KSvj0SeOzuRzCu3zxdsGyUd+j4wzj0K0xLwvyDC\n6qrkMqiSxaVXFSjgiQn+B2QCQHhvz2AwGAwGY1gMOVBTSsf2i0gGg8FgMEROuEU5QgaldMhTnYHe\ntWv0loDXDwaOixwJy0BlNZkGd3UJdB8iCbNZmItbH4HqMZLaRCCC+S2B6nks1RPjNEP1ExzHBXXf\nw92fi62PE9dG/CBoTHZ8dqQNEgJcPy8PSWe9023SWrC+rB1x0VG4oSQPSvmZh0rmPbYZOotXuWrj\nA+dhWlbSGen76nUobdShMD0WV8ziF4PZ7ebwxy/L0aiz4Oq5OUHFJQ43ZrsbD31RDo3Jju8vHofL\nZpx50OLv31TixW+9LmYTU5XY9usVZ6R3mRz49EgrCIDr5uVGtHBGyV82Q2v2ton/3TkPSyZn8rJ/\nfttJ7KvXoWRcMn59yZnv7TmOw6Prq1DTYcRlM7Jw+3kFoSr2iNNtduKPX56AwebC3UsnYglPYYyr\n/7kbR1u98QXuWVKA310+/Yz0rZUdeGNPE1JiFXj86hmIi+Z/GJQhLjhK8druRthdHqyZm4Ocs87E\nVKoNeHpTDSQE+OPl0zA+jV9IjnD25xxH8fnRNrT0WLF0Uhrm5icFNhoBImJFXa+xwOb0wOLwoFHn\nO5Oq6TTB5aHotjjRbvAViO+7qQDwz231PumVaiMoBWo7zXC4AwcdGYjaYEeD1gJKgX314vZ5rdWY\noDbY4OEo9tRqfdLf3t/S/7lB61uPjVrvfbA6PWjycx8iib5BGgD+trmWt/2hph5QChxp9vV911vd\nqO5tU/sbdEGVc7Q50aaH1uyEy+MNwsKXsrbTQYDeO9jqk767Tgc3R9FptKOyXTShGRhB4HRzMNpc\ncLo51Hb67s7tq9P19+f7BcQJCGd/brK70dxtBaVAlVo8QXQiYqCenBmHJFUUUmPlKEz3nX3NyElA\nXLQMOYlK5Cb5nnHLS/SeyCYAHrnCV5mzOD8RSrkUs/MSeLt45CRFY1ZuApRyKVZNTedlO9JMzYxD\nUXosYhRSXORH4u0XA1yu5o1L8EmflBGL5Bg5UmLlKEyL7OML4wa0k8evmT7EN/2zbFIalHIplk7y\nXWEmx8pRUpAMpVyKlVPE3SYCUTwuCfkpKsRFy/y2mUAsKTp9cv6nyyb4pF88LQOxChkmpMZgZq5v\nm2NEHnKZBBnx0YhXRmFaVrxP+rIp6UiOkSMtToELJ6Xyvn44+/N4pQxTMuOglEsxJy+Rd9nChWA/\n6lASCj/qc4XR9lGMFFg9DR9WV8OD+VEHRgx+1JHEcP2oI2JFzWAwGAzGuQobqBkMBoPBEDFsoGYw\nGAwGQ8SIZqBWG2xo0g5+krhZZ0Vrj39lLKfTiV98eBQv7eB/ehcAdGYH3tzTiDo/JxQBwOJw42Sn\naVAZyso2A97c0wiDzSko/5Hk/ncOYvETW9DR49+3tcNgR+MQ96G0QYcDjZF9knk4aM12PL2pCgea\n/P9Wm9ODk50mWJ3+ZSiPnOrG05uqoDEIk8p7cftJ/OrDY3A6w9+mPBxFbacJHk7YeZXrX9qDK174\nTpCt0+nBu/tPofQcaFOM4WGxWLD8b9/iJ28dEGRvsruwuaIDar2v58pwaNFZsbmiY9BnezQQhR+1\ny8Phw4MtoBRYMSUds886bVfdYcTXJ7xygmvm5mB8aswZ6Wte2o/qDhMIIYgiEvx4Kb/g/ve+ewQt\nPVa8W9qMDfddAPlZftgfHWqB3upCVkI0blpwpp+0zuzAve8fhdPtwa5aLV67Q3jc4nDz1w0VWFfu\nlW47/+mdqH/y8jPSOwx2fHCwGZQCSyenofgsH8LNFR39Up53L52IFRF+onkovv/aAbR2W/HBgRZs\neuBCpJ8ljvHZ0VZojA6kxMrxg8UFZ6TpLXb85O3DcLo92FKpwZZfLuWV94vbT+K5rXWglKJWY8ZX\n918Q7M8ZEp3FifVlakzPjsfF0/n5k1/y7E7UdHonfQse34IDay/iZf+nryqwq64LUgnBv24pxsxc\n8Zy0ZYwOJU99B5uLQ6POip++cwj/vi3gWaszeGJDFRq0FsRFy/CfW+fxEkoy2V146Mty2F0eHGjq\nxkOXT+Nb/LAgihU1xwF9h88tDt9ZzMD/5y/dYPf61VFKcWqQVfdQmBxee4fbA5vnzFUzpRRWp/f/\nmf3lbXPB5eHOKIdYOTlAa9vf4snidA95H3SW06u7brMj5OUTE2a79/e7OQrTEG3SX5uwuWh/mxAy\nK2/W2fojI+lHYJemLy+LgLJqB7QDk52/fbfV+/s8HD3jWoxzl75nBwCau/n358beftjm9MDJM/qZ\n1enp97022MTTn4tiRa2IkuCColTYXR7MK/CNBDM7NxF2FwcJIZjqxy/vpVvm4t73jiE1VoHH1vBX\nwfr96qn48EALLpyUhgTlmVHPCCG4anY2TnaaMC3bN+8JabH48QXjcaS5Bz88fzzvvEeS1+5YiJmP\nfAOLw417l/r6tE5IjcGSolRYnR7ML/BVfrp6TjbMdhckhOCqOTkjUeRR45Erp+Hl7xqwcEIKJvrx\n3b98Vjaq1UZM8qPLnZWoxI+XjMfuWi3uPI9/m/jb9bNR22lCt9WJ/9xWLKj8fEhQRmF2XgLm5fNX\n+/r6/vNx4TPfgaMU7/9wHm/7P6yegue21aIgWYXlU/j7aTPGHv+4fhZ+9XEZoqOkWP+zC3nb37ui\nEJtOdGD++GSo/GjJD0VGfDR+eP54VLQbsEZEfRzzo44wmI/i8GD1NHxYXQ0P5kcdGOZHzQ/mR81g\nMBgMxhiADdQMBoPBYIgYNlAzGAwGgyFiImKgPtigw+SHNmLqH79GXZchsMFZ6MwObDyhxlE/Skdj\njcVPbsXE32/AXW8dHO2iiJp/ba9F0dqNKP7zN4Lsm7QWbChTo6ErOE1rsWOz2TDrkU2YtHYj/re3\nMeTXN9hc2FSuxgEBKkqMyGRvbRcK/7ABk9ZuRE2nfrSLExFExEB99zuH4HBT2Fwcbv8v/wFo58ku\n1HSYsKOmC90W8QclEcpXR1uhNjjgocDmKs1oF0fUPLvlpFca1erGA+8d4W2/qaIDJztN+Lq8Iwyl\nEw8/fPsYjHYPnB6Kv2ysCvn199ZpUaU2YU+dFu0CA1QwIou73zkMNwc4PRS3vSIsqMm5RkQM1FkD\nhMcn8BQZB4CkGK/LlVIuhTKKn+xZJDE5+3TdSCPizo4eKsXpdlDixyUwEMkqb5tKUskDfDOyKR53\nOgBJnCIq5NfvezblMglio0XhLcoIMxnxiv7PBWcFr2L4JyKejA0/uxC//fgYlHIZHv3eDN72yyal\noTAtFkkxcijlY3igzkjEM9fNwPsHWvHsDXNHuziipvR3S3HfBydwQWEKvi/A13nN3Bx0GOzISFAE\n/nIE85tLp0Ill+F4ix6v3B76qHuLJqQgN0mJuOgoxEeHfiLAEB9bf7Uc9793GEq5DE9fN3u0ixMR\nRMRADQBPXz9HsC0hBHnJqhCWRrxcVzIO15WMG+1iiB6lUonX7lwg2F4ukyA/5dxoU/euKArr9XOT\nzo16ZJzmxVv4B8c5l2EbpAwGg8FgiBg2UDMYDAaDIWLCOlATQp4lhOwihDw/nO9brfwDsA+XcIdK\nHclQrDZbeE/HcjwD2fNhJOvJ4/EvSxoqAv2WYH+rwzFyIhXBPntD/VYxhClmjDysPw8dYXtHTQgp\nBhBLKV1CCHmJEDKfUurXt0prcvTHz11WlIo3f7QwpGUpbzNge7UGmQnRuGZuDmQhPBLNcRRfHGtD\nS7cNSyenYU5eeGX6ytsMmProdiijJKh67LKQXrvTaMfDX5bD4vTggZVFKPEjzBEMVWojtlR2IiNe\ngWuKcxEVxqPpRpsLK5/9DtFSKf59W7Egb4Gh2FGjwbEWPWbmJGDl1DPFJCilWF+mRn2XGecXpvoV\nOBmKnTWd+NFbh8FRijVzsvGPG8N7MPBEmwHT/vwt0uMUOLB2FS9bvdWJTw63ws1RXDM3B+nxZ8qB\nqg02fH60DQqZFNeX5LIDY+cArD8PPeFcUS8CsKX381YAiwcmEkLuIoQcIoQcUmtO+/zuawi9gHyV\n2ggPR9HWY0OPNbTSZSa7G6d0VnCUorLdGNJr+6NvnmdzhX7Ve6S5Bz1WF5xuDrvrtCG/fmW79z60\n6+1h92c32F1wuTmYHC5srewM+fUr2o2g1Pvfs7G7ONRpzN70Nv4Bel7d1Qg3R8FR4NvqkfOH15j4\nr+CbdFaY7G7YnB7U+Qn+crLTDIeLg9HmQrMufCsshnjQDni2WX8eGsI5UCcC6Pulht6/+6GUvkIp\nLaGUluRmnV6RXDw99FJ3s/MSoZRLMSEtBskxofV7jVfKMCkjDtFRUszOSwjptf0hIcSbb3To3cwW\nFqQgK0GJuGgZVkxJD/n1Z+clQCmXYnxqDFJjw+vWlKiUI0YuQ2qsApfNzAz59efmJ0IRJUFxvq8P\ntlIuxfTseERHSTHHT3ogHlg5EXIpgZQAV87KDkVxh8W4FGXgL53FhLQYpMbKkaCMwmQ/kp9Ts+IQ\nr4xCWpwC45nP7DnBQD9p1p+HhrDJXBJC7gXQRSn9iBByDYBcSukL/r6bmppKCwoKwlKOSMfu9KC2\nywwCYGpmLFpaWsDqyj/VaiNcHEWiMgoeo0bU9WS0u+BwcUhSySGTkpBe2+2haNNbIZNIkJPkO/ga\nbS609tigkEkwMT0WTU1Noq6r0aS8zQAKIC9JCb2mndXTIDR0mWFxeqCQSSC36Vg9DZPDhw9TSmnA\nBXM4/aj3AbgbwEcAVgF4c7AvFhQUMP3SQSj8wwZk9e5yO+USFGz8I6srP7yyow5PbKrp/zt168Oi\nraf6LjPWfn4ClALTs+Pxpyunh/T6d7x+AJ5T3tjZP1xWiJ8uLzwjfcpDXyPd7W1Uty6fgHfXfl+0\ndTWaLHlqKzL13tcBHgAFIm5To03BgxsQ3/tZzM+e2CCEDCt+cdi2vimlRwDYCSG7AHgopSyoqwBk\nktO3aCyHPw2WzAiKEBYdJYG09xWGUh76uXLMgPCoKX62BqUDmlFKXOTU20iTNKDuQrvnwWDwI6zu\nWZTSByilSyil94czn7FM9V8uQ6JShsw4OQ798eLRLo5ouWpuHlZNToVSJsELN84a7eIMSU6iCmsv\nn4pbF+Xj/uUTQ37952+cjVsXjsOvL5mEGxfk+6Rv+Nn5mJYVh9sW5uEH500Ief5jha/uvxATU1WI\nVUjx3W+WjHZxRM2vVhVCKZPg+nlZo12UMUnY3lHzoaSkhLKtkuFRUlLCtpWGAaun4cPqaniwehoe\nrJ689Lmo+aPpqcsBAISQw5TSkkDXYpHJGAwGg8EQMWygZjAYDAZDxLCBmsFgMBgMESMKmUtKgY8P\ntcDu5rB6RiZSQhwMo1FrwbfVGmQnRuOS6Zkg5MwznF8cbcPGE2rMyU/ET5cVDnKV8LDpRDvuefco\nAOD/LhyP362eNqL5D8Tu8mB9mRo2pxuXzshCmshOBE9auxFOD0W0TILqvwQXPrWl24qtVZ1IjVVg\n9cwsSCX8zvUePtWNYy0GzMxJwILxviFCd9RoUN9lwaIJyZiezS9wgsnuwpMbq2CwuXDvikJMy+Jn\n//j6Cry2pwlSAnx893mYM45/0JVQoTM7sLG8AwqZBFfNzkb0WZ4LrT1WbK3sRHKsAqtnZIY0HGQg\nNHoLFv11BzgKFKXFYMuvlo1Y3pFGyWObobV4o4CdWHsh4uJ8g9swwocoBmqH24PWHq/QxIk2A5ZN\nDm1UrENN3TDYXDDYXJg3LtlnANp4Qg2DzYWdNV34/qJxiBvBeMRPfF3dHxb0rf3NozpQN+ksaOn2\nhnksbzNgeRiikwWD0+OtKbs7+PCpR5p7oLe6oLe60GG0IyeRX1Su/Q3dcLo57G/Q+QzUNqcHR5v1\nAICDjd28B+rSBh3quywAgI1lHbwH6vcPtoCjAEeBh9dV4Mv7LuBlH0oq2o3Q9oYmrdOYMSPnzN9y\ntFmPHqsLPVYX1Ab7iOrG/3FdBbjeh6+2t74Z/ukbpAHgD1/V4MVbA55/GnGGOrwFnD7AxddWqF0o\nEcXWd5RUghiFFDIJwYTU0IonAEBRRhwIAdLiFEhU+Q7Cs3sDrxemx47oIA0A187N6f88v2B0A8Bn\nJyoRq5BBJiGiDPdIzvpvMBSmx4IQIDlG7tfXOBBF6bFn/Hcg0VES5PcOOEV+wmoGYnp2AuKiZZBK\nCOYX8F8Nl/SuoAmAm0pyeduHkvGpMYiSEqjkUuQl+Q7ChemxkBCCJFXUiO/g3HNBQf/ncITkHUvI\nB0TPu2/55FEsybmJaNyzSg8cBEdp2BSVnG4OUVLis+3dh8nuQoxcColk5Ocubd02mGw2TMkJrLIU\nbtcHD0fDeh+CZWuFGqumB/bVHE49Od0cZBICCc9t7z4cbg8UMv8dPKUUTg83aHog3G4OTo6DSmBA\nlLoOPVJjopEYFx3wu+FuUy4PBwkhg75eCPY+BIPFYkGZ2oLFhYF3j851t6Ovy9pwwfj4gNveo1VP\nkbSi5uueJYqtbwCQSgikYYz/I5cNPfCM9Ep6IDnJSgD8BRHCQbjvQ7AMaGZtAQAAIABJREFUZ5Ae\nLoHaRCCGGoQJIYIHaQCQySSQBbHhVZgpDnk+AAEnfcHeh2CIiYnB4kLx7R6Jkctm5QT+EiMsiHPZ\nxGAwGAwGA4CIVtQMBoPBGDsEuy0cymtGOmxFPQysTjfK2wxwCjxtvLOmE89trgn8xUHosThhsIVW\nID1cHGrUoaHLLMjWbHHixe0n0STQ3uH2oNNohxjOXQSi2+xEpdog2P71XQ14fVdDCEs0Njne3I1f\nfngU3UabIHuzww2t2RHiUomTtZ+V4dNDzYJsPRxFp9EOlyd4jwyGL2xFPQwe+rwcbXobJmXE4bE1\nM3jZrj/Whp99eAwcBdaVqbHt18t42dd3mbHueDskhOD6UT7BG4h/fVuL90qbIZNK8PyNczAnn9+J\n5eXP7oTO4sQ/t9fj8O9XIpbHaWy3h8N7pc3QW12YlSsewXd/dJud+PUnx2BxeLBqWjp+soSfMMfd\nbx/EN5UaAMC+Bh1evX1+OIoZ8dhsNqz59z5QeJ+92sdX87LXW514t7QZTjeHVVMzwlNIkbDg8a3Q\nmBx490ALjDYX7uTZJteXtaOhy4KM+MCHFxn8YSvqALjdHDqMdgDe4Ax82V2n7ffV7DTxn5lrjA5Q\n6p2xdgmwH0lqOkwAvINmRbuRt73R7vbacxTNBn51bXdz0Fu9uw5990usdJhssDg8AIBTWv5tamDd\nVrQJX5WPdcrV1v4YBS4P/12WbouzfxetU+RtKlj0Vmf/5+01XbztNUZv3yT2PipSYSvqAMhkEty2\ncBx213Vh1bRM3vaPXjkF39Z0wWh34ecr+Uc9m5OXiB6rEzIJwZTM+MAGo8i9ywvx+MYqJKnkuL6Y\n/+r/hpJcfHGsDVMy4zEtm9+p5ViFDEsnp+GUzoIF41PwLO/cR45pWQlYNS0dp7RW3LZoHG/7f95c\njJv/ux8A8NxNc0JdvDHD/AkpyE1UQm2wYUFBYNfHsylIicGc/ESY7G7M9xN9bizxkyXj8Z+dDVBE\nSfHKrbN526+cmo5jLXpMzozD/4Isy7n6Hnoo2EA9DFbPysLqWcLcghQKBUrXrhKct1IuxeqZkaHx\nOjkzHm//cKFg+8fWzMRja2YKti/OT0Ixz+320YLvdvdA5oxLQtVjwYVQPVfY/eAKwbYSCcHyEEdJ\nFCu/uXQqfnPpVMH2E9JiMSEt9MGqGF7Y1jeDwWAwGCKGDdQMBoPBYIgYNlAzGAwGgyFiRPOO+tPD\nLTDa3bhxfh7v+MYOtwdHTukRr5T5VSrSGO34/GgbijLisMKPIlS3xYmKdgPGp8Yg149wQCAe/PQ4\nSht68OBlk3DJjGxetpRSlLUa4HBzKM5PDCjzZ3d58O8ddVg2KQ3TeKoyAcC97x5GldqEv103C/N4\nHrBxuzl8eLgFBAQ3zMuFjGfoR63Zjk8Pt6EwPRYrBbi7dBjsqNWYMDkzDunDiGEdDC09Vmw4rsas\n3AScV5jqk16pNmBHTRcuLErzUYQCvDKaTToLZuYkIFHFX/Tjllf3Q2d24OXb5qGA57s/q9ONDw60\nIEklx9XFgcM+akx23PH6Afz6kkmYkcPvEB/HcfjwUCtcHg43zc/3CQfq9nA40qyHQibpF78ZSIfB\nhhe31WJ8Wix+vGQCr7wBYF+dFp8fa8NlMzKxfEp4Xag4SrG7VovsxGhB72OPNvdgX4MOq6ZmYJIf\nsZaGLjPa9XbMzkvwG9K4Sm1Ej9WJ4vwkH7nQQDTpjLjx5VJEy2T45meLER197rlRCT2kJobDbaIY\nqE12Nz461AoA4DiKH/F8YPfV6/plBeOjo3yk8v61ox7VaiO+rdGgKC0WeSlnpm84oYbW5MDxFj3+\nb+lEXpq4u2u78PHhNlBK8auPy3gP1HUaM7ZXe31iKaVYOCFlyO93GO3YWdOFw009eO0Ofv6z7+xt\nxKaKTlBKcfc7h3HooYt42X9xrA1fHWsHAKjkUqyZyy/277+/rUdFu/c+TEiNwXiend0Xx9pgc3pQ\n02ES1Knz4YWttWjutuK72i5My473GWz/sfkkTHY3DjR24807F5yR5nB78MXRNrg5itYeG25ekM8r\n77WflWF/gw4AcMcbB7Hjt8t52f9v36n+NpUWJ8cFRWlDfl9rcuLwqW788qPj2PyLpbzy2niiA18c\nbQMAyCQS3LLwzN966FQP9tV7f0uMQorC9DMHqEfXVaKsVY8dJ7swJTMuYFnP5pF1FTA73DjY1IML\ni1IhlYZPBctoc+NgUzckhODOCwoQz0MfwO3m8I8tJ+F0cyhvM+Dft847I93scGPdcTU4StFltuPq\nuWd6TagNNmwq7wDglVHlO9G96eVSdBqdAJy4+bVD+Pze0ZM+ZfBHFFvfA0VzlALUgvpm8YT4D/Af\n3fv/pIRAHuWbrugdmKOkkkHVtQYjPvq0hEWUAOWtgeUdjjiBpLd8Cj+/IxDxytODTZSUv/DGwJ0O\nlZx/h9i3ChjsPgSiT9xBMQIiDn15yKT+VZ/60hV+JnUSQvone3IBKmTJMfL+dhgt52+vHHBv+DxP\nQupVpRi6TZzRvv0Mon1tghAiSCms7/pREhLWQRrw9i8AIJUAMp5KXxLJ6bbgT6xFSghkvc+kv3qK\nkkr6n30hIibRUafrNkE5egJEDGGIRubyhQ82wWR346Jp6bylJjmOoqbThLhomd+ta6vTjS2VnShK\nj/W7XWxzelCnMSM3SYkkAdrEb+xpxJbKTjx65XQUZfLXHz6ls8Dh5lCUHhtwojB7bjEeeW0dFk1I\nRlYif8Wt57bU4EhLD56+dgYyE/hv322v1kBCgGUC3Fb67sPEtFi/28WBMNpdOKW1oiBVFVDtLFip\nPYPViW9rujAjOx6FfrYp1Xob9jd0Y8GEJOQk+ra5bosT7XobCtNjeW9TAsDDX55Au96OZ6+bzStC\nG+Ddjv6mshPJKnnAHRoAKJo+Gzc/8Q7uW1aE9AT+W6K7arvgcHn8xhmglKJWY4ZCJsG4FF+VKpvT\ngzf2NmByRhxWTuUfp6Chy4z1x9VYNT0d07LCG5Fu3rwSvPXVNqTHKwS9emnRWXHoVA/OL0xBup8I\nXl0mBzqNdkzKiPM7GLfpbTBYXZicGTeoZOhg2O123PzaISQoo/BmEC6Uw6Hv2RPDlrFY4StzKZqB\n+lzWeeXDua6JO1xYPQ0fVlfDg9XT8GADdWD4DtSi2PpmMBgMBoPhnyEHakJIOiHkOULIekLIk4QQ\nccewZDAYDAZjjBFoRf02AAuAFwHEAnhhuBcmhBQQQjoJITsIIZuDKCODwWAwGOcsgY5ZZlFK1/Z+\n/oYQcoTn9bdQSm8TUC5RMf8vW6A1O5GfrMJOnq4ydqcbT22qgcZkx48umIB54yIjFrUQ/r65Ci/t\naIRMSrDu3vNRxFNE5D876vDF0XbMyE3AM9fzFwaIFNxuDn/9phqtPTbcvrgAiyYGPvA1kI8PNuPB\nz04AAP7yvem4eVFBGEopDu599zC2VHYiNU6BvQ+u5G3/4CdlONaix5VzsnDv8iJetk43h40n1DDZ\nXbhkOv+DbiPJphPtuOfdowCAn68sxAMXTeZl3663YWtVJxJVcqyekcnLRZURfgLeDUJIEiEkmRCS\nDEB61t+BWE4I2UUI+UXwRR0d9CY7usxOUADN3fwlCY+3GlClNkJndmJDWXvoCygi3tnXDDdHYXdx\neGxDFW/7L461w+RwYV+9Fh0GWxhKKA6qO00oazWg2+LEV8fbeNs/u+UkPBTwUOC57bVhKKF42F6t\ngZuj6DDYsaGMX13pzA7squuCyeHq9//nQ3O3FY1aC7RmJ4616HnbjySPra8EBUABvLqrkbf9sRY9\ndGYn6jVmtOnH7rMXqQQaqBMAHB7wLx7Akd7PgY4/qgFMArAcwCpCyKyBiYSQuwghhwghh7q6+Ouf\njhSJcdFQ9Po3qgT4tE7OjEOSKgoSQlAybmxL5c0rSAYhgJQAN8zjL3M5J9cbuSovSYW0WP5ucpFC\nQUoM0uIUIASCdlgunp4BAoAAuEhAhLdIYnyq16UrOkqKxRP4BUNJVMqQ3xv8aGYuv4hrAJCZEI24\naBmkEiJ6ZairZp8OtLRQgCTnxLRYSAhBgjIq7FH/GPwR7J5FCMmhlA5riksIuQeAgVL6nr/0SHDP\nOtCgxYIJvqEkh4PbzcHm9gT0/R0OYncRqe0wIlGlQFq8QpC9xmhDSow86OAVYq+nYNtEk84It4tD\nYSb/AehsxF5Xle16FKaqIJfzn7x5PB7oLE6kx/OPOQAAHo7Cw1HIZRLR11NdlwFupwdTcoQtCBxu\nD6IkEkh4+mifDXPPCgxf96xgQojuAzBobERCSByl1NT75/nwHkiLWIQO0gAgk0kQNwLRtMQA3/fS\nZyO0Q400gm0TBSnnjgPGtGzhkxGpVBpUm5JK/EemEyOFacEFfPEXMY0hDoIZPQK13iWEkMOEkL0A\n2iilpUHkxWAwGAzGOUkwK+oh98wppRsBbAzi+gwGg8FgnPMECnjyIiHkBT//XgQQ/MsxHhisLhjt\nrkHT6zpN0Bjtg6ZrTHbYXR6/aWaLEy/tqEVTl1lQ2XRmB3bXdsHj8X/9UELhle10ezhB9m09Nuyr\n0w6abna40W1xDpr++q4GvL23QVDekQTHcahsN8A0SJtzur3pdqfbb3pTlxkv7aiFeYi6HIpOox31\nAtsj4I01bnb4L1uoadNbcUpnGTS9x+IctB4B4LefHMcnh06Fo2iiwup0o7LdAKfb/7Nrd3mgMQ3e\nh6071oKHvywXnL/eOvR9YIiXQCvqoU5OjNipiiatBV8eawchwLXzcpFzlhjF50fa8MHBZshlEjyx\nZqaPjOWeOi0ONHYjLlqG2xaN8xFJWPbsTnRbnHhhWx2O/3Elr0MrBpsTt75aCpPDhfnjk/HcjXOF\n/9BhoLc68W5pM/KTVbiW58nqlm4L7njjIOwuDy6aloFHrppxRrrO7MD7B5rh8lBcOiMTU7POfA/6\nk7cOYkuVVz5xX4MOL93GT2Yzknhuay1KG7uRHCPHszfMRvRZyk6PfFWO+i4LxqWo8PR1Z/p8my1O\nXPL8Lrg8HN7Y04QDa/nJiTZ2mfGnryrgdHO4dVE+rprNT060Sm3EpvIOyGUS3DQ/Dymxwg72DYfj\nLT3466YacJTi3uWFWHKWTGVtpwkbTqghJQQ3LsjzOVE8+5FvYOiVubU43Lj9/IlhK+to84fPyqE2\n2DA1Kx6PXDX9jDSnm8O7pc0w2lwoHpeEpZPOrMc3dtXj0Q3VAIBNFR0o/cMqXnnXacxYX9YOKSG4\nYX4eMvyIgjDEy5ArakrpW0P9G6lCdhrt4Kj39GWXyeGTXte78nC6OTRofVchaoN3lmqyu2Hxs8ow\n2ryzTKeHot3AbwXUYbDD5PDaN2n5+1nzxeXxvnHoGGL3YDDqNOb+XYX6Lt8VkM7iHPL6J9pO+5KW\nt5l80scSTTrvvey2OGG0+7aZ1l5f07YeX5/Thm4zXL07HgYb/1Vtg9bSv+qq1/BfVffdO6ebG3J3\nJBTUdprh4Sgo9X72VxZKATdHoTX5lmXgqv+bCk1YyzqaON0cOnvvS2uPbz9hdbr7+6FOg++zt7X6\ntAtrj4B72jngPvjrQxniZsgVNSHkq6HSKaVXhbY4/pmVmwit2QmpBJia5Ss5eFNJHow2F1Ji5Th/\nou/p7CVFqdhTp0VWgtLv6uKa4hxsKFNjWnY8Cnj6S07OjMfqGVkobzfg9vPG87IVQny01zdUiEzk\n8ikZuLCoE6e6rfjpUt+Vy8S0WMzMSYDV5UGJH//eZ66fhR+/dQSEAH+/fpZP+ljitkX5+PxIG2bm\nJvqVJLxt4Th8W63xWUECwKy8ZBTnJ6Gmw4g1c/mthgFgSVEaylr16LG6cMP8PN7288YlwWR3I0Yu\nDbv/76UzslCrMcPNUayZ4/tb5+YnQW91QSGTYFKGb1lunp+Ldw+0Qi6T4L+3jd1odHKZBDctyMP+\neh0umeEb5SxRJcf5halo7bFisZ9Idf+9bTbmPbEDDjeHnyzh38/MyUtEj9WJKKkEkwVI8TJGlyH9\nqAkhXQBaALwPoBRnnfSmlO4MRSEiwY9aLIjdl1MssHoaPqyuhgerp+HB/KgDE2o/6kwAFwG4GcAt\nADYAeJ9SWhFkORkMBoPBYAyDQO+oPZTSTZTS2wEsAlAHYAch5L4RKR2DwWAwGOc4Af2oCSEKAJfD\nu6ougFfq8vPwFovBYDAYDAYQ2I/6bXhDhRYDeJRSOp9S+thwY3zz4USrAQcauwX5BzvdHPY36FDZ\nbvSbvrWyA+c9uQ13vXXQb3qPxYk9dVrBqjF767R4eWc91BGgOrOtqhOv7qpHt9n/ydEFj2/FjIc3\nobx5cF/rSIACONDYjROtBr/pm060Y9Yjm7D6+e/Ckv+BRh1e3lk/pH9xpFClNmJ/gw4ON/84AZXq\nHkz949eY88imMJRsZOEoxd46LRq14bmnlzy7E5PXbsQrO0+G5fqMyCVQCNHbABQBeADAXkKIsfef\niRDif1QUgMPNYWtVJ/bUaXGwqYe3/d56LfbV6/BNRYdf14cH3j+GdoMdW6o1+NhPYIUNJ9Q40NiN\nL4628Z4oaM12/PPbOmyv1uCFbeKWHKzrNOHVXQ3YWqnBy9/V+aRf8fx30JgcMDs8uOFV/5OaSMHi\ncGNPnRZbqzrR4CdwyM8+OAaj3YNKtSmoIBL+MNvdeGFbLbZXa/DcVnG3iUC06W3YVN6BffU67K3X\n8ba/9l/7YXNx0Ns9WPbX7WEo4chhtLlR2tiNr461hzxwyCs7T6Km0wyHh+KJryO7zTBCz5Bb35TS\nEVGSGHiUXC7jHwBf3ityTggQ5UfwXColQO9z5U+tqM9eKiEghF/+MokEUgnxKuxEiTuovUImhYQQ\neChFlB91qnjl6bqJFCGCwRhYfH9tQkII+qLgJquCVzU749oSQCqRwOXxQB7hYixREgJCAEpPPyd8\nkEkJ0OsqrVKI+/kIRF/XIJWE/vlIVp12AYzsJ48RDoKJ9R0y5DIJrp6bA7vbg8kZ/H38Fk1IQaJK\njrhomd+IO5/+32L88uMynDcxGZfOyPZJv2J2Fuo0ZuQlqXg/gIkqOdaunooqtQmrpqXzLvtIkpei\nwu8unYxGrRWXTvfVMX7vrsW4+p+7oTU78M3PFo9CCUOHSi7DZTMzoYySIi9Z5ZO+/oHz8MM3DmNW\ndgIeuGhyyPP+05XTcKy5B8snR7ZedHp8NK4tzoXR7sIUAcpo+3+7BCuf34cEZRQ2/nxpGEo4csRH\nR2HV1AxkxCugkoe267xufj62VHfgQIMez904dv3JGcIQxUANAAW9AvFCkEgIpmUP3okUZcZj3f0X\nDJquksswS4CwfB9TsuIxJSsyZAdn5yVhdp5vMJM+Pr9v8HqKNIYaWArTEvDdb1eELe+JabGYGOZg\nIyOFv4nOcImJicF+nuEuxQohwMzc4KQkh+Ll7y8I27UZkU1k78sxGAwGgzHGYQM1g8FgMBgihg3U\nDAaDwWCIGFG8o6YU+OxIK2wuDy6bkYXkmOHLTALAO/ub8LdNNVApZPj8p4uRmcDvndpXx9uwsUyN\nuflJuNuPWEVpgw6VaiOK85MwO8/3XfazW2pwstOM60vysGKKeA+U6U12LHr6WzjdHC6Znu4jU+lw\ne7DxhBoWhweXzshE6lkCJmq9Dc9sroGEEPz6ksljWirvzT2N+PBQC6ZkxuPZG+f4pB9p7sHxFj1m\n5iSgpCDZJ/0Hr5WiusOEq2Zl4aErp/ukD0WP2Yn73j8Ck92N3182BYsLfYVmQonR7sKbexqxdHI6\nxvM8K7K5vB33vHsUAPDwlVPxg/Mm8LI/2tyD/+5qQGaCEr+7dErEn5IfiikPfQ27m0OSMgpHH754\ntIvDiCBE8VQ43B6c0lmhMTpQ1qoPbHAWr+1qhM3lgc7swH92NvC2X39cjR6r6//bu/fguOrrgOPf\ns1pJ1sO2MPIjgJExwmSMeRkBDsROKHSGV2l5BpoC6TANfzAtr8y0aaFD6CQl0xAXSCiPCWWYljiZ\nZMAG7BCMCTbFD/yQBdjGlmzZlvzQW5a0K2klnf6xV3jR7lp71/u4qz2fGY137927Pjq6u7+9d+/5\nHdbsaomqj1RV1u9tpysQYv3e6DrSg+0BNuztoKNvkBW1h1z/35n0b+/spD80wojC6p2tUev3tfXR\n2BagtWcg5kQhf9xxlKbOIAc6AqzeeTQTIWfN77c2cSwYYtO+9ph12OsbwvtErNrihpZeth3oJDg4\nxFufHnb9f79V10xjex/tfQO8vulAUvG7ERwcpjMQ4pPGDtfb/njlFwwrDCs88350bf54ltceoq13\nkM+au6k96H4OhVyxr6WPfqd1aWcwtTXYZuLzxEBdWOCjtKgAv09cf6IHuKK6EhGhsMDH9edHt5Ab\nz2jLyLmVZZQVfbXWU0S+bBUY6yremVMncVpFCQAXzk7fFaGp8J3LZn9ZX1w1LTrPX5taQllxAQU+\niXkV/sVnVlDk91Hk93FxjDMLE8kFztW9M6dM4oypJVHrzz7BPlE1bdKXZyOSKTe8fO6plBT68Ylw\nRXV0y8NU8zv10clcpX79+bMQwrW/i6ujW36OZ2FVBSJQUVLIvCRylSvOmnH89ZTjUxSYLDhhm8tM\nqamp0Q0bNzGsSrE/uUkR9rf1UVFaxNQkJ6/o6B2kotSPzxf92UVV6Q+NUFIUO7ahoRF6B4eoKHV3\nyj4ZJ9tqr6unn92tvVw2N/bp1KHhkRP+HXr7h/D5SHkdaaqloiXhke4g08uLKIgxOQyEj0QnFfpi\nTpIzNDREU1c/cyqTK9HqDQ4yMKwx+6enWk1NDR+t38ikJCfsqT/SxeAwzD89uQ9v3YFBSor8nj/t\nfbL7VF9fH6t2tHPbpWemMCrvsTaX40t1m8uM8Rf4TiqYqpOowwaYVh5/kBWRuIM0gN/vo8Kf/kE6\nFSomT+KyyfG/Wx7v71A+yTO7TNrNinEkHenE+4Q/6UEaoLykiExWYSc7SANUzzq5sytTM/AB1wvK\nysq47dKTe58y+cnbH2GNMcaYPGcDtTHGGONhOTNQP7N6Fy9/6P6q0lG7j/bQHYjd2nEi2byvjUd+\ns41AILqLWCJajvVPiNaMifjBb7ayYtvBpLYdHlFaevqTasuaa363eT9PLP80bc9ff7QnbtvVXNLW\nHeDBZVuSbhHb0x9i1+GUNSU0E0hOfOF403PrqGsO78D/V9/Oq/dd7mr7l9c2sHpnC5Mn+Xn69gsn\n7HdiB9oC3PbiRgBWbD9E/U9ucLV9/dEefvT2DkLDI9x7xRyuW/C1dITpCfMfX0UgNMLvth2mZ2CI\n7y46y9X2K7Y309gW4IxTSri9Znaaosy+Z1bvYunqBgBWfnqUTY+ldt7u1zceYHltMyVFBfz01gty\nujb/8qc+YFhhee0RdvzrVZSWJj6fQ2//EI/+djvdwRBL5k3ngauq0xipyTU5cUS9t/X4EV7doej6\n3vHUO9v39A9xtGcgZXF5zabG47XRQ0kc6O1t62NwaATV8BmIiSwYOp6gt2rd1zof7u4H4Ijz70T1\nfkS9fUcg9a+dBqdGPTg4zMGO5M4CecVwRAHNwR53Zwja+wboduqrY9Xtm/yWEwP1T25egI9wH9hf\n3Hmx6+3vXlTF3Moyrpk/Y0LXat5WU0VFiR8BLq1yfyXuknMqqZkzjXNnTea2S85IfYAect2CcPvJ\nQp/wq7vdtxW8+uszmT2tlGvm53Yby/G8cs8lFBUIAvzdN92ddUjEXZfOpnpGOYvPqWThmbldm//1\nmeUIMKO8mHNnuvtdqk4t49oFs5hbWcbfLKpKT4AmZ3mmjvpka17zRSrqg/OB5SlxlqvEWJ4SY3XU\n43NbR50TR9TGGGNMvrKB2hhjjPGwtA7UIrJURNaJyDPp/H+MMcaYiSptA7WILATKVXUxUCQil57o\n8d/86RoWPvku9a3RV3WPjChb9ndSe7CLZL5Tb+vt5+V1DXz4RYvrbb3mYEeA+Y+v4sFlW9Ly/Mtr\nm3ltfSOBwaG0PH+mqCqvrW/kzW3NMdf3h4ZZ39BOfUtyV7e39gzwcX0bLcdiX/Xd1Bng4/o2ugPJ\ndUq65fmP+NZ/rKGxNf11tfUtvcx/fBWvb9jneltVZfvBLrbs72R4xP1rsz80zIa97ezJgSqDjr4B\n5j++ipueW5eW529s6+PjhjZ6B1L/2hseUbbs76CuKbn3UJNd6TyiXgS859xeDXwj3gPrW3pp6gzS\nERji1uc3RK3f3tTF2t2tfLCrhZ2H3b+gn1vTwOodLbzw4V4OduZ2CUhXMEQgNMLy2iMpf+6P9rTy\n+sYDvFN3mP/dsD/lz59J7X2DvFN3mF9vOhDzA9qfvmhlw9523q47TFuv+7Kj5bXNbNzXwRsxPggM\nDo3w5rbw+pWfuS/9emjZNrYe6GZ/e5A7X/rE9fZuBUPDBEIj/MubO1xvu+tID2t2tbB2dyu1B923\nqF23p431DeG/Q0uPt0vdmrv6CYRGqGs+dlKTL8XSOzDE8tpDbNzbwXs7Uv/a3nqgk7W723h/Zwt7\nWqz8K9ekc6CuAEYPB7qd+18Ske+LyGYR2RzqO34UXRije1VhgS/itvsecUXONj6BogL7Wj6eyMYM\nRUl2MfMKX0RHq1gNJ0b3I0EoiNH9ajyj+6Q/xv4kAgXOfuxPoqfhlOLj8xAV+jPXEzGZ9ouRr8dk\nXlv+L1+byf0dsqWsOLWvD5+Ey0/hq+93qRK5HyazT5rsSufMZN3AFOf2FOArH7dV9SXgJQiXZ805\ns4KuwCBvPbAo6onOO20KhQU+CnxQPcN9HfSDV8/j3c8Pc87MyTk98xHAzMnFnFpWyD3fSH2rvJo5\n0/j7P6umKxDi2vPc9/X2klNKi7h7URVTSwu5fG50T+cl86YzY/IkppUXcUqZ+5nqbl54Ovta+5hz\nanQ3pMICH3fUnEFTZzCpuv0nbz6frmCIpq4Ar95zwm+MUmJqSSFbUldIAAAG0klEQVTTywp5Jok5\nCqpnTOYvLhSGR5R5M933+1pcXcn08mIqSgsz0tLzZJxVWcbkskJqzprGX7ucyW48pUV+7qiZzZFj\n/Zw7K/VzPVw0u4KSogIKC3zMTaLvuMmutNVRO99R36+q94vI88CrqropzmNbgf1AJZDcRLnp55XY\nFgIH8EYs8XghVwuBrR6JJR6vxGb7VGJsn0qM5SlxVao6fbwHpe2IWlW3iki/iKwDauMN0s5jpwOI\nyOZEir+zwUuxeSmWWLwUn5diGctLsXkplli8FJ+XYhnLS7F5KZaxvBxbLGltyqGqD6bz+Y0xxpiJ\nzq6sMsYYYzzMawP1S9kO4AS8FJuXYonFS/F5KZaxvBSbl2KJxUvxeSmWsbwUm5diGcvLsUXxRFMO\nY4wxxsTmtSNqY4wxxkSwgdoYY4zxMBuojTHGGA9La3nWeETkEsJzgFcQnrlsg6p6rjO7iCwAFgAN\nqpr+yZej/3/LU+IxeD5XlqfEWa4SY3lKnBdy5VbWLiYTkaVAMeGGHaPTjV4DDHmh/lpE/qCq14rI\nQ8DVwDvAlUCTqv4wg3FYnhKPxbO5sjwlznKVcGyWpwR5KVdJUdWs/ABr3SzPQnxrnH8/BHwRyz+y\nPHkvT17PleXJcmV5slwl+5PNU9+bReRFwq0wjxH+BHY14TlivWC+iLwGnE34k2LQWZ7prh6Wp8R5\nOVeWp8RZrhJjeUqcl3LlWlbrqEXkYsJ9qysIny5Zr6rbshZQBBGpirh7SFVDIlIOLFbVVRmOxfKU\neDyezJXlKXGWq8RYnhLntVy5ZROeGGOMMR5m5VnGGGOMh9lAbYwxxnhYXg3UIjJLRJaJSIOIbBGR\nlSIyz1n3kNM/e2rE478tIt0iUisiu0TkZ87yv3WW1YrIoIh86tx+Klu/W6aIyLDzu34mIm+JSIWz\nfI6IBCPyUisiRdmONxtEREXk6Yj7PxCRJ5zbT4hIc8Q+9V8ikjevQxHpjbh9vYjsFpEqJy8BEZkR\n57Fxc5ovIvMRsSxyf9ohIndlI7ZscvaN/4m47xeRVhF527n/PRH5RYztGp337joR+aOIzMpk3G7k\n0xuEAG8Af1LVs1X1EuCHwEznIXcBnwC3jNl0napeBFwM3CgiV6rqf6vqRc7yQ8BVzv1/ysxvk1VB\n53ddAHQAD0SsaxjNi/MzmKUYs20AuEVEKuOsX+rsO/OB84FvZSwyjxCRq4FngetUdb+zuA14NM4m\n4+U0n43uT38JvCgihdkOKMP6gAUiUuLc/3OgOcFtr1LVC4DNwD+nI7hUyJuBGrgKCKnqC6MLVHW7\nqq4TkbOBcuAxwgN2FFUNArXA6ZkINkesx/IRyxDhNnoPj/O4IsLlIZ1pj8hDRGQJ8DJwo6o2RKx6\nBfiOiEyLsVmiOc1bqroHCACnZDuWLFgJ3ODcvgv4tcvt1wLVKY0ohfJpoF4AbImz7k5gGbAOOFdE\nZo59gIicApxD+A+a90SkgHCd5IqIxWdHnPb+ZZZC84pfAt+N/ColwsMiUgscBnaram1mQ8uqYuBN\n4K9UddeYdb2EB+t4M1mdKKd5T0QWAntUtSXbsWTBMuBOEZkEXABsdLn9jcCnKY8qRfJpoD6Ru4Bl\nqjoC/B64PWLdYhHZTvhUyruqeiQbAXpIiTPIHCH8tcF7EesiT30/EHvz/KCqx4DXgH+IsXr0VOUM\noExE7sxocNkVAj4G7ouz/lngXhGZPHbFODnNZw+LyOeEB6cfZzuYbFDVOmAO4ffylS42/cB5P5sC\n/HsaQkuJfBqoPwcuGbtQRM4nfKT8nog0Ej66jjz9vU5VLwTOA+4TkYsyEKuXBZ1BpgoQvvodtfmq\n/yQ8IJXFWqmqIeAPwJJMBpVlI8AdwGUiEvWdoKp2Aa8Tf786YU7z1FJVPQ+4FfiVc1SZj1YAP8Pd\nae/R64vucfY9T8qngXoNUCwi3x9dICIXEP4E/4SqznF+TgNOGzOTDaq6D3gK+MdMBu1VqhogfGTz\nqIhktQubV6lqB/Bb4hw9Ohc4Xgk0xFo/UTn7zg2ET2PHys3PgfuJ0d1vvJzmM1VdQfiiqHuzHUuW\nvAL8SFU9ewo7WXkzUGt4CrabgWuc8qzPCZ/q+Dbhq8EjvUH4yHqsF4AlIjInfZHmDmd6wDriXIBn\nAHgaGHul8uh31J8BBcDzGY8qy5wB91rgMRG5acy6NsKvweI4m8fKaT4oFZGmiJ9HYjzmSeCRfCr5\nG6WqTar6bJzV3xuTuzMyGtxJsilEjTHGGA/Lu09dxhhjTC6xgdoYY4zxMBuojTHGGA+zgdoYY4zx\nMBuojTHGGA+zgdoYY4zxMBuojTHGGA/7fxRoL7bG5tKJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b195400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    We calculate accuracy for each base estimator inside the SuperLearner.\n",
    "    \n",
    "    We can also see that Pearson correlation coefficient among all the base estimators for our SuperLearner has been\n",
    "    calculated. The highest correlation is between MLP and LR (~ 93%), which is quite intuitive because Logistic regression is\n",
    "    the base for Neural networks in MLP.\n",
    "    \n",
    "    On the other hand, the least disagreement is between NB and RF. This is again obvious, because both work on completely\n",
    "    different algorithms. Random forest is an ensemble of Decision trees which is based on Predicting label outputs based\n",
    "    on criterion such as entropy or gini; whereas Naive Bayes calculates the conditional probability and its \n",
    "    working is very much different from decision tree/random forest.\n",
    "    \n",
    "    We also found this during our grid search that combination of LR, RF and KNN in the base estimator gives best \n",
    "    accuracy, which proves that the base estimators should be properly trade-off between predictive power(accuracy)\n",
    "    and the heterogenity (Diversity) among them.\n",
    "\"\"\"\n",
    "\n",
    "# Evaluating diversity vs accuracy in the SuperLearner using a simple default object with label type outputs\n",
    "diversity_model = SuperLearnerClassifier(criteria=\"label\")\n",
    "diversity_model.fit(X_train, Y_train)\n",
    "diversity_model.check_accuracy()\n",
    "diversity_model.check_diversity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
